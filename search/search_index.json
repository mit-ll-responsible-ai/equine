{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Establishing Quantified Uncertainty in Neural Networks","text":""},{"location":"#usage","title":"Usage","text":"<p>Deep neural networks (DNNs) for supervised labeling problems are known to produce accurate results on a wide variety of learning tasks. However, when accuracy is the only objective, DNNs frequently make over-confident predictions, and they also always make a label prediction regardless of whether or not the test data belongs to any known labels. </p> <p>EQUINE was created to simplify two kinds of uncertainty quantification for supervised labeling problems: 1) Calibrated probabilities for each predicted label 2) An in-distribution score, indicating whether any of the model's known labels should be trusted. Additionally, we provide a companion web application.</p>"},{"location":"#installation","title":"Installation","text":"<p>Users are recommended to install a virtual environment such as Anaconda, as is also recommended in the pytorch installation. EQUINE has relatively few dependencies beyond torch.  <pre><code>pip install equine\n</code></pre> Users interested in contributing should refer to CONTRIBUTING.md for details.</p>"},{"location":"#design","title":"Design","text":"<p>EQUINE extends pytorch's <code>nn.Module</code> interface using a <code>predict</code> method that returns both the class predictions and the extra OOD scores. </p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>DISTRIBUTION STATEMENT A. Approved for public release. Distribution is unlimited.</p> <p>\u00a9 2024 MASSACHUSETTS INSTITUTE OF TECHNOLOGY</p> <ul> <li>Subject to FAR 52.227-11 \u2013 Patent Rights \u2013 Ownership by the Contractor (May 2014)</li> <li>SPDX-License-Identifier: MIT</li> </ul> <p>This material is based upon work supported by the Under Secretary of Defense for Research and Engineering under Air Force Contract No. FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Under Secretary of Defense for Research and Engineering.</p> <p>The software/firmware is provided to you on an As-Is basis.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":""},{"location":"CONTRIBUTING/#developer-installation","title":"Developer Installation","text":"<ol> <li> <p>Clone the git repository and navigate to that directory</p> </li> <li> <p>Install virtual environment (the below example assumes conda)</p> <p><pre><code>conda create --name equine python==3.10\nconda activate equine\n</code></pre> We currently support python versions &gt;= 3.9</p> </li> <li> <p>Install the code with the extra <code>tests</code> dependencies</p> <pre><code>pip install -e .'[tests]'\n</code></pre> </li> <li> <p>Activate the pre-commit hooks     <pre><code>pre-commit install\npre-commit run\n</code></pre></p> </li> </ol> <p>We prefer that any contributed code be outfitted with contracts from <code>icontract</code> and tested with <code>hypothesis</code>.  This combination frequently means that the tests require few (if any) actual post-checks -- if the contracts are well-written, then <code>hypothesis</code> can generate reasonable tests that will explore the bounds of the contracts for each method.  Assuming that tests pass, then make a pull request. </p>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>In the MIT-LL Responsible AI GitHub organization, we use the numpy/scipy format for docstrings.</p> <p>We use mkdocs to build our documentation and autodocumented API.  Most of these files can be found in the <code>docs</code> folder, and the dependencies to generate your own version of the documentation can be installed via:     <pre><code>pip install -e .'[docs]'\n</code></pre></p> <p>You can test new documentation by issuing <code>mkdocs serve</code> from the root directory. Once it has built, you can check out the new documentation by connecting your browser to localhost:8000.</p>"},{"location":"LICENSE/","title":"MIT License","text":"<p>Copyright (c) 2024 Massachusetts Institute of Technology</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"gen_ref_nav/","title":"Gen ref nav","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages and navigation.\"\"\"\n</pre> \"\"\"Generate the code reference pages and navigation.\"\"\" In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        fd.write(f\"::: {ident}\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, \"..\" / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         fd.write(f\"::: {ident}\")      mkdocs_gen_files.set_edit_path(full_doc_path, \"..\" / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"example_notebooks/MNIST_OOD_detection/","title":"Image Classification","text":"In\u00a0[1]: Copied! <pre>#!pip install matplotlib, torchvision, scipy\n</pre> #!pip install matplotlib, torchvision, scipy In\u00a0[2]: Copied! <pre>import equine as eq\n\nimport torch\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nimport scipy\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom torchmetrics.classification import MulticlassAccuracy \nimport torch.nn.functional as F\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\n</pre> import equine as eq  import torch import numpy as np from torch.utils.data import DataLoader, TensorDataset import scipy from torchvision import datasets from torchvision.transforms import ToTensor from torchmetrics.classification import MulticlassAccuracy  import torch.nn.functional as F from sklearn.metrics import roc_auc_score import matplotlib.pyplot as plt In\u00a0[3]: Copied! <pre>training_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\n\nX_train = training_data.data\nY_train = training_data.targets\nX_train = X_train.type(torch.float32)\nX_train = torch.unsqueeze(X_train, 1)\n\nX_test = test_data.data\nY_test = test_data.targets\nX_test = X_test.type(torch.float32)\nX_test = torch.unsqueeze(X_test, 1)\n\ntrainloader = DataLoader(training_data,batch_size=64,shuffle=True, drop_last=True)\ntestloader = DataLoader(test_data,batch_size=64,shuffle=True, drop_last=True)\n\nood_data = datasets.MNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\nX_ood = ood_data.data\nX_ood = X_ood.type(torch.float32)\nX_ood = torch.unsqueeze(X_ood, 1)\n\noodloader = DataLoader(ood_data,batch_size=64,shuffle=True, drop_last=True)\n</pre> training_data = datasets.FashionMNIST(     root=\"data\",     train=True,     download=True,     transform=ToTensor(), )  # Download test data from open datasets. test_data = datasets.FashionMNIST(     root=\"data\",     train=False,     download=True,     transform=ToTensor(), )  X_train = training_data.data Y_train = training_data.targets X_train = X_train.type(torch.float32) X_train = torch.unsqueeze(X_train, 1)  X_test = test_data.data Y_test = test_data.targets X_test = X_test.type(torch.float32) X_test = torch.unsqueeze(X_test, 1)  trainloader = DataLoader(training_data,batch_size=64,shuffle=True, drop_last=True) testloader = DataLoader(test_data,batch_size=64,shuffle=True, drop_last=True)  ood_data = datasets.MNIST(     root=\"data\",     train=False,     download=True,     transform=ToTensor(), ) X_ood = ood_data.data X_ood = X_ood.type(torch.float32) X_ood = torch.unsqueeze(X_ood, 1)  oodloader = DataLoader(ood_data,batch_size=64,shuffle=True, drop_last=True) In\u00a0[4]: Copied! <pre>class LeNet(torch.nn.Module):\n\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        self.fc1   = torch.nn.Linear(16*5*5, 120)\n        self.fc2   = torch.nn.Linear(120, 84)\n        self.fc3   = torch.nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]\n        return torch.prod(torch.tensor(size))\n\nclass EmbeddingModel(LeNet):\n\n    # passing in weights for a layer will freeze that layer\n    # and it will not be updated during training\n    def __init__(self, conv1_weights=None, conv2_weights=None, fc1_weights=None, \n                 fc2_weights=None, fc3_weights=None):\n        super(EmbeddingModel, self).__init__()\n        self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)\n        if conv1_weights is not None:\n            self.conv1.weight = conv1_weights\n            self.conv1.weight.requires_grad = False\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        if conv2_weights is not None:\n            self.conv2.weight = conv2_weights\n            self.conv2.weight.requires_grad = False\n        self.fc1 = torch.nn.Linear(16*5*5, 120)\n        if conv1_weights is not None:\n            self.fc1.weight = fc1_weights\n            self.fc1.weight.requires_grad = False\n        self.fc2 = torch.nn.Linear(120, 84)\n        if fc2_weights is not None:\n            self.fc2.weight = fc2_weights\n            self.fc2.weight.requires_grad = False\n        self.fc3 = torch.nn.Linear(84, 10)\n        if fc3_weights is not None:\n            self.fc3.weight = fc3_weights\n            self.fc3.weight.requires_grad = False\n</pre> class LeNet(torch.nn.Module):      def __init__(self):         super(LeNet, self).__init__()         self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)         self.conv2 = torch.nn.Conv2d(6, 16, 5)         self.fc1   = torch.nn.Linear(16*5*5, 120)         self.fc2   = torch.nn.Linear(120, 84)         self.fc3   = torch.nn.Linear(84, 10)      def forward(self, x):         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))         x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))         x = x.view(-1, self.num_flat_features(x))         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)         return x      def num_flat_features(self, x):         size = x.size()[1:]         return torch.prod(torch.tensor(size))  class EmbeddingModel(LeNet):      # passing in weights for a layer will freeze that layer     # and it will not be updated during training     def __init__(self, conv1_weights=None, conv2_weights=None, fc1_weights=None,                   fc2_weights=None, fc3_weights=None):         super(EmbeddingModel, self).__init__()         self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)         if conv1_weights is not None:             self.conv1.weight = conv1_weights             self.conv1.weight.requires_grad = False         self.conv2 = torch.nn.Conv2d(6, 16, 5)         if conv2_weights is not None:             self.conv2.weight = conv2_weights             self.conv2.weight.requires_grad = False         self.fc1 = torch.nn.Linear(16*5*5, 120)         if conv1_weights is not None:             self.fc1.weight = fc1_weights             self.fc1.weight.requires_grad = False         self.fc2 = torch.nn.Linear(120, 84)         if fc2_weights is not None:             self.fc2.weight = fc2_weights             self.fc2.weight.requires_grad = False         self.fc3 = torch.nn.Linear(84, 10)         if fc3_weights is not None:             self.fc3.weight = fc3_weights             self.fc3.weight.requires_grad = False <p>We train the model for 30 epochs using SGD with two scheduled drops in learning rate.</p> In\u00a0[5]: Copied! <pre>model_orig = EmbeddingModel()\nloss_fn = torch.nn.CrossEntropyLoss()\nopt = torch.optim.SGD(\n        model_orig.parameters(),\n        lr=0.01,\n        momentum=0.9,\n        weight_decay=0.0001,\n    )\nscheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[20,25], gamma=0.1)\n\ntrain_accuracy = MulticlassAccuracy(10)\nfor epoch in range(30):\n    epoch_loss = 0.0\n    for i, (xs, labels) in enumerate(trainloader):\n        opt.zero_grad()\n        yhats = model_orig(xs)\n        loss = loss_fn(yhats, labels)\n        batch_acc = train_accuracy(yhats, labels)\n        loss.backward()\n        opt.step()\n        epoch_loss += loss.item()\n    #print(epoch_loss)\n    total_train_accuracy = train_accuracy.compute()\n    scheduler.step()\n\n    print(\"Training acc for epoch {}: {:.3f}\".format(epoch, total_train_accuracy))\n</pre> model_orig = EmbeddingModel() loss_fn = torch.nn.CrossEntropyLoss() opt = torch.optim.SGD(         model_orig.parameters(),         lr=0.01,         momentum=0.9,         weight_decay=0.0001,     ) scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[20,25], gamma=0.1)  train_accuracy = MulticlassAccuracy(10) for epoch in range(30):     epoch_loss = 0.0     for i, (xs, labels) in enumerate(trainloader):         opt.zero_grad()         yhats = model_orig(xs)         loss = loss_fn(yhats, labels)         batch_acc = train_accuracy(yhats, labels)         loss.backward()         opt.step()         epoch_loss += loss.item()     #print(epoch_loss)     total_train_accuracy = train_accuracy.compute()     scheduler.step()      print(\"Training acc for epoch {}: {:.3f}\".format(epoch, total_train_accuracy)) <pre>Training acc for epoch 0: 0.679\nTraining acc for epoch 1: 0.760\nTraining acc for epoch 2: 0.796\nTraining acc for epoch 3: 0.818\nTraining acc for epoch 4: 0.832\nTraining acc for epoch 5: 0.843\nTraining acc for epoch 6: 0.851\nTraining acc for epoch 7: 0.858\nTraining acc for epoch 8: 0.864\nTraining acc for epoch 9: 0.869\nTraining acc for epoch 10: 0.873\nTraining acc for epoch 11: 0.877\nTraining acc for epoch 12: 0.881\nTraining acc for epoch 13: 0.884\nTraining acc for epoch 14: 0.887\nTraining acc for epoch 15: 0.889\nTraining acc for epoch 16: 0.892\nTraining acc for epoch 17: 0.894\nTraining acc for epoch 18: 0.896\nTraining acc for epoch 19: 0.898\nTraining acc for epoch 20: 0.901\nTraining acc for epoch 21: 0.904\nTraining acc for epoch 22: 0.906\nTraining acc for epoch 23: 0.908\nTraining acc for epoch 24: 0.911\nTraining acc for epoch 25: 0.913\nTraining acc for epoch 26: 0.915\nTraining acc for epoch 27: 0.916\nTraining acc for epoch 28: 0.918\nTraining acc for epoch 29: 0.920\n</pre> <p>To evaluate the model, we first consider its accuracy on the test dataset and then look at how well its predictive probabilities allow us to separate in-distribution data from out-of-distribution (OOD) data.  To do this, we compute the entropy of the predictive probability distribution.  Ideally, the model will produce predictions with low entropy for in distribution data and predictions with high entropy for out of distribution data.</p> In\u00a0[6]: Copied! <pre>model_orig.eval()\n\noods_in_dist = []\npredictions = []\ntrue_labels = []\nfor i, (xs, labels) in enumerate(testloader):\n    y_pred = model_orig(xs).detach().numpy()\n    oods = np.sum(scipy.special.entr(scipy.special.softmax(y_pred, axis=1)), axis=1)\n    oods_in_dist.extend(list(oods))\n    predictions.extend(list(np.argmax(y_pred, axis=1)))\n    true_labels.extend(list(labels))\npredictions = np.array(predictions)\ntrue_labels = np.array(true_labels)\nprint('Model accuracy on test set: {:.3f}'.format(np.mean(predictions == true_labels)))\n    \noods_out_dist = []\nfor i, (xs, labels) in enumerate(oodloader):\n    y_pred = model_orig(xs).detach().numpy()\n    oods = np.sum(scipy.special.entr(scipy.special.softmax(y_pred, axis=1)), axis=1)\n    oods_out_dist.extend(list(oods))\n    \nplt.hist(oods_in_dist,bins=np.linspace(0,3,61),alpha=0.5, label='In Distribution')\nplt.hist(oods_out_dist,bins=np.linspace(0,3,61),alpha=0.5, label='Out of Distribution')\nplt.xlabel('Entropy')\nplt.ylabel('Count')\nplt.legend()\nplt.show()\nroc = roc_auc_score(np.hstack((np.ones_like(oods_out_dist),np.zeros_like(oods_in_dist))),\n              oods_out_dist+oods_in_dist)\nprint('AUROC for detecting out of distribution examples: {:.3f}'.format(roc))\n</pre> model_orig.eval()  oods_in_dist = [] predictions = [] true_labels = [] for i, (xs, labels) in enumerate(testloader):     y_pred = model_orig(xs).detach().numpy()     oods = np.sum(scipy.special.entr(scipy.special.softmax(y_pred, axis=1)), axis=1)     oods_in_dist.extend(list(oods))     predictions.extend(list(np.argmax(y_pred, axis=1)))     true_labels.extend(list(labels)) predictions = np.array(predictions) true_labels = np.array(true_labels) print('Model accuracy on test set: {:.3f}'.format(np.mean(predictions == true_labels)))      oods_out_dist = [] for i, (xs, labels) in enumerate(oodloader):     y_pred = model_orig(xs).detach().numpy()     oods = np.sum(scipy.special.entr(scipy.special.softmax(y_pred, axis=1)), axis=1)     oods_out_dist.extend(list(oods))      plt.hist(oods_in_dist,bins=np.linspace(0,3,61),alpha=0.5, label='In Distribution') plt.hist(oods_out_dist,bins=np.linspace(0,3,61),alpha=0.5, label='Out of Distribution') plt.xlabel('Entropy') plt.ylabel('Count') plt.legend() plt.show() roc = roc_auc_score(np.hstack((np.ones_like(oods_out_dist),np.zeros_like(oods_in_dist))),               oods_out_dist+oods_in_dist) print('AUROC for detecting out of distribution examples: {:.3f}'.format(roc)) <pre>Model accuracy on test set: 0.913\n</pre> <pre>AUROC for detecting out of distribution examples: 0.701\n</pre> <p>While the original model performs well on the in-distribution test data, its predictive probabilities do not allow us to discriminate between in-distribution and out-of-distribution data.  For example, the model confidently predicts below that the digit 7 belongs to one of the Fashion MNIST labels.</p> In\u00a0[7]: Copied! <pre>plt.imshow(X_ood[0:1].reshape(28,28), cmap=\"gray\")\nplt.show()\nprint('Predictive probabilities:')\nprint(scipy.special.softmax(model_orig(X_ood[0:1]).detach().numpy(), axis=1))\n</pre> plt.imshow(X_ood[0:1].reshape(28,28), cmap=\"gray\") plt.show() print('Predictive probabilities:') print(scipy.special.softmax(model_orig(X_ood[0:1]).detach().numpy(), axis=1)) <pre>Predictive probabilities:\n[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n</pre> <p>Seeing the limitations of the original model, we will now freeze all but the output layer and wrap the model with two different equine models.</p> In\u00a0[8]: Copied! <pre>model_GP = eq.EquineGP(EmbeddingModel(model_orig.conv1.weight, \n                                   model_orig.conv2.weight, \n                                   model_orig.fc1.weight, \n                                   model_orig.fc2.weight), \n                    emb_out_dim=10, num_classes = 10)\n</pre> model_GP = eq.EquineGP(EmbeddingModel(model_orig.conv1.weight,                                     model_orig.conv2.weight,                                     model_orig.fc1.weight,                                     model_orig.fc2.weight),                      emb_out_dim=10, num_classes = 10) <p>We now train for a few more epochs to fine tune the last layer of the original model and learn the parameters in the Gaussian Process layer.</p> In\u00a0[9]: Copied! <pre>loss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(\n        model_GP.model.parameters(),\n        lr=0.001,\n        momentum=0.9,\n        weight_decay=0.0,\n    )\nres_GP = model_GP.train_model(TensorDataset(X_train, Y_train), loss_fn, optimizer, 5, vis_support=True)\n</pre> loss_fn = torch.nn.CrossEntropyLoss() optimizer = torch.optim.SGD(         model_GP.model.parameters(),         lr=0.001,         momentum=0.9,         weight_decay=0.0,     ) res_GP = model_GP.train_model(TensorDataset(X_train, Y_train), loss_fn, optimizer, 5, vis_support=True) <pre>  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [01:18&lt;00:00, 15.62s/it]\n</pre> <p>We now compute the test accuracy and out of distribution results to compare with the original model.</p> In\u00a0[10]: Copied! <pre>oods_in_dist = []\npredictions = []\ntrue_labels = []\nfor i, (xs, labels) in enumerate(testloader):\n    y_pred = model_GP.predict(xs)\n    classes = y_pred.classes.detach().numpy()\n    oods = y_pred.ood_scores.detach().numpy()\n    oods_in_dist.extend(list(oods))\n    predictions.extend(list(np.argmax(classes, axis=1)))\n    true_labels.extend(list(labels))\npredictions = np.array(predictions)\ntrue_labels = np.array(true_labels)\nprint('Model accuracy on test set: {:.3f}'.format(np.mean(predictions == true_labels)))\n    \noods_out_dist = []\nfor i, (xs, labels) in enumerate(oodloader):\n    y_pred = model_GP.predict(xs)\n    oods = y_pred.ood_scores.detach().numpy()\n    oods_out_dist.extend(list(oods))\n    \nplt.hist(oods_in_dist,bins=np.linspace(0,1,21),alpha=0.5, label='In Distribution')\nplt.hist(oods_out_dist,bins=np.linspace(0,1,21),alpha=0.5, label='Out of Distribution')\nplt.xlabel('OOD Score')\nplt.ylabel('Count')\nplt.legend()\nplt.show()\nroc = roc_auc_score(np.hstack((np.ones_like(oods_out_dist),np.zeros_like(oods_in_dist))),\n              oods_out_dist+oods_in_dist)\nprint('AUROC for detecting out of distribution examples: {:.3f}'.format(roc))\n</pre> oods_in_dist = [] predictions = [] true_labels = [] for i, (xs, labels) in enumerate(testloader):     y_pred = model_GP.predict(xs)     classes = y_pred.classes.detach().numpy()     oods = y_pred.ood_scores.detach().numpy()     oods_in_dist.extend(list(oods))     predictions.extend(list(np.argmax(classes, axis=1)))     true_labels.extend(list(labels)) predictions = np.array(predictions) true_labels = np.array(true_labels) print('Model accuracy on test set: {:.3f}'.format(np.mean(predictions == true_labels)))      oods_out_dist = [] for i, (xs, labels) in enumerate(oodloader):     y_pred = model_GP.predict(xs)     oods = y_pred.ood_scores.detach().numpy()     oods_out_dist.extend(list(oods))      plt.hist(oods_in_dist,bins=np.linspace(0,1,21),alpha=0.5, label='In Distribution') plt.hist(oods_out_dist,bins=np.linspace(0,1,21),alpha=0.5, label='Out of Distribution') plt.xlabel('OOD Score') plt.ylabel('Count') plt.legend() plt.show() roc = roc_auc_score(np.hstack((np.ones_like(oods_out_dist),np.zeros_like(oods_in_dist))),               oods_out_dist+oods_in_dist) print('AUROC for detecting out of distribution examples: {:.3f}'.format(roc)) <pre>Model accuracy on test set: 0.896\n</pre> <pre>AUROC for detecting out of distribution examples: 0.875\n</pre> <p>The EquineGP model clearly does a much better job of separating the in distribution and out of distribution data.  Returning to the specific example below, the EquineGP model outputs an almost uniform distribution of predictive probabilities, which is appropriate since the example is unlike data that the model was trained on.  The EquineGP out of distribution score is the entropy of the probabilities scaled to between 0 and 1 and is computed internally.</p> In\u00a0[11]: Copied! <pre>plt.imshow(X_ood[0:1].reshape(28,28), cmap=\"gray\")\nplt.show()\nprint('Predictive probabilities: {}'.format(scipy.special.softmax(model_GP(X_ood[0:1]).detach().numpy(), axis=1)[0]))\nprint('Out of distribution score: {}'.format(model_GP.predict(X_ood[0:1]).ood_scores.detach().numpy()))\n</pre> plt.imshow(X_ood[0:1].reshape(28,28), cmap=\"gray\") plt.show() print('Predictive probabilities: {}'.format(scipy.special.softmax(model_GP(X_ood[0:1]).detach().numpy(), axis=1)[0])) print('Out of distribution score: {}'.format(model_GP.predict(X_ood[0:1]).ood_scores.detach().numpy())) <pre>Predictive probabilities: [0.09750234 0.05757334 0.06371779 0.04375702 0.04340108 0.34525907\n 0.07057668 0.10528837 0.11296965 0.05995459]\nOut of distribution score: [0.8886502]\n</pre> In\u00a0[12]: Copied! <pre>model_Proto = eq.equine_protonet.EquineProtonet(EmbeddingModel(model_orig.conv1.weight, \n                                                         model_orig.conv2.weight, \n                                                         model_orig.fc1.weight, \n                                                         model_orig.fc2.weight), \n                                                emb_out_dim=10, cov_type=eq.CovType.DIAGONAL, use_temperature=True, relative_mahal=False)\n</pre> model_Proto = eq.equine_protonet.EquineProtonet(EmbeddingModel(model_orig.conv1.weight,                                                           model_orig.conv2.weight,                                                           model_orig.fc1.weight,                                                           model_orig.fc2.weight),                                                  emb_out_dim=10, cov_type=eq.CovType.DIAGONAL, use_temperature=True, relative_mahal=False) <p>To adapt to the new output, we fine tune the last layer.</p> In\u00a0[13]: Copied! <pre>res_Proto = model_Proto.train_model(TensorDataset(X_train, Y_train), num_episodes=3000, \n                        support_size=10, \n                        way=10, \n                        episode_size=1000)\n</pre> res_Proto = model_Proto.train_model(TensorDataset(X_train, Y_train), num_episodes=3000,                          support_size=10,                          way=10,                          episode_size=1000) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3000/3000 [13:28&lt;00:00,  3.71it/s]\n</pre> <p>We now compute the test accuracy and out of distribution results to compare with the original model.</p> In\u00a0[14]: Copied! <pre>oods_out_dist = model_Proto.predict(X_ood).ood_scores\noods_out_dist = oods_out_dist.detach().numpy()\noods_in_dist = model_Proto.predict(X_test).ood_scores\noods_in_dist = oods_in_dist.detach().numpy()\n\npredictions = np.argmax(model_Proto.predict(X_test).classes.detach().numpy(), axis=1)\nprint('Model accuracy on test set: {0:.3f}'.format(np.mean(predictions == Y_test.detach().numpy())))\n\nplt.hist(oods_in_dist,bins=np.linspace(0,1,21),alpha=0.5, label='In Distribution')\nplt.hist(oods_out_dist,bins=np.linspace(0,1,21),alpha=0.5, label='Out of Distribution')\nplt.xlabel('OOD Score')\nplt.ylabel('Count')\nplt.legend()\nplt.show()\n\nroc = roc_auc_score(np.hstack((np.ones_like(oods_out_dist),np.zeros_like(oods_in_dist))),\n              list(oods_out_dist)+list(oods_in_dist))\nprint('AUROC for detecting out of distribution examples: {0:.3f}'.format(roc))\n</pre> oods_out_dist = model_Proto.predict(X_ood).ood_scores oods_out_dist = oods_out_dist.detach().numpy() oods_in_dist = model_Proto.predict(X_test).ood_scores oods_in_dist = oods_in_dist.detach().numpy()  predictions = np.argmax(model_Proto.predict(X_test).classes.detach().numpy(), axis=1) print('Model accuracy on test set: {0:.3f}'.format(np.mean(predictions == Y_test.detach().numpy())))  plt.hist(oods_in_dist,bins=np.linspace(0,1,21),alpha=0.5, label='In Distribution') plt.hist(oods_out_dist,bins=np.linspace(0,1,21),alpha=0.5, label='Out of Distribution') plt.xlabel('OOD Score') plt.ylabel('Count') plt.legend() plt.show()  roc = roc_auc_score(np.hstack((np.ones_like(oods_out_dist),np.zeros_like(oods_in_dist))),               list(oods_out_dist)+list(oods_in_dist)) print('AUROC for detecting out of distribution examples: {0:.3f}'.format(roc)) <pre>Model accuracy on test set: 0.876\n</pre> <pre>AUROC for detecting out of distribution examples: 0.925\n</pre> <p>The protonet also does a good job of separating in distribution and out of distribution data, though its accuracy is lower than the original model for the Gaussian Process model.  The OOD score produced by the protonet is based on the distance to a representation of the closest class, rather than on the entropy of predictive probabilities.  One minus the OOD score of a particular example can be interpreted as the probability of observing an in distribution example that is further from its closest class representation than the example point.  As a result, the ood scores for the in distribution data roughly follow a uniform distribution.</p> <p>Below, we see that the out out of distribution example receives a high OOD score.</p> In\u00a0[15]: Copied! <pre>plt.imshow(X_ood[0:1].reshape(28,28), cmap=\"gray\")\nplt.show()\nprint('Out of distribution score:')\nprint(model_Proto.predict(X_ood[0:1]).ood_scores.detach().numpy())\n</pre> plt.imshow(X_ood[0:1].reshape(28,28), cmap=\"gray\") plt.show() print('Out of distribution score:') print(model_Proto.predict(X_ood[0:1]).ood_scores.detach().numpy()) <pre>Out of distribution score:\n[0.8480285]\n</pre> In\u00a0[16]: Copied! <pre># Save out the GP and Protonet models for visualization in the web-app\nmodel_GP.save(\"vis_MNIST_GP.eq\")\nmodel_Proto.save(\"vis_MNIST_proto.eq\")\n</pre> # Save out the GP and Protonet models for visualization in the web-app model_GP.save(\"vis_MNIST_GP.eq\") model_Proto.save(\"vis_MNIST_proto.eq\") In\u00a0[21]: Copied! <pre># Save out some randomized datasets to load into the web-app\nidxs = torch.randperm(X_test.size(0))[:50]\nsome_fashion_x = X_test[idxs]\nsome_fashion_y = Y_test[idxs]\ntorch.save(TensorDataset(some_fashion_x, some_fashion_y), \"some_fashion.pt\")\n\nidxs = torch.randperm(X_ood.size(0))[:50]\nsome_digits_x = X_ood[idxs]\nsome_digits_y = X_ood[idxs]\ntorch.save(TensorDataset(some_digits_x, some_digits_y), \"some_digits.pt\")\n</pre> # Save out some randomized datasets to load into the web-app idxs = torch.randperm(X_test.size(0))[:50] some_fashion_x = X_test[idxs] some_fashion_y = Y_test[idxs] torch.save(TensorDataset(some_fashion_x, some_fashion_y), \"some_fashion.pt\")  idxs = torch.randperm(X_ood.size(0))[:50] some_digits_x = X_ood[idxs] some_digits_y = X_ood[idxs] torch.save(TensorDataset(some_digits_x, some_digits_y), \"some_digits.pt\")"},{"location":"example_notebooks/MNIST_OOD_detection/#equine-image-classification-example","title":"EQUINE Image Classification Example\u00b6","text":"<p>This notebook walks through a simple application of a Neural Network trained on a vision task -- predicting a clothing article in the FashionMNIST dataset -- as applied to image data from that and from regular MNIST, a handwritten digit dataset. In this, we load the datasets, train a model, wrap the model with two EQUINE architectures, and demonstrate out-of-distribution performance.</p> <p>This notebook requires some extra dependencies to run. You can uncomment the below cell to install them into your local environment.</p>"},{"location":"example_notebooks/MNIST_OOD_detection/#1-load-mnist-and-fashionmnist-datasets","title":"1. Load MNIST and FashionMNIST Datasets\u00b6","text":""},{"location":"example_notebooks/MNIST_OOD_detection/#2-create-embedding-model","title":"2. Create Embedding Model\u00b6","text":"<p>We define a simple CNN using the LeNet architecture and our embedding model which allows freezing layers if weights are passed during initialization.</p>"},{"location":"example_notebooks/MNIST_OOD_detection/#3-wrap-embedding-model-with-equinegp","title":"3. Wrap embedding model with EquineGP\u00b6","text":"<p>We first create a new EmbeddingModel, passing in the weights for the first four layers that we learned above.  We then wrap that EmbeddingModel in EquineGP.  The resulting model has an extra Gaussian Process \"layer\" on top of the original model.</p>"},{"location":"example_notebooks/MNIST_OOD_detection/#4-wrap-embedding-model-with-equineprotonet","title":"4. Wrap embedding model with EquineProtonet\u00b6","text":"<p>Our second wrapper replaces the softmax output of the original model with a protonet.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/","title":"Toy Problem with Protonet","text":"In\u00a0[1]: Copied! <pre>#!pip install scikit-learn matplotlib\n</pre> #!pip install scikit-learn matplotlib In\u00a0[2]: Copied! <pre># Remove a TQDM warning\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nfrom sklearn.metrics import RocCurveDisplay\nfrom torchmetrics import Accuracy\nimport matplotlib.pyplot as plt\n\n# Helpers from EQUINE\nimport equine as eq\nfrom equine import brier_score, brier_skill_score, expected_calibration_error\n</pre> # Remove a TQDM warning import warnings warnings.filterwarnings('ignore')  import torch from torch.utils.data import TensorDataset, DataLoader, random_split import numpy as np from sklearn.datasets import make_blobs from sklearn.metrics import RocCurveDisplay from torchmetrics import Accuracy import matplotlib.pyplot as plt  # Helpers from EQUINE import equine as eq from equine import brier_score, brier_skill_score, expected_calibration_error In\u00a0[3]: Copied! <pre>num_classes = 4\nexamples_per_class = 500\ntensor_dim = 2\n\nn_samples = examples_per_class * num_classes\ncenters = [ (2,2), (-2,2), (-2,-2), (2,-2), (0,0) ]\nx_list, y_list = make_blobs(n_samples=n_samples, n_features=tensor_dim, \n                            centers=centers, cluster_std=0.75, shuffle=False,random_state=52)\n# Randomize the classes in the middle\nrng = np.random.default_rng(seed=52)\ny_list[(n_samples*4//5):] = rng.integers(4, size=n_samples//5) \nX = torch.FloatTensor(x_list)\nY = torch.tensor(y_list)\n\ndataset = TensorDataset(X,Y)\ntrainset, testset = random_split(dataset, [0.8, 0.2], \n                    generator=torch.Generator().manual_seed(52))\ntrain_x = trainset.dataset.tensors[0][trainset.indices]\ntrain_y = trainset.dataset.tensors[1][trainset.indices]\ntest_x  = testset.dataset.tensors[0][testset.indices]\ntest_y  = testset.dataset.tensors[1][testset.indices]\n\n# Plot the training data\nfor class_i, marker in enumerate([\"x\", \"+\", \".\", \"1\"]):\n    xs = train_x[train_y == class_i]\n    plt.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}')\nplt.legend(loc=\"best\")\nplt.title(\"Class membership of training data\")\n</pre> num_classes = 4 examples_per_class = 500 tensor_dim = 2  n_samples = examples_per_class * num_classes centers = [ (2,2), (-2,2), (-2,-2), (2,-2), (0,0) ] x_list, y_list = make_blobs(n_samples=n_samples, n_features=tensor_dim,                              centers=centers, cluster_std=0.75, shuffle=False,random_state=52) # Randomize the classes in the middle rng = np.random.default_rng(seed=52) y_list[(n_samples*4//5):] = rng.integers(4, size=n_samples//5)  X = torch.FloatTensor(x_list) Y = torch.tensor(y_list)  dataset = TensorDataset(X,Y) trainset, testset = random_split(dataset, [0.8, 0.2],                      generator=torch.Generator().manual_seed(52)) train_x = trainset.dataset.tensors[0][trainset.indices] train_y = trainset.dataset.tensors[1][trainset.indices] test_x  = testset.dataset.tensors[0][testset.indices] test_y  = testset.dataset.tensors[1][testset.indices]  # Plot the training data for class_i, marker in enumerate([\"x\", \"+\", \".\", \"1\"]):     xs = train_x[train_y == class_i]     plt.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}') plt.legend(loc=\"best\") plt.title(\"Class membership of training data\") Out[3]: <pre>Text(0.5, 1.0, 'Class membership of training data')</pre> In\u00a0[4]: Copied! <pre>class EmbeddingModel(torch.nn.Module):\n    def __init__(self):\n        super(EmbeddingModel, self).__init__()\n        self.linear_relu_stack = torch.nn.Sequential(\n            torch.nn.Linear(tensor_dim, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, num_classes)\n        )\n    def forward(self, x):\n        logits = self.linear_relu_stack(x)\n        return logits\n\n# Note that we have left off the very last step (the softmax),\n# so we'll need to apply that after the model to calculate \"probabilities\"\n</pre> class EmbeddingModel(torch.nn.Module):     def __init__(self):         super(EmbeddingModel, self).__init__()         self.linear_relu_stack = torch.nn.Sequential(             torch.nn.Linear(tensor_dim, 16),             torch.nn.ReLU(),             torch.nn.Linear(16, 16),             torch.nn.ReLU(),             torch.nn.Linear(16, 16),             torch.nn.ReLU(),             torch.nn.Linear(16, num_classes)         )     def forward(self, x):         logits = self.linear_relu_stack(x)         return logits  # Note that we have left off the very last step (the softmax), # so we'll need to apply that after the model to calculate \"probabilities\" <p>Next, we train a multiclass classification model in the usual way, using cross entropy loss and the Adam optimizer over 500 epochs (this should only take a few seconds)</p> In\u00a0[5]: Copied! <pre>vanilla_nn = EmbeddingModel()\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vanilla_nn.parameters())\n\ntrainloader = DataLoader(trainset,batch_size=50,shuffle=True)\n\nvanilla_nn.train()\nfor epoch in range(100):\n    epoch_loss = 0.0\n    for i, (xs, labels) in enumerate(trainloader):\n        optimizer.zero_grad()\n        yhats = vanilla_nn(xs)\n        loss = loss_fn(yhats, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    if epoch%50 == 49 or epoch == 0:\n        print(f\"Epoch {epoch+1} has loss {epoch_loss:3.2f}\")\n</pre> vanilla_nn = EmbeddingModel() loss_fn = torch.nn.CrossEntropyLoss() optimizer = torch.optim.Adam(vanilla_nn.parameters())  trainloader = DataLoader(trainset,batch_size=50,shuffle=True)  vanilla_nn.train() for epoch in range(100):     epoch_loss = 0.0     for i, (xs, labels) in enumerate(trainloader):         optimizer.zero_grad()         yhats = vanilla_nn(xs)         loss = loss_fn(yhats, labels)         loss.backward()         optimizer.step()         epoch_loss += loss.item()     if epoch%50 == 49 or epoch == 0:         print(f\"Epoch {epoch+1} has loss {epoch_loss:3.2f}\") <pre>Epoch 1 has loss 43.12\nEpoch 50 has loss 11.02\nEpoch 100 has loss 10.78\n</pre> <p>Before we test the results, here are a few helper functions for printing out metrics like:</p> <ul> <li>Accuracy</li> <li>Expected Calibration Error (ECE). Closest to zero is better, implying the NN output probabilities are well calibrated</li> <li>Brier score, lower is better</li> <li>Brier skill score), as compared to random guessing. Closer to 1.0 is better We also evaluate the NN on a 2-D mesh and plot a contour map of background confidences</li> </ul> In\u00a0[6]: Copied! <pre>def display_2d_test_and_confidence(y_hat, x_test, y_test, Xt, Yt, confidences, title_in=None, num_classes=4):\n    \"\"\"\n    Print out accuracy, expected calibration error, and render a 2-D plot\n\n    :param y_hat: NN predictions on test data\n    :param x_test: X data for testing\n    :param y_test: one-hot encoded ground truth labels\n    :param Xt: meshgrid of x locations\n    :param Yt: meshgrid of y locations\n    :param confidences: 2D torch tensor of confidences (scores between 0 and 1)\n    :param title_in: Optional title for plot\n    \"\"\"\n    # Plot class confidences on countourf and overlay test data predictions \n    y_out = torch.argmax(y_hat,1)\n    fig, ax = plt.subplots()\n    cf = ax.contourf(Xt.numpy(), Yt.numpy(), torch.reshape(confidences, [len(Xt),len(Yt)]), cmap=plt.cm.bone)\n    fig.colorbar(cf, ax=ax)\n    wrong_xs = torch.Tensor()\n    markers = [\"1\", \"+\", \".\", \"o\"] # 4-class default\n    if num_classes == 5:\n        markers = [\"1\", \"+\", \".\", \"o\", \"2\"] \n    for class_i, marker in enumerate(markers):\n        xs = x_test[(y_out == class_i) &amp; (y_test == class_i)]\n        wxs = x_test[(y_out == class_i) &amp; (y_test != class_i)]\n        wrong_xs = torch.cat((wrong_xs, wxs),0)\n        ax.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}')\n    ax.scatter(wrong_xs[:,0], wrong_xs[:,1], marker=\"x\", label=\"Incorrect\")\n    ax.legend()\n\n    title = title_in\n    if not title_in:\n        title = \"NN Test Predictions and Class Confidence\"\n    plt.title(title)\n\n\ndef print_metrics(y_hat, y_test, num_classes=4):\n    \"\"\"\n    Print out accuracy, expected calibration error, and render a 2-D plot\n\n    :param y_hat: NN predictions on test data\n    :param y_test: one-hot encoded ground truth labels\n    :param confidences: 2D torch tensor of confidences (scores between 0 and 1)\n    \"\"\"\n    # Compute accuracy and ECE\n    accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1)\n\n    y_out = torch.argmax(y_hat,1)\n    acc = accuracy(y_out, y_test)\n    print(f\"NN accuracy is {acc:3.2f}\")\n    \n    ece = expected_calibration_error(y_hat, y_test)\n    print(f\"NN ECE is: {ece:3.2e}\")\n \n    bs = brier_score(y_hat, y_test)\n    print(f\"Brier score is: {bs:3.2e}\")\n\n    bss = brier_skill_score(y_hat, y_test)\n    print(f\"Brier skill score is: {bss:3.2f}\")\n</pre> def display_2d_test_and_confidence(y_hat, x_test, y_test, Xt, Yt, confidences, title_in=None, num_classes=4):     \"\"\"     Print out accuracy, expected calibration error, and render a 2-D plot      :param y_hat: NN predictions on test data     :param x_test: X data for testing     :param y_test: one-hot encoded ground truth labels     :param Xt: meshgrid of x locations     :param Yt: meshgrid of y locations     :param confidences: 2D torch tensor of confidences (scores between 0 and 1)     :param title_in: Optional title for plot     \"\"\"     # Plot class confidences on countourf and overlay test data predictions      y_out = torch.argmax(y_hat,1)     fig, ax = plt.subplots()     cf = ax.contourf(Xt.numpy(), Yt.numpy(), torch.reshape(confidences, [len(Xt),len(Yt)]), cmap=plt.cm.bone)     fig.colorbar(cf, ax=ax)     wrong_xs = torch.Tensor()     markers = [\"1\", \"+\", \".\", \"o\"] # 4-class default     if num_classes == 5:         markers = [\"1\", \"+\", \".\", \"o\", \"2\"]      for class_i, marker in enumerate(markers):         xs = x_test[(y_out == class_i) &amp; (y_test == class_i)]         wxs = x_test[(y_out == class_i) &amp; (y_test != class_i)]         wrong_xs = torch.cat((wrong_xs, wxs),0)         ax.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}')     ax.scatter(wrong_xs[:,0], wrong_xs[:,1], marker=\"x\", label=\"Incorrect\")     ax.legend()      title = title_in     if not title_in:         title = \"NN Test Predictions and Class Confidence\"     plt.title(title)   def print_metrics(y_hat, y_test, num_classes=4):     \"\"\"     Print out accuracy, expected calibration error, and render a 2-D plot      :param y_hat: NN predictions on test data     :param y_test: one-hot encoded ground truth labels     :param confidences: 2D torch tensor of confidences (scores between 0 and 1)     \"\"\"     # Compute accuracy and ECE     accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1)      y_out = torch.argmax(y_hat,1)     acc = accuracy(y_out, y_test)     print(f\"NN accuracy is {acc:3.2f}\")          ece = expected_calibration_error(y_hat, y_test)     print(f\"NN ECE is: {ece:3.2e}\")       bs = brier_score(y_hat, y_test)     print(f\"Brier score is: {bs:3.2e}\")      bss = brier_skill_score(y_hat, y_test)     print(f\"Brier skill score is: {bss:3.2f}\")  <p>Below we see that the vanilla neural network does fairly well on the test data for this problem, acheiving good accuracy, reasonably low ECE, and much better skill than random guessing. However, the predictive confidences remain high even far from the training data.</p> In\u00a0[7]: Copied! <pre>vanilla_nn.eval()\n# Compute results on held-out test data\nvanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(test_x))\n\n# Compute confidence scores on a test grid\nbbox = 8 \nXt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox,steps=100), \n                        torch.linspace(-bbox,bbox,steps=100),\n                        indexing='xy')\nXs = torch.cat(tuple(torch.dstack((Xt,Yt))))\nvnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs))\nvnn_conf = torch.max(vnn_results_grid,1).values.detach()\n\n# Evaluate the results\nprint_metrics(vanilla_results, test_y)\ndisplay_2d_test_and_confidence(vanilla_results, test_x, test_y, Xt, Yt, vnn_conf,\n                            \"Vanilla NN Test Predictions and Class Confidence\" )\n</pre> vanilla_nn.eval() # Compute results on held-out test data vanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(test_x))  # Compute confidence scores on a test grid bbox = 8  Xt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox,steps=100),                          torch.linspace(-bbox,bbox,steps=100),                         indexing='xy') Xs = torch.cat(tuple(torch.dstack((Xt,Yt)))) vnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs)) vnn_conf = torch.max(vnn_results_grid,1).values.detach()  # Evaluate the results print_metrics(vanilla_results, test_y) display_2d_test_and_confidence(vanilla_results, test_x, test_y, Xt, Yt, vnn_conf,                             \"Vanilla NN Test Predictions and Class Confidence\" ) <pre>NN accuracy is 0.83\nNN ECE is: 3.20e-02\nBrier score is: 1.88e-01\nBrier skill score is: 0.75\n</pre> In\u00a0[8]: Copied! <pre># Load weights from the trained model\nsd = vanilla_nn.state_dict()\nem = EmbeddingModel()\nem.load_state_dict(sd)\n\n# Pull out the feature embedding\nall_layers = list(vanilla_nn.children())\nembedding_layers = all_layers[0][:-1] # Remove the last layer\nembedding_model = torch.nn.Sequential(*embedding_layers) # Rebuild the NN\n\n# Create the EQUINE model, support examples, and pointers to those examples \nmodel = eq.EquineProtonet(embedding_model, emb_out_dim=16, use_temperature=True)\n#model = eq.EquineProtonet(EmbeddingModel(), emb_out_dim=4) # Uncomment to restart \"from scratch\"\n</pre> # Load weights from the trained model sd = vanilla_nn.state_dict() em = EmbeddingModel() em.load_state_dict(sd)  # Pull out the feature embedding all_layers = list(vanilla_nn.children()) embedding_layers = all_layers[0][:-1] # Remove the last layer embedding_model = torch.nn.Sequential(*embedding_layers) # Rebuild the NN  # Create the EQUINE model, support examples, and pointers to those examples  model = eq.EquineProtonet(embedding_model, emb_out_dim=16, use_temperature=True) #model = eq.EquineProtonet(EmbeddingModel(), emb_out_dim=4) # Uncomment to restart \"from scratch\" In\u00a0[9]: Copied! <pre>_ = model.train_model(TensorDataset(train_x,train_y),\n                    way=4,             # Number of classes to train each episode\n                    support_size=20,           # Number of support examples per class each episode\n                    num_episodes=1000, # Number of episodes (like epochs)\n                    episode_size=100)  # Number training points selected per episode (like batches)\n</pre> _ = model.train_model(TensorDataset(train_x,train_y),                     way=4,             # Number of classes to train each episode                     support_size=20,           # Number of support examples per class each episode                     num_episodes=1000, # Number of episodes (like epochs)                     episode_size=100)  # Number training points selected per episode (like batches) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:04&lt;00:00, 239.47it/s]\n</pre> In\u00a0[10]: Copied! <pre># Evaluate for the held-out test data and on the 2-D mesh\nmodel.eval()\nproto_results=model.predict(test_x)\nyhat = proto_results.classes\n\nproto_grid_results=model.predict(Xs)\ny_conf = torch.max(proto_grid_results.classes,1).values.detach()\nprint_metrics(yhat,test_y)\ndisplay_2d_test_and_confidence(yhat, test_x, test_y, Xt, Yt, y_conf, \"EQUINE Test Predictions and Class Confidence \")\n</pre> # Evaluate for the held-out test data and on the 2-D mesh model.eval() proto_results=model.predict(test_x) yhat = proto_results.classes  proto_grid_results=model.predict(Xs) y_conf = torch.max(proto_grid_results.classes,1).values.detach() print_metrics(yhat,test_y) display_2d_test_and_confidence(yhat, test_x, test_y, Xt, Yt, y_conf, \"EQUINE Test Predictions and Class Confidence \") <pre>NN accuracy is 0.86\nNN ECE is: 5.85e-02\nBrier score is: 2.10e-01\nBrier skill score is: 0.72\n</pre> <p>Here's an example of the OOD scores, which is supposed to indicate that, far away from the training data, the predictions are more likely to be out-of-distribution (scores should approach 1.0),</p> In\u00a0[11]: Copied! <pre>y_ood  = torch.FloatTensor(proto_grid_results.ood_scores)\ndisplay_2d_test_and_confidence(yhat, test_x, test_y, Xt, Yt, y_ood, \"EQUINE Test Predictions and OOD Scores \")\n</pre> y_ood  = torch.FloatTensor(proto_grid_results.ood_scores) display_2d_test_and_confidence(yhat, test_x, test_y, Xt, Yt, y_ood, \"EQUINE Test Predictions and OOD Scores \") In\u00a0[12]: Copied! <pre>new_x, _ = make_blobs(n_samples=100, n_features=tensor_dim, \n                        centers=[[6,0]], cluster_std=0.5, shuffle=False,random_state=52)\nclass4_Xs = torch.FloatTensor(new_x)\nclass4_Ys = 4*torch.ones(len(new_x),dtype=torch.int)    \n\n# Append to existing test data\nood_test_x = torch.cat((test_x, class4_Xs))\nood_test_y = torch.cat((test_y, class4_Ys))\n</pre> new_x, _ = make_blobs(n_samples=100, n_features=tensor_dim,                          centers=[[6,0]], cluster_std=0.5, shuffle=False,random_state=52) class4_Xs = torch.FloatTensor(new_x) class4_Ys = 4*torch.ones(len(new_x),dtype=torch.int)      # Append to existing test data ood_test_x = torch.cat((test_x, class4_Xs)) ood_test_y = torch.cat((test_y, class4_Ys)) <p>Neither the vanilla neural network or the EQUINE network knows \"out of distribution\" cluster, so it's impossible for the networks to correctly predict the new label -- meaning that the cluster appears as a bunch of wrong predictions to the right of the existing test data.</p> In\u00a0[13]: Copied! <pre># Compute new results with appended OOD cluster\nvanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(ood_test_x))\nvnn_conf_pts = torch.max(vanilla_results,1).values.detach()\nvnn_y_classes = torch.argmax(vanilla_results,1)\n\n# Extend the grid to the right a bit to see the new cluster\nbbox = 8 \nXt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox+2,steps=100), \n                        torch.linspace(-bbox,bbox,steps=100),\n                        indexing='xy')\nXs = torch.cat(tuple(torch.dstack((Xt,Yt))))\nvnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs))\nvnn_conf = torch.max(vnn_results_grid,1).values.detach()\n\n# Evaluate the 4-class predictions on the 5-class problem\nnum_res = vanilla_results.size(dim=0)\nzero_col = torch.zeros((num_res,1))\nv5_res = torch.concat((vanilla_results, zero_col),dim=1)\nprint_metrics(v5_res,ood_test_y, num_classes=5)\ndisplay_2d_test_and_confidence(vanilla_results, ood_test_x, ood_test_y, Xt, Yt, vnn_conf,\n                            \"Vanilla NN Test Predictions and Class Confidence\")\n</pre> # Compute new results with appended OOD cluster vanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(ood_test_x)) vnn_conf_pts = torch.max(vanilla_results,1).values.detach() vnn_y_classes = torch.argmax(vanilla_results,1)  # Extend the grid to the right a bit to see the new cluster bbox = 8  Xt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox+2,steps=100),                          torch.linspace(-bbox,bbox,steps=100),                         indexing='xy') Xs = torch.cat(tuple(torch.dstack((Xt,Yt)))) vnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs)) vnn_conf = torch.max(vnn_results_grid,1).values.detach()  # Evaluate the 4-class predictions on the 5-class problem num_res = vanilla_results.size(dim=0) zero_col = torch.zeros((num_res,1)) v5_res = torch.concat((vanilla_results, zero_col),dim=1) print_metrics(v5_res,ood_test_y, num_classes=5) display_2d_test_and_confidence(vanilla_results, ood_test_x, ood_test_y, Xt, Yt, vnn_conf,                             \"Vanilla NN Test Predictions and Class Confidence\") <pre>NN accuracy is 0.68\nNN ECE is: 2.01e-01\nBrier score is: 5.23e-01\nBrier skill score is: 0.35\n</pre> <p>Finally, we illustrate the binary predictive performance on \"correct\" and \"incorrect\" predictions that would come from using the OOD scores to screen out predictions on likely OOD data. To do this, we'll generate a ROC curve using 1-OOD scores (something like an \"in-distribution\" score) as a confidence threshold for EQUINE, and the maximum probability for the vanilla Neural Network.  Note that these ROC curves could be made arbitrarily more unfavorable to the Vanilla Neural Network by adding more OOD test points and/or more OOD data clusters; the point is just to show how EQUINE's <code>ood_scores</code> can be used to filter out predictions on OOD data.</p> In\u00a0[14]: Copied! <pre># Let's see how well the confidence does at figuring ou\nvnn_correct = (vnn_y_classes == ood_test_y)\n\n# Generate results for the EQUINE protonet\nproto_results=model.predict(ood_test_x)\neq_y_classes = torch.argmax(proto_results.classes,1)\neq_correct = (eq_y_classes == ood_test_y)\n\nnum_res = proto_results.classes.size(dim=0)\nzero_col = torch.zeros((num_res,1))\np5_res = torch.concat((proto_results.classes, zero_col),dim=1)\nprint_metrics(p5_res, ood_test_y, num_classes=5)\n\n# Show the performance \nfig, ax = plt.subplots(figsize=(6, 6))\nRocCurveDisplay.from_predictions(eq_correct, 1.0-proto_results.ood_scores, name=\"EQUINE In-Distribution\", ax=ax)\nRocCurveDisplay.from_predictions(vnn_correct, vnn_conf_pts, name=\"Vanilla NN Confidence\", ax=ax)\n</pre> # Let's see how well the confidence does at figuring ou vnn_correct = (vnn_y_classes == ood_test_y)  # Generate results for the EQUINE protonet proto_results=model.predict(ood_test_x) eq_y_classes = torch.argmax(proto_results.classes,1) eq_correct = (eq_y_classes == ood_test_y)  num_res = proto_results.classes.size(dim=0) zero_col = torch.zeros((num_res,1)) p5_res = torch.concat((proto_results.classes, zero_col),dim=1) print_metrics(p5_res, ood_test_y, num_classes=5)  # Show the performance  fig, ax = plt.subplots(figsize=(6, 6)) RocCurveDisplay.from_predictions(eq_correct, 1.0-proto_results.ood_scores, name=\"EQUINE In-Distribution\", ax=ax) RocCurveDisplay.from_predictions(vnn_correct, vnn_conf_pts, name=\"Vanilla NN Confidence\", ax=ax) <pre>NN accuracy is 0.69\nNN ECE is: 2.43e-01\nBrier score is: 5.63e-01\nBrier skill score is: 0.30\n</pre> Out[14]: <pre>&lt;sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7fc61098b310&gt;</pre> In\u00a0[15]: Copied! <pre># Generate some support for the OOD class so as not to overlap with the test data\nnew_x, _ = make_blobs(n_samples=100, n_features=tensor_dim, \n                        centers=[[6,0]], cluster_std=0.5, shuffle=False,random_state=52)\nclass4_Xs = torch.FloatTensor(new_x)\nclass4_Ys = 4*torch.ones(len(new_x),dtype=torch.int) \nood_train_x= torch.cat((train_x, class4_Xs))\nood_train_y = torch.cat((train_y, class4_Ys))\n\n# Randomly pull 30 examples from each class in the training data to use as support and for prototypes\nsupport_size = 30\nnew_support_dict = eq.utils.generate_support(ood_train_x, ood_train_y, \n                    support_size=support_size, selected_labels=list(range(5)))\nsupport_x = torch.concat(tuple(new_support_dict.values()))\nsupport_y = torch.Tensor([support_size*[i] for i in range(5)]).ravel()\n\nmodel.update_support(support_x, support_y, 0.33) # This uses 1/3 of the data to calibrate the OOD scores\n</pre> # Generate some support for the OOD class so as not to overlap with the test data new_x, _ = make_blobs(n_samples=100, n_features=tensor_dim,                          centers=[[6,0]], cluster_std=0.5, shuffle=False,random_state=52) class4_Xs = torch.FloatTensor(new_x) class4_Ys = 4*torch.ones(len(new_x),dtype=torch.int)  ood_train_x= torch.cat((train_x, class4_Xs)) ood_train_y = torch.cat((train_y, class4_Ys))  # Randomly pull 30 examples from each class in the training data to use as support and for prototypes support_size = 30 new_support_dict = eq.utils.generate_support(ood_train_x, ood_train_y,                      support_size=support_size, selected_labels=list(range(5))) support_x = torch.concat(tuple(new_support_dict.values())) support_y = torch.Tensor([support_size*[i] for i in range(5)]).ravel()  model.update_support(support_x, support_y, 0.33) # This uses 1/3 of the data to calibrate the OOD scores <p>Having updated the support, we can now do more predictions without having to retrain.</p> In\u00a0[16]: Copied! <pre>proto_results=model.predict(ood_test_x)\nyhat = proto_results.classes\nproto_grid_results = model.predict(Xs)\ny_conf = torch.max(proto_grid_results.classes,1).values.detach()\nprint_metrics(yhat, ood_test_y, num_classes=5)\ndisplay_2d_test_and_confidence(yhat, ood_test_x, ood_test_y, Xt, Yt, y_conf, \"EQUINE Test Predictions and Class Confidence\", num_classes=5)\n</pre> proto_results=model.predict(ood_test_x) yhat = proto_results.classes proto_grid_results = model.predict(Xs) y_conf = torch.max(proto_grid_results.classes,1).values.detach() print_metrics(yhat, ood_test_y, num_classes=5) display_2d_test_and_confidence(yhat, ood_test_x, ood_test_y, Xt, Yt, y_conf, \"EQUINE Test Predictions and Class Confidence\", num_classes=5) <pre>NN accuracy is 0.86\nNN ECE is: 8.51e-02\nBrier score is: 2.06e-01\nBrier skill score is: 0.74\n</pre> <p>The new class has shifted the class confidence boundaries. Furthermore, the OOD scores for the new class are now lower:</p> In\u00a0[17]: Copied! <pre>y_ood  = torch.FloatTensor(proto_grid_results.ood_scores)\ndisplay_2d_test_and_confidence(yhat, ood_test_x, ood_test_y, Xt, Yt, y_ood, \"EQUINE Test Predictions and OOD Scores\",num_classes=5)\n</pre> y_ood  = torch.FloatTensor(proto_grid_results.ood_scores) display_2d_test_and_confidence(yhat, ood_test_x, ood_test_y, Xt, Yt, y_ood, \"EQUINE Test Predictions and OOD Scores\",num_classes=5)"},{"location":"example_notebooks/toy_example_EquineProtonet/#equine-protonet-toy-problem-example","title":"EQUINE Protonet Toy Problem Example\u00b6","text":"<p>The intent of this example notebook is to provide an easy-to-visualize, 2-D, toy problem that illustrates both the general problem of uncertainty quantification in neural network classification as well as to show how EQUINE can be used to make predictions more robust in the face of uncertainty. Here, we use the <code>EquineProtonet</code> class to demonstrate the ideas, which appends an extra layer to a provided neural network embedding model and trains on distances to average class representations (prototypes) in the same way that protonets do, with the exception that we also add an out-of-distribution score.</p> <p>This notebook requires some extra dependencies to run. You can uncomment the below cell to install them into your local environment.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/#generate-toy-dataset","title":"Generate Toy Dataset\u00b6","text":"<p>This dataset uses <code>make_blobs</code> from scikit-learn, placing 4 clusters in each quadrant (for 4 classes), along with a middle cluster with random class memberships.</p> <p>In this toy problem, the accuracy should not be much higher than 80%, since the middle class memberships are essentially random.</p> <p>Additionally, the class confidence in the middle of the problem should hover around 25% for the same reason.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/#define-our-embedding-model","title":"Define our embedding model\u00b6","text":"<p>Here we define a \"usual\" neural network architecture, leaving off only the softmax in the forward function.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/#wrap-the-model-using-equine","title":"Wrap the model using EQUINE\u00b6","text":"<p>In order to have more reliable confidence overlays, and to have any chance of estimating an out-of-distribution score for each inference, we need to evaluate distances in the penultimate layer of the network. EQUINE provides a way to take an existing model and data, add layer(s) for distance embedding, and output new quantities for uncertainty quantification.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/#retrain-or-fine-tune-equine-model-with-episodic-training","title":"Retrain or fine-tune EQUINE model with episodic training\u00b6","text":"<p>To train a model, we use <code>train_episodes</code>, which has options explained below.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/#evaluate-the-results","title":"Evaluate the results\u00b6","text":"<p>EQUINE introduces the \"predict()\" API to return predictions with the probability contexts, including</p> <ul> <li>classes:    the class probabilities</li> <li>ood_scores: the out-of-distribution scores as well as other variables</li> </ul>"},{"location":"example_notebooks/toy_example_EquineProtonet/#adding-out-of-distribution-data","title":"Adding Out-Of-Distribution Data\u00b6","text":"<p>In this section, we add a new cluster of data just to the right of the existing data to showcase how one could use the \"ood_score\" attribute of <code>EquineOutput</code>.</p>"},{"location":"example_notebooks/toy_example_EquineProtonet/#bonus-protonet-result-few-shot-learning","title":"Bonus Protonet result (few-shot learning)\u00b6","text":"<p>Protonets are able to add additional classes without retraining! We next show how the OOD scores and confidences change when this happens. In the below cells, we generate some new \"support\" examples by randomly sampling 30 examples of each class, including the new class, and then using that to update the EquineProtonet model.</p>"},{"location":"example_notebooks/toy_example_GP/","title":"Toy Problem with GP","text":"In\u00a0[1]: Copied! <pre>#!pip install scikit-learn matplotlib\n</pre> #!pip install scikit-learn matplotlib In\u00a0[2]: Copied! <pre># Remove a TQDM warning\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nfrom sklearn.metrics import RocCurveDisplay\nfrom torchmetrics import Accuracy\nimport matplotlib.pyplot as plt\n\n# Helpers from EQUINE\nimport equine as eq\nfrom equine import brier_score, brier_skill_score, expected_calibration_error\n</pre> # Remove a TQDM warning import warnings warnings.filterwarnings('ignore')  import torch import numpy as np from sklearn.datasets import make_blobs from sklearn.metrics import RocCurveDisplay from torchmetrics import Accuracy import matplotlib.pyplot as plt  # Helpers from EQUINE import equine as eq from equine import brier_score, brier_skill_score, expected_calibration_error In\u00a0[3]: Copied! <pre>num_classes = 4\nexamples_per_class = 500\ntensor_dim = 2\n\nn_samples = examples_per_class * num_classes\ncenters = [ (2,2), (-2,2), (-2,-2), (2,-2), (0,0) ]\nx_list, y_list = make_blobs(n_samples=n_samples, n_features=tensor_dim, \n                            centers=centers, cluster_std=0.75, shuffle=False,random_state=52)\n# Randomize the classes in the middle\nrng = np.random.default_rng(seed=52)\ny_list[(n_samples*4//5):] = rng.integers(4, size=n_samples//5) \nX = torch.FloatTensor(x_list)\nY = torch.tensor(y_list)\n\ndataset = torch.utils.data.TensorDataset(X,Y)\ntrainset, testset = torch.utils.data.random_split(dataset, [0.8, 0.2], \n                    generator=torch.Generator().manual_seed(52))\ntrain_x = trainset.dataset.tensors[0][trainset.indices]\ntrain_y = trainset.dataset.tensors[1][trainset.indices]\ntest_x  = testset.dataset.tensors[0][testset.indices]\ntest_y  = testset.dataset.tensors[1][testset.indices]\n\n# Plot the training data\nfor class_i, marker in enumerate([\"x\", \"+\", \".\", \"1\"]):\n    xs = train_x[train_y == class_i]\n    plt.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}')\nplt.legend(loc=\"best\")\nplt.title(\"Class membership of training data\")\n</pre> num_classes = 4 examples_per_class = 500 tensor_dim = 2  n_samples = examples_per_class * num_classes centers = [ (2,2), (-2,2), (-2,-2), (2,-2), (0,0) ] x_list, y_list = make_blobs(n_samples=n_samples, n_features=tensor_dim,                              centers=centers, cluster_std=0.75, shuffle=False,random_state=52) # Randomize the classes in the middle rng = np.random.default_rng(seed=52) y_list[(n_samples*4//5):] = rng.integers(4, size=n_samples//5)  X = torch.FloatTensor(x_list) Y = torch.tensor(y_list)  dataset = torch.utils.data.TensorDataset(X,Y) trainset, testset = torch.utils.data.random_split(dataset, [0.8, 0.2],                      generator=torch.Generator().manual_seed(52)) train_x = trainset.dataset.tensors[0][trainset.indices] train_y = trainset.dataset.tensors[1][trainset.indices] test_x  = testset.dataset.tensors[0][testset.indices] test_y  = testset.dataset.tensors[1][testset.indices]  # Plot the training data for class_i, marker in enumerate([\"x\", \"+\", \".\", \"1\"]):     xs = train_x[train_y == class_i]     plt.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}') plt.legend(loc=\"best\") plt.title(\"Class membership of training data\") Out[3]: <pre>Text(0.5, 1.0, 'Class membership of training data')</pre> In\u00a0[4]: Copied! <pre>class EmbeddingModel(torch.nn.Module):\n    def __init__(self):\n        super(EmbeddingModel, self).__init__()\n        self.linear_relu_stack = torch.nn.Sequential(\n            torch.nn.Linear(tensor_dim, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, num_classes)\n        )\n    def forward(self, x):\n        logits = self.linear_relu_stack(x)\n        return logits\n\n# Note that we have left off the very last step (the softmax),\n# so we'll need to apply that after the model to calculate \"probabilities\"\n</pre> class EmbeddingModel(torch.nn.Module):     def __init__(self):         super(EmbeddingModel, self).__init__()         self.linear_relu_stack = torch.nn.Sequential(             torch.nn.Linear(tensor_dim, 16),             torch.nn.ReLU(),             torch.nn.Linear(16, 16),             torch.nn.ReLU(),             torch.nn.Linear(16, 16),             torch.nn.ReLU(),             torch.nn.Linear(16, num_classes)         )     def forward(self, x):         logits = self.linear_relu_stack(x)         return logits  # Note that we have left off the very last step (the softmax), # so we'll need to apply that after the model to calculate \"probabilities\" <p>Next, we train a multiclass classification model in the usual way, using cross entropy loss and the Adam optimizer over 100 epochs (this should only take a few seconds, even on a CPU)</p> In\u00a0[5]: Copied! <pre># Set up a pytorch network for training\nvanilla_nn = EmbeddingModel()\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vanilla_nn.parameters())\n\n# Prepare the input data\ntrainloader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True, drop_last=True)\n\n# Train the model\nvanilla_nn.train()\nfor epoch in range(100):\n    epoch_loss = 0.0\n    for i, (xs, labels) in enumerate(trainloader):\n        optimizer.zero_grad()\n        yhats = vanilla_nn(xs)\n        loss = loss_fn(yhats, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    if epoch%50 == 49 or epoch == 0:\n        print(f\"Epoch {epoch+1} has loss {epoch_loss:3.2f}\")\n</pre> # Set up a pytorch network for training vanilla_nn = EmbeddingModel() loss_fn = torch.nn.CrossEntropyLoss() optimizer = torch.optim.Adam(vanilla_nn.parameters())  # Prepare the input data trainloader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True, drop_last=True)  # Train the model vanilla_nn.train() for epoch in range(100):     epoch_loss = 0.0     for i, (xs, labels) in enumerate(trainloader):         optimizer.zero_grad()         yhats = vanilla_nn(xs)         loss = loss_fn(yhats, labels)         loss.backward()         optimizer.step()         epoch_loss += loss.item()     if epoch%50 == 49 or epoch == 0:         print(f\"Epoch {epoch+1} has loss {epoch_loss:3.2f}\") <pre>Epoch 1 has loss 32.79\nEpoch 50 has loss 8.59\nEpoch 100 has loss 8.39\n</pre> <p>Before we test the results, here are a few helper functions for printing out metrics like:</p> <ul> <li>Accuracy</li> <li>Expected Calibration Error (ECE). Closest to zero is better, implying well-calibrated NN output probabilities</li> <li>Brier score, lower is better</li> <li>Brier skill score), as compared to random guessing (closer to 1.0 is better)</li> </ul> <p>We also evaluate the NN on a 2-D mesh and plot a contour map of background confidences.</p> In\u00a0[6]: Copied! <pre>def display_2d_test_and_confidence(y_hat, x_test, y_test, Xt, Yt, confidences, title_in=None):\n    \"\"\"\n    Display test points as a scatter plot against a contour plot of confidence values\n\n    :param y_hat: NN predictions on test data\n    :param x_test: X data for testing\n    :param y_test: one-hot encoded ground truth labels\n    :param Xt: meshgrid of Cartesian X locations for contour plot\n    :param Yt: meshgrid of Cartesian Y locations for contour plot\n    :param confidences: 2D torch tensor of confidences (scores between 0 and 1)\n    :param title_in: Optional title for plot\n    \"\"\"\n    # Plot class confidences on countourf and overlay test data predictions \n    y_out = torch.argmax(y_hat,1)\n    fig, ax = plt.subplots()\n    cf = ax.contourf(Xt.numpy(), Yt.numpy(), torch.reshape(confidences, [len(Xt),len(Yt)]), cmap=plt.cm.bone)\n    fig.colorbar(cf, ax=ax)\n    wrong_xs = torch.Tensor()\n    for class_i, marker in enumerate([\"1\", \"+\", \".\", \"o\"]):\n        xs = x_test[(y_out == class_i) &amp; (y_test == class_i)]\n        wxs = x_test[(y_out == class_i) &amp; (y_test != class_i)]\n        wrong_xs = torch.cat((wrong_xs, wxs),0)\n        ax.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}')\n    ax.scatter(wrong_xs[:,0], wrong_xs[:,1], marker=\"x\", label=\"Incorrect\")\n    ax.legend()\n\n    title = title_in\n    if not title_in:\n        title = \"NN Test Predictions and Class Confidence\"\n    plt.title(title)\n\n\ndef print_metrics(y_hat, y_test, num_classes=4):\n    \"\"\"\n    Print out accuracy, expected calibration error, and render a 2-D plot\n\n    :param y_hat: NN predictions on test data\n    :param y_test: one-hot encoded ground truth labels\n    :param confidences: 2D torch tensor of confidences (scores between 0 and 1)\n    \"\"\"\n    # Compute accuracy and ECE\n    accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1)\n\n    y_out = torch.argmax(y_hat,1)\n    acc = accuracy(y_out, y_test)\n    print(f\"NN accuracy is {acc:3.2f}\")\n    \n    ece = expected_calibration_error(y_hat, y_test)\n    print(f\"NN ECE is: {ece:3.2e}\")\n \n    bs = brier_score(y_hat, y_test)\n    print(f\"Brier score is: {bs:3.2e}\")\n\n    bss = brier_skill_score(y_hat, y_test)\n    print(f\"Brier skill score is: {bss:3.2f}\")\n</pre> def display_2d_test_and_confidence(y_hat, x_test, y_test, Xt, Yt, confidences, title_in=None):     \"\"\"     Display test points as a scatter plot against a contour plot of confidence values      :param y_hat: NN predictions on test data     :param x_test: X data for testing     :param y_test: one-hot encoded ground truth labels     :param Xt: meshgrid of Cartesian X locations for contour plot     :param Yt: meshgrid of Cartesian Y locations for contour plot     :param confidences: 2D torch tensor of confidences (scores between 0 and 1)     :param title_in: Optional title for plot     \"\"\"     # Plot class confidences on countourf and overlay test data predictions      y_out = torch.argmax(y_hat,1)     fig, ax = plt.subplots()     cf = ax.contourf(Xt.numpy(), Yt.numpy(), torch.reshape(confidences, [len(Xt),len(Yt)]), cmap=plt.cm.bone)     fig.colorbar(cf, ax=ax)     wrong_xs = torch.Tensor()     for class_i, marker in enumerate([\"1\", \"+\", \".\", \"o\"]):         xs = x_test[(y_out == class_i) &amp; (y_test == class_i)]         wxs = x_test[(y_out == class_i) &amp; (y_test != class_i)]         wrong_xs = torch.cat((wrong_xs, wxs),0)         ax.scatter(xs[:,0], xs[:,1],marker=marker,label=f'Class {class_i}')     ax.scatter(wrong_xs[:,0], wrong_xs[:,1], marker=\"x\", label=\"Incorrect\")     ax.legend()      title = title_in     if not title_in:         title = \"NN Test Predictions and Class Confidence\"     plt.title(title)   def print_metrics(y_hat, y_test, num_classes=4):     \"\"\"     Print out accuracy, expected calibration error, and render a 2-D plot      :param y_hat: NN predictions on test data     :param y_test: one-hot encoded ground truth labels     :param confidences: 2D torch tensor of confidences (scores between 0 and 1)     \"\"\"     # Compute accuracy and ECE     accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1)      y_out = torch.argmax(y_hat,1)     acc = accuracy(y_out, y_test)     print(f\"NN accuracy is {acc:3.2f}\")          ece = expected_calibration_error(y_hat, y_test)     print(f\"NN ECE is: {ece:3.2e}\")       bs = brier_score(y_hat, y_test)     print(f\"Brier score is: {bs:3.2e}\")      bss = brier_skill_score(y_hat, y_test)     print(f\"Brier skill score is: {bss:3.2f}\")  In\u00a0[7]: Copied! <pre>vanilla_nn.eval()\n# Compute results on held-out test data\nvanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(test_x))\n\n# Compute confidence scores on a test grid\nbbox = 8 \nXt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox,steps=100), \n                        torch.linspace(-bbox,bbox,steps=100),\n                        indexing='xy')\nXs = torch.cat(tuple(torch.dstack((Xt,Yt))))\nvnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs))\ny_conf = torch.max(vnn_results_grid,1).values.detach()\n\n# Evaluate the results\nprint_metrics(vanilla_results, test_y)\ndisplay_2d_test_and_confidence(vanilla_results, test_x, test_y, Xt, Yt, y_conf,\n                            \"Vanilla NN Test Predictions and Class Confidence\" )\n</pre> vanilla_nn.eval() # Compute results on held-out test data vanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(test_x))  # Compute confidence scores on a test grid bbox = 8  Xt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox,steps=100),                          torch.linspace(-bbox,bbox,steps=100),                         indexing='xy') Xs = torch.cat(tuple(torch.dstack((Xt,Yt)))) vnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs)) y_conf = torch.max(vnn_results_grid,1).values.detach()  # Evaluate the results print_metrics(vanilla_results, test_y) display_2d_test_and_confidence(vanilla_results, test_x, test_y, Xt, Yt, y_conf,                             \"Vanilla NN Test Predictions and Class Confidence\" ) <pre>NN accuracy is 0.84\nNN ECE is: 3.19e-02\nBrier score is: 1.84e-01\nBrier skill score is: 0.75\n</pre> In\u00a0[8]: Copied! <pre># Pull out the feature embedding\nall_layers = list(vanilla_nn.children())\nembedding_layers = all_layers[0][:-1] # Remove the last layer\nembedding_model = torch.nn.Sequential(*embedding_layers) # Rebuild the NN\n\n# Build an EQUINE object by wrapping the feature embedding\nmodel = eq.EquineGP(embedding_model, emb_out_dim=16, num_classes=num_classes, use_temperature=True)\n</pre> # Pull out the feature embedding all_layers = list(vanilla_nn.children()) embedding_layers = all_layers[0][:-1] # Remove the last layer embedding_model = torch.nn.Sequential(*embedding_layers) # Rebuild the NN  # Build an EQUINE object by wrapping the feature embedding model = eq.EquineGP(embedding_model, emb_out_dim=16, num_classes=num_classes, use_temperature=True) In\u00a0[9]: Copied! <pre># Retrain using the GP -- here we use a convenience function\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\nmodel.train_model(torch.utils.data.TensorDataset(train_x, train_y), loss_fn, optimizer, 50)\n</pre> # Retrain using the GP -- here we use a convenience function loss_fn = torch.nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.parameters()) model.train_model(torch.utils.data.TensorDataset(train_x, train_y), loss_fn, optimizer, 50) <pre>  0%|          | 0/50 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [00:03&lt;00:00, 12.87it/s]\n</pre> Out[9]: <pre>({'numTrainExamples': [{'label': 0, 'numExamples': 360},\n   {'label': 1, 'numExamples': 369},\n   {'label': 2, 'numExamples': 353},\n   {'label': 3, 'numExamples': 358}],\n  'dateTrained': '07/06/2023, 12:02:30',\n  'modelType': 'EquineGP'},\n &lt;torch.utils.data.dataloader.DataLoader at 0x7f93385d3fd0&gt;)</pre> In\u00a0[10]: Copied! <pre># Using the grid points from before, evaluate EquineGP\nres = torch.nn.Softmax(dim=1)(model(test_x)) # Test points\nresults_grid=torch.nn.Softmax(dim=1)(model(Xs)) # Grid points\ny_conf = torch.max(results_grid,1).values.detach()\n\n# Evaluate the results\nprint_metrics(res, test_y)\ndisplay_2d_test_and_confidence(res, test_x, test_y, Xt, Yt, y_conf,\n                            \"EQUINE NN Test Predictions and Confidence\" )\n</pre> # Using the grid points from before, evaluate EquineGP res = torch.nn.Softmax(dim=1)(model(test_x)) # Test points results_grid=torch.nn.Softmax(dim=1)(model(Xs)) # Grid points y_conf = torch.max(results_grid,1).values.detach()  # Evaluate the results print_metrics(res, test_y) display_2d_test_and_confidence(res, test_x, test_y, Xt, Yt, y_conf,                             \"EQUINE NN Test Predictions and Confidence\" )  <pre>NN accuracy is 0.83\nNN ECE is: 6.59e-02\nBrier score is: 2.12e-01\nBrier skill score is: 0.72\n</pre> <p>After wrapping with EQUINE, the class confidences are now more reasonably low (25%, a random guess) away from the input training clusters, as well as fairly uniform within the middle, random cluster. This is because <code>EquineGP</code> explicitly leverages distances in the embedding space. These distances can also be used to calculate a normalized predictive entropy, which can then be forwarded to the user through the <code>predict()</code> method.</p> In\u00a0[11]: Copied! <pre>y_ood = (model.predict(Xs).ood_scores).detach()\n# Evaluate the results\ndisplay_2d_test_and_confidence(res, test_x, test_y, Xt, Yt, y_ood,\n                            \"EQUINE GP Tests and Normalized Predictive Entropy\" )\n</pre> y_ood = (model.predict(Xs).ood_scores).detach() # Evaluate the results display_2d_test_and_confidence(res, test_x, test_y, Xt, Yt, y_ood,                             \"EQUINE GP Tests and Normalized Predictive Entropy\" ) <p>The OOD scores can then be used as a filter to screen out out-of-distribution predictions, as opposed to simply accepting the outputs and confidence values of the original Neural Network. This shows that, generally, moving away from the training data will lead to higher (close to 1.0) OOD scores.</p> In\u00a0[12]: Copied! <pre># Make a new set of datapoints centered at (6,0)\nnew_x, _ = make_blobs(n_samples=100, n_features=tensor_dim, \n                        centers=[[6,0]], cluster_std=0.5, shuffle=False,random_state=52)\nclass4_Xs = torch.FloatTensor(new_x)\nclass4_Ys = 4*torch.ones(len(new_x),dtype=torch.int)    \n\n# Append to existing test data\nood_test_x= torch.cat((test_x, class4_Xs))\nood_test_y = torch.cat((test_y, class4_Ys))\n</pre> # Make a new set of datapoints centered at (6,0) new_x, _ = make_blobs(n_samples=100, n_features=tensor_dim,                          centers=[[6,0]], cluster_std=0.5, shuffle=False,random_state=52) class4_Xs = torch.FloatTensor(new_x) class4_Ys = 4*torch.ones(len(new_x),dtype=torch.int)      # Append to existing test data ood_test_x= torch.cat((test_x, class4_Xs)) ood_test_y = torch.cat((test_y, class4_Ys)) <p>Neither the vanilla neural network or the EQUINE network knows \"out of distribution\" cluster, so it's impossible for the networks to correctly predict the new label -- meaning that the cluster appears as a bunch of incorrect predictions to the right of the existing test data.</p> In\u00a0[13]: Copied! <pre># Compute new results with appended OOD cluster\nvanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(ood_test_x))\nvnn_conf_pts = torch.max(vanilla_results,1).values.detach()\nvnn_y_classes = torch.argmax(vanilla_results,1)\n\n# Extend the grid to the right a bit to see the new cluster\nbbox = 8 \nXt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox+2,steps=100), \n                        torch.linspace(-bbox,bbox,steps=100),\n                        indexing='xy')\nXs = torch.cat(tuple(torch.dstack((Xt,Yt))))\nvnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs))\nvnn_conf = torch.max(vnn_results_grid,1).values.detach()\n\ndisplay_2d_test_and_confidence(vanilla_results, ood_test_x, ood_test_y, Xt, Yt, vnn_conf,\n                            \"Vanilla NN Test Predictions and Class Confidence\")\n</pre> # Compute new results with appended OOD cluster vanilla_results = torch.nn.Softmax(dim=1)(vanilla_nn(ood_test_x)) vnn_conf_pts = torch.max(vanilla_results,1).values.detach() vnn_y_classes = torch.argmax(vanilla_results,1)  # Extend the grid to the right a bit to see the new cluster bbox = 8  Xt, Yt = torch.meshgrid(torch.linspace(-bbox,bbox+2,steps=100),                          torch.linspace(-bbox,bbox,steps=100),                         indexing='xy') Xs = torch.cat(tuple(torch.dstack((Xt,Yt)))) vnn_results_grid=torch.nn.Softmax(dim=1)(vanilla_nn(Xs)) vnn_conf = torch.max(vnn_results_grid,1).values.detach()  display_2d_test_and_confidence(vanilla_results, ood_test_x, ood_test_y, Xt, Yt, vnn_conf,                             \"Vanilla NN Test Predictions and Class Confidence\") <p>Finally, we illustrate the binary predictive performance on \"correct\" and \"incorrect\" predictions that would come from using the OOD scores to screen out predictions on likely OOD data. To do this, we'll generate a ROC curve using 1-OOD scores (something like an \"in-distribution\" score) as a confidence threshold for EQUINE, and the maximum probability for the vanilla Neural Network.</p> <p>Note that these ROC curves could be made arbitrarily worse for the Vanilla Neural Network by adding more OOD test points and/or more OOD data clusters; the point is just to show how EQUINE's <code>ood_scores</code> can be used to filter out predictions on OOD data.</p> In\u00a0[14]: Copied! <pre># Let's see how well the confidence does at figuring ou\nvnn_correct = (vnn_y_classes == ood_test_y)\n\n# Generate results for the EQUINE protonet\neq_results=model.predict(ood_test_x)\neq_y_classes = torch.argmax(eq_results.classes,1)\neq_correct = (eq_y_classes == ood_test_y)\n\n# Show the performance \nfig, ax = plt.subplots(figsize=(6, 6))\nRocCurveDisplay.from_predictions(eq_correct, 1.0-eq_results.ood_scores.detach().numpy(), name=\"EQUINE In-Distribution\", ax=ax)\nRocCurveDisplay.from_predictions(vnn_correct, vnn_conf_pts, name=\"Vanilla NN Confidence\", ax=ax)\n</pre> # Let's see how well the confidence does at figuring ou vnn_correct = (vnn_y_classes == ood_test_y)  # Generate results for the EQUINE protonet eq_results=model.predict(ood_test_x) eq_y_classes = torch.argmax(eq_results.classes,1) eq_correct = (eq_y_classes == ood_test_y)  # Show the performance  fig, ax = plt.subplots(figsize=(6, 6)) RocCurveDisplay.from_predictions(eq_correct, 1.0-eq_results.ood_scores.detach().numpy(), name=\"EQUINE In-Distribution\", ax=ax) RocCurveDisplay.from_predictions(vnn_correct, vnn_conf_pts, name=\"Vanilla NN Confidence\", ax=ax) Out[14]: <pre>&lt;sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7f93287cfb50&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"example_notebooks/toy_example_GP/#equine-toy-problem-example","title":"EQUINE Toy Problem Example\u00b6","text":"<p>The intent of this example notebook is to provide an easy-to-visualize, 2-D, toy problem that illustrates both the general problem of uncertainty quantification in neural network classification as well as to show how EQUINE can be used to make predictions more robust in the face of uncertainty.</p> <p>Here, we use the <code>EquineGP</code> class to demonstrate the ideas. This class follows the approach used in Spectral-normalized Neural Gaussian Processes (SNGP), which appends random Fourier features and a Laplace approximation to a Gaussian Process (GP) to the end of a neural network, making it possible to compute out-of-distribution scores (see deterministic uncertainty estimation and the SNGP tutorial). Note that EQUINE does not assume that the user is enforcing a spectral normalization in the neural network embedding, so the results may vary.</p> <p>This notebook requires some extra dependencies to run. You can uncomment the below cell to install them into your local environment.</p>"},{"location":"example_notebooks/toy_example_GP/#generate-toy-dataset","title":"Generate Toy Dataset\u00b6","text":"<p>This dataset uses <code>make_blobs</code> from scikit-learn, placing 4 clusters in each quadrant (for 4 classes), along with a middle cluster with random class memberships.</p> <p>In this toy problem, the accuracy should not be much higher than 80%, since the middle class memberships are essentially random.</p> <p>Additionally, the class confidence in the middle of the problem should hover around 25% for the same reason.</p>"},{"location":"example_notebooks/toy_example_GP/#define-a-feature-embedding-model","title":"Define a feature embedding model\u00b6","text":"<p>Here we define a \"usual\", sequential neural network architecture, leaving off only the softmax in the forward function. Here, we've arbitrarily selected 16 as the dimension of the feature embeddings (the penultimate layer), but we're classifying on the 4 output categories from above.</p>"},{"location":"example_notebooks/toy_example_GP/#visualizing-the-neural-network-uncertainty","title":"Visualizing the Neural Network Uncertainty\u00b6","text":"<p>Before continuing onto how EQUINE can help, here's how well the \"vanilla\" Neural Network does on this problem. Using the above function, we can show the output predictions on the held-out test data and on a uniform grid.</p>"},{"location":"example_notebooks/toy_example_GP/#wrapping-the-vanilla-nn-feature-embedding-in-equine","title":"Wrapping the Vanilla NN Feature Embedding in EQUINE\u00b6","text":"<p>At first glance, the network is performing very well: it is getting more than 80% accuracy and is very confident about its predictions (the maximum probability is nearly 1.0 almost everywhere). However, the confidence contours reveal that the model is extremely confident everywhere except for a relatively thin boundary between the classes on the x/y axes and in the interior, random cluster. On the held-out test data, the calibration error for this simple problem is also decent.</p> <p>Next, let's consider all but the last layer of the above neural network as a \"feature embedding\". In this example, we use <code>EquineGP</code>, which is based upon Spectral Norm Gaussian Processes (for more background, checkout this TensorFlow tutorial as well as the PyTorch reimplementation).</p> <p>To wrap the feature embedding into an Equine GP, we wrap the embedding model into an <code>EquineGP</code> class:</p>"},{"location":"example_notebooks/toy_example_GP/#out-of-distribution-indicators","title":"Out of Distribution Indicators\u00b6","text":"<p>EQUINE introduces the <code>predict()</code> method to return predictions with the probability contexts, including</p> <ul> <li>classes:    the class probabilities</li> <li>ood_scores: the out-of-distribution scores</li> </ul>"},{"location":"example_notebooks/toy_example_GP/#adding-an-out-of-distribution-class","title":"Adding an out-of-distribution class\u00b6","text":"<p>Finally, we illustrate the binary predictive performance on \"correct\" and \"incorrect\" predictions that would come from using the OOD scores to screen out predictions on likely OOD data.</p>"},{"location":"example_notebooks/vnat_example/","title":"Encrypted Network Traffic","text":"In\u00a0[1]: Copied! <pre># This notebook requires additional pythom modules and a dataset to run. \n# You can uncomment the following lines to install them in your environment.\n# !curl -o VNAT_Dataframe_release_1.h5 https://archive.ll.mit.edu/datasets/vnat/VNAT_Dataframe_release_1.h5 \n# !conda install -y pytables\n# !pip install scikit-learn pandas matplotlib\n</pre> # This notebook requires additional pythom modules and a dataset to run.  # You can uncomment the following lines to install them in your environment. # !curl -o VNAT_Dataframe_release_1.h5 https://archive.ll.mit.edu/datasets/vnat/VNAT_Dataframe_release_1.h5  # !conda install -y pytables # !pip install scikit-learn pandas matplotlib  In\u00a0[2]: Copied! <pre>import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\nimport equine as eq\n</pre> import torch import numpy as np import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.metrics import RocCurveDisplay import matplotlib.pyplot as plt  import equine as eq In\u00a0[3]: Copied! <pre>data_path = \"VNAT_Dataframe_release_1.h5\"\nvnat_df = pd.read_hdf(data_path)\nprint(\"Shape is \", vnat_df.shape)\nvnat_df.head()\n</pre> data_path = \"VNAT_Dataframe_release_1.h5\" vnat_df = pd.read_hdf(data_path) print(\"Shape is \", vnat_df.shape) vnat_df.head() <pre>Shape is  (33711, 5)\n</pre> Out[3]: connection timestamps sizes directions file_names 0 (10.123.1.2, 1195, 10.123.1.1, 1195, 17) [1563289706.330096, 1563289706.330207, 1563289... [120, 88, 120, 88, 120, 88, 120, 120, 152, 120... [1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ... vpn_youtube_capture2.pcap 0 (10.113.1.2, 22924, 10.115.1.2, 53, 17) [1561391908.523659, 1561391908.524042] [63, 79] [1, 0] nonvpn_sftp_newcapture1.pcap 1 (10.113.1.2, 53065, 10.115.1.2, 53, 17) [1561391908.523706, 1561391908.524059] [63, 63] [1, 0] nonvpn_sftp_newcapture1.pcap 2 (10.113.1.150, 39816, 10.115.1.123, 22, 6) [1561391908.524836, 1561391908.525027, 1561391... [60, 60, 52, 73, 52, 73, 52, 1378, 222, 52, 13... [1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, ... nonvpn_sftp_newcapture1.pcap 3 (10.115.1.2, 6589, 10.113.1.2, 53, 17) [1561391908.594887, 1561391908.595301] [51, 102] [1, 0] nonvpn_sftp_newcapture1.pcap <p>Following the table from the download site, we'll use the filenames to generate some overarching labels. Here, \"FT\" means file-transfer, and \"C2\" means \"command-and-control\" (i.e., these applications feature two-way traffic where commands are issued). It is also possible to create VPN and non-VPN categories, etc.</p> In\u00a0[4]: Copied! <pre>app_to_label = { \"vimeo\":\"streaming\", \"netflix\":\"streaming\", \"youtube\":\"streaming\", \n    \"voip\":\"voip\",\n    \"skype-chat\":\"chat\",\n    \"ssh\":\"C2\", \"rdp\":\"C2\",\n    \"sftp\":\"FT\", \"rsync\":\"FT\", \"scp\":\"FT\"}\n\napps = np.array(list(app_to_label.keys()))\ndef label_match(filename):\n    words = filename.split('_')\n    app = words[1] # Application name is second in filename\n    matches = apps[apps == app]\n    label = app_to_label[matches[0]] \n    return label\n\nvnat_df[\"labels\"] = vnat_df.file_names.apply(lambda x: label_match(x))\n</pre> app_to_label = { \"vimeo\":\"streaming\", \"netflix\":\"streaming\", \"youtube\":\"streaming\",      \"voip\":\"voip\",     \"skype-chat\":\"chat\",     \"ssh\":\"C2\", \"rdp\":\"C2\",     \"sftp\":\"FT\", \"rsync\":\"FT\", \"scp\":\"FT\"}  apps = np.array(list(app_to_label.keys())) def label_match(filename):     words = filename.split('_')     app = words[1] # Application name is second in filename     matches = apps[apps == app]     label = app_to_label[matches[0]]      return label  vnat_df[\"labels\"] = vnat_df.file_names.apply(lambda x: label_match(x)) In\u00a0[5]: Copied! <pre>def calculate_features(row):\n    forward_backward_mask = np.array(row.directions, dtype=bool)\n    ts = np.array(row.timestamps)\n    duration = ts[-1]-ts[0]\n\n    # split out \"forward\" and \"backward\" timestamps\n    ts_forward = ts[forward_backward_mask] \n    ts_backward = ts[~forward_backward_mask]\n\n    # Bail out if this connection is too short or has very little data\n    if duration &lt; 30.0 or len(ts_forward) &lt; 10 or len(ts_backward) &lt; 10:\n        return tuple(16*[pd.NA])\n\n    # Statistics for forward interarrival times\n    forward_interarrivals = ts_forward[1:]-ts_forward[:-1]\n    fiat_mean = np.mean(forward_interarrivals)\n    fiat_std = np.std(forward_interarrivals)\n    fiat_max = np.max(forward_interarrivals)\n    fiat_min = np.min(forward_interarrivals)\n\n    # Statistics for backward interarrival times\n    backward_interarrivals = ts_backward[1:]-ts_backward[:-1]\n    biat_mean = np.mean(backward_interarrivals)\n    biat_std = np.std(backward_interarrivals)\n    biat_max = np.max(backward_interarrivals)\n    biat_min = np.min(backward_interarrivals)\n\n    # Size statisticstics \n    sizes = np.array(row.sizes)\n    total_forward = len(ts_forward)\n    total_backward = len(ts_backward)\n    bytes_forward = sum(sizes[forward_backward_mask])\n    bytes_backward = sum(sizes[~forward_backward_mask])\n    bytes_per_sec = (bytes_forward + bytes_backward) / duration\n    num_unique_forward_sizes = len(np.unique(sizes[forward_backward_mask]))\n    num_unique_backward_sizes = len(np.unique(sizes[~forward_backward_mask]))\n\n    return  (duration, fiat_mean, fiat_std, fiat_max, fiat_min, \n            biat_mean, biat_std, biat_max, biat_min, \n            total_forward, total_backward, \n            bytes_forward, bytes_backward, bytes_per_sec, \n            num_unique_forward_sizes, num_unique_backward_sizes)\n</pre> def calculate_features(row):     forward_backward_mask = np.array(row.directions, dtype=bool)     ts = np.array(row.timestamps)     duration = ts[-1]-ts[0]      # split out \"forward\" and \"backward\" timestamps     ts_forward = ts[forward_backward_mask]      ts_backward = ts[~forward_backward_mask]      # Bail out if this connection is too short or has very little data     if duration &lt; 30.0 or len(ts_forward) &lt; 10 or len(ts_backward) &lt; 10:         return tuple(16*[pd.NA])      # Statistics for forward interarrival times     forward_interarrivals = ts_forward[1:]-ts_forward[:-1]     fiat_mean = np.mean(forward_interarrivals)     fiat_std = np.std(forward_interarrivals)     fiat_max = np.max(forward_interarrivals)     fiat_min = np.min(forward_interarrivals)      # Statistics for backward interarrival times     backward_interarrivals = ts_backward[1:]-ts_backward[:-1]     biat_mean = np.mean(backward_interarrivals)     biat_std = np.std(backward_interarrivals)     biat_max = np.max(backward_interarrivals)     biat_min = np.min(backward_interarrivals)      # Size statisticstics      sizes = np.array(row.sizes)     total_forward = len(ts_forward)     total_backward = len(ts_backward)     bytes_forward = sum(sizes[forward_backward_mask])     bytes_backward = sum(sizes[~forward_backward_mask])     bytes_per_sec = (bytes_forward + bytes_backward) / duration     num_unique_forward_sizes = len(np.unique(sizes[forward_backward_mask]))     num_unique_backward_sizes = len(np.unique(sizes[~forward_backward_mask]))      return  (duration, fiat_mean, fiat_std, fiat_max, fiat_min,              biat_mean, biat_std, biat_max, biat_min,              total_forward, total_backward,              bytes_forward, bytes_backward, bytes_per_sec,              num_unique_forward_sizes, num_unique_backward_sizes) In\u00a0[6]: Copied! <pre># Add the features to the dataframe\nvnat_df[[\"duration\", \"fiat_mean\", \"fiat_std\", \"fiat_max\", \"fiat_min\",\n \"biat_mean\", \"biat_std\", \"biat_max\", \"biat_min\", \"total_forward\", \n \"total_backward\", \"bytes_foward\", \"bytes_backward\", \"bytes_per_sec\",\n  \"num_unique_forward_sizes\", \"num_unique_backward_sizes\"]] = vnat_df.apply(\n    calculate_features, axis=1, result_type='expand')\n</pre> # Add the features to the dataframe vnat_df[[\"duration\", \"fiat_mean\", \"fiat_std\", \"fiat_max\", \"fiat_min\",  \"biat_mean\", \"biat_std\", \"biat_max\", \"biat_min\", \"total_forward\",   \"total_backward\", \"bytes_foward\", \"bytes_backward\", \"bytes_per_sec\",   \"num_unique_forward_sizes\", \"num_unique_backward_sizes\"]] = vnat_df.apply(     calculate_features, axis=1, result_type='expand') In\u00a0[7]: Copied! <pre>vnat_df.drop([\"connection\", \"timestamps\", \"sizes\", \"directions\", \"file_names\"],axis=1, inplace=True)\nvnat_df.dropna(inplace=True)\nvnat_df.groupby(\"labels\").describe()\n</pre> vnat_df.drop([\"connection\", \"timestamps\", \"sizes\", \"directions\", \"file_names\"],axis=1, inplace=True) vnat_df.dropna(inplace=True) vnat_df.groupby(\"labels\").describe() Out[7]: duration fiat_mean fiat_std ... bytes_per_sec num_unique_forward_sizes num_unique_backward_sizes count unique top freq count unique top freq count unique ... top freq count unique top freq count unique top freq labels C2 379.0 379.0 26542.717629 1.0 379.0 379.0 8.918924 1.0 379.0 379.0 ... 2.330914e+01 1.0 379.0 20.0 14.0 338.0 379.0 27.0 13.0 57.0 FT 30.0 30.0 473.359046 1.0 30.0 30.0 0.000514 1.0 30.0 30.0 ... 3.859252e+06 1.0 30.0 17.0 15.0 4.0 30.0 19.0 13.0 5.0 chat 152.0 151.0 17990.640175 2.0 152.0 151.0 2.911578 2.0 152.0 151.0 ... 1.853004e+02 2.0 152.0 49.0 24.0 25.0 152.0 54.0 26.0 22.0 streaming 671.0 671.0 800.568697 1.0 671.0 671.0 0.039530 1.0 671.0 671.0 ... 7.286141e+04 1.0 671.0 49.0 9.0 107.0 671.0 107.0 8.0 109.0 voip 12.0 12.0 1819.484871 1.0 12.0 12.0 0.019927 1.0 12.0 12.0 ... 8.418154e+03 1.0 12.0 6.0 1.0 5.0 12.0 6.0 1.0 5.0 <p>5 rows \u00d7 64 columns</p> In\u00a0[8]: Copied! <pre># Drop a couple of the classes with a small number of total connections\nvnat_df_no_voip = vnat_df[vnat_df.labels != \"voip\"]\nvnat_df_drop2 = vnat_df_no_voip[vnat_df_no_voip.labels != \"FT\"]\n\n# Encode the labels as integers\nencoder = LabelEncoder()\nencoded_labels = torch.IntTensor(encoder.fit_transform(vnat_df_drop2[\"labels\"]))\n\n# Create the tensor input data, dropping the labels\ndata = torch.FloatTensor(np.array(vnat_df_drop2.drop([\"labels\"], axis=1).values, dtype=np.float32))\ndataset = torch.utils.data.TensorDataset(data,encoded_labels)\ntrainset, testset = torch.utils.data.random_split(dataset, [0.8, 0.2], \n                    generator=torch.Generator().manual_seed(52))\n\n# Pull out the train/test tensors for the protonet\ntrain_x = trainset.dataset.tensors[0][trainset.indices]\ntrain_y = trainset.dataset.tensors[1][trainset.indices]\ntest_x = trainset.dataset.tensors[0][testset.indices]\ntest_y = trainset.dataset.tensors[1][testset.indices]\n\n# Store some helpful variables for the emedding model and data normalization\ninput_dim = data.shape[1]\nnum_classes = len(np.unique(vnat_df_drop2.labels))\n\ntrain_means = train_x.mean(0, keepdim=True)\ntrain_deviations = train_x.std(0, keepdim=True)\n</pre> # Drop a couple of the classes with a small number of total connections vnat_df_no_voip = vnat_df[vnat_df.labels != \"voip\"] vnat_df_drop2 = vnat_df_no_voip[vnat_df_no_voip.labels != \"FT\"]  # Encode the labels as integers encoder = LabelEncoder() encoded_labels = torch.IntTensor(encoder.fit_transform(vnat_df_drop2[\"labels\"]))  # Create the tensor input data, dropping the labels data = torch.FloatTensor(np.array(vnat_df_drop2.drop([\"labels\"], axis=1).values, dtype=np.float32)) dataset = torch.utils.data.TensorDataset(data,encoded_labels) trainset, testset = torch.utils.data.random_split(dataset, [0.8, 0.2],                      generator=torch.Generator().manual_seed(52))  # Pull out the train/test tensors for the protonet train_x = trainset.dataset.tensors[0][trainset.indices] train_y = trainset.dataset.tensors[1][trainset.indices] test_x = trainset.dataset.tensors[0][testset.indices] test_y = trainset.dataset.tensors[1][testset.indices]  # Store some helpful variables for the emedding model and data normalization input_dim = data.shape[1] num_classes = len(np.unique(vnat_df_drop2.labels))  train_means = train_x.mean(0, keepdim=True) train_deviations = train_x.std(0, keepdim=True) In\u00a0[9]: Copied! <pre>num_deep_features = 16\nclass EmbeddingModel(torch.nn.Module):\n    def __init__(self, train_means, train_deviations):\n        super(EmbeddingModel, self).__init__()\n        self.train_means = train_means\n        self.train_deviations = train_deviations\n        self.linear_relu_stack = torch.nn.Sequential(\n            torch.nn.Linear(input_dim, num_deep_features),\n            torch.nn.ReLU(),\n            torch.nn.Linear(num_deep_features, num_deep_features),\n            torch.nn.ReLU(),\n            torch.nn.Linear(num_deep_features, num_deep_features),\n            torch.nn.ReLU(),\n            torch.nn.Linear(num_deep_features, num_deep_features),\n        )\n\n    def forward(self, x):\n        x = (x - self.train_means ) / self.train_deviations\n        logits = self.linear_relu_stack(x)\n        return logits\n</pre> num_deep_features = 16 class EmbeddingModel(torch.nn.Module):     def __init__(self, train_means, train_deviations):         super(EmbeddingModel, self).__init__()         self.train_means = train_means         self.train_deviations = train_deviations         self.linear_relu_stack = torch.nn.Sequential(             torch.nn.Linear(input_dim, num_deep_features),             torch.nn.ReLU(),             torch.nn.Linear(num_deep_features, num_deep_features),             torch.nn.ReLU(),             torch.nn.Linear(num_deep_features, num_deep_features),             torch.nn.ReLU(),             torch.nn.Linear(num_deep_features, num_deep_features),         )      def forward(self, x):         x = (x - self.train_means ) / self.train_deviations         logits = self.linear_relu_stack(x)         return logits In\u00a0[10]: Copied! <pre>model = eq.EquineProtonet(EmbeddingModel(train_means, train_deviations),  num_deep_features)\nres = model.train_model(torch.utils.data.TensorDataset(train_x,train_y),\n                    way=num_classes,   # Number of classes to train each episode\n                    support_size=20,   # Number of support examples per class each episode\n                    num_episodes=1000, # Number of episodes (like epochs)\n                    episode_size=250)  # Number of examples per episode (like batch size)\n</pre> model = eq.EquineProtonet(EmbeddingModel(train_means, train_deviations),  num_deep_features) res = model.train_model(torch.utils.data.TensorDataset(train_x,train_y),                     way=num_classes,   # Number of classes to train each episode                     support_size=20,   # Number of support examples per class each episode                     num_episodes=1000, # Number of episodes (like epochs)                     episode_size=250)  # Number of examples per episode (like batch size) <pre>  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:03&lt;00:00, 266.76it/s]\n</pre> In\u00a0[11]: Copied! <pre>test_results = model.predict(test_x)\nacc = sum((torch.argmax(test_results.classes,1)==test_y).to(int))/len(test_results.classes)\nprint(acc)\n</pre> test_results = model.predict(test_x) acc = sum((torch.argmax(test_results.classes,1)==test_y).to(int))/len(test_results.classes) print(acc) <pre>tensor(0.9792)\n</pre> <p>You should see a relatively high accuracy (&gt;95%). Next, we consider the problem of handling network traffic generated by applications that were not seen by the model.</p> In\u00a0[12]: Copied! <pre>ood_df = vnat_df[(vnat_df.labels == \"voip\") | (vnat_df.labels == \"FT\")]\nood_data = torch.FloatTensor(np.array(ood_df.drop([\"labels\"], axis=1).values, dtype=np.float32))\nood_results = model.predict(ood_data)\n\nfig, ax = plt.subplots(2,1, figsize=(8,8))\n\nax[0].hist(test_results.ood_scores, bins=20, alpha=0.5, label=\"Test Class Data\")\nax[0].hist(ood_results.ood_scores, bins=20, alpha=0.5, label=\"OOD Classes\")\nax[0].set_xlabel(\"OOD Scores\")\nax[0].legend()\n\nin_out = torch.concat((torch.zeros(len(test_results.ood_scores)), torch.ones(len(ood_results.ood_scores))))\nall_oods = torch.concat((test_results.ood_scores,ood_results.ood_scores))\n\nRocCurveDisplay.from_predictions(in_out, all_oods, name=\"EQUINE In-Distribution\", ax=ax[1])\nplt.show()\n</pre> ood_df = vnat_df[(vnat_df.labels == \"voip\") | (vnat_df.labels == \"FT\")] ood_data = torch.FloatTensor(np.array(ood_df.drop([\"labels\"], axis=1).values, dtype=np.float32)) ood_results = model.predict(ood_data)  fig, ax = plt.subplots(2,1, figsize=(8,8))  ax[0].hist(test_results.ood_scores, bins=20, alpha=0.5, label=\"Test Class Data\") ax[0].hist(ood_results.ood_scores, bins=20, alpha=0.5, label=\"OOD Classes\") ax[0].set_xlabel(\"OOD Scores\") ax[0].legend()  in_out = torch.concat((torch.zeros(len(test_results.ood_scores)), torch.ones(len(ood_results.ood_scores)))) all_oods = torch.concat((test_results.ood_scores,ood_results.ood_scores))  RocCurveDisplay.from_predictions(in_out, all_oods, name=\"EQUINE In-Distribution\", ax=ax[1]) plt.show()"},{"location":"example_notebooks/vnat_example/#equine-example-on-vpnnonvpn-network-application-traffic-dataset-vnat","title":"EQUINE Example on VPN/NonVPN Network Application Traffic Dataset (VNAT)\u00b6","text":"<p>This example showcases how to use an EQUINE class to analyze an encrypted network traffic dataset. The general question of interest from this dataset is whether it is possible to discern the application that generated network traffic, even if that traffic is routed through a Virtual Private Network (VPN). To try this example out, you will need to download the connections dataframe from that location and place it in the same directory as this notebook.  For more information, check out this paper in the IEEE Journal, Transactions of Artificial Intelligence.</p> <p>In this example, we'll demonstrate how to add labels and features to the dataframe and then train an <code>EquineProtonet</code> model, holding out two of the five classes, in order to evaluate its performance at assigning relatively high out-of-distribution scores for the two held-out classes.</p>"},{"location":"example_notebooks/vnat_example/#dataset-preparation","title":"Dataset Preparation\u00b6","text":"<p>We'll use pandas to read the HDF5 file. It should produce a dataframe with the keys \"connection\", \"timestamps\", \"sizes\", \"directions\" and \"file_names\".</p>"},{"location":"example_notebooks/vnat_example/#feature-generation","title":"Feature Generation\u00b6","text":"<p>Next, we'll generate some simple \"transport layer statistics\" to use as classification features. Essentially, these are statistical features calculated over the entirety of each connection, including things like the average \"interarrival times\" between packets, the total amount of bytes transferred, etc. Note that the below code filters any connections with fewer than 10 packets in either direction or shorter than 30 seconds.</p>"},{"location":"example_notebooks/vnat_example/#grouped-data-characteristics","title":"Grouped Data Characteristics\u00b6","text":"<p>Note here that we have grouped only by application type. Since there are few remaining single-connection examples of file-transfer and VOIP, we'll hold those out for out-of-distribution testing.</p>"},{"location":"example_notebooks/vnat_example/#create-an-embedding-model-and-train-a-neural-network","title":"Create an Embedding Model and train a Neural Network\u00b6","text":"<p>We next create a simple embedding model that we'll use to train from scratch using the <code>train_episodes</code> method in <code>EquineProtonet</code>. Given that the predictions are on the entire connnections (and some of them are pretty long), this is not too challenging a prediction problem, even though some of the connections are tunnneled through a VPN. This is because the size and timing characteristics of the connections are not always obscured by VPNs.</p>"},{"location":"example_notebooks/vnat_example/#train-a-model","title":"Train a model\u00b6","text":"<p>Here we create the Neural Network from scratch using the above feature embedding model and perform episodic training. Other examples showcase how one can pretrain and freeze layers in the feature embedding model, but for this example, we simply train from scratch, which should only take a few seconds on a CPU.</p>"},{"location":"example_notebooks/vnat_example/#out-of-distribution-study","title":"Out of distribution study\u00b6","text":"<p>Here we demonstrate that the remaining two application categories, VOIP and File Transfer (FT), which were not included in the model training, produce relatively high out-of-distribution, represented by the <code>ood_scores</code> in <code>EquineOutput</code>. In the below cell, we consider the held-out test data as in-distribution for reference, whereas the VOIP and FT connections are the <code>ood_data</code>. To generate a ROC curve, we concatenate the test and OOD data together and use the <code>ood_scores</code> as a signifier as to whether they were in- or out-of-distribution. The histogram should reveal thaat the majority of the OOD data is in the highest scoring bin (closest to 1.0).</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>equine<ul> <li>_version</li> <li>equine</li> <li>equine_gp</li> <li>equine_output</li> <li>equine_protonet</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/equine/","title":"equine","text":""},{"location":"reference/equine/#equine.Equine","title":"<code>Equine</code>","text":"<p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>EQUINE Abstract Base Class (ABC): EQUINE is set up to extend torch's nn.Module to enrich it with a method that enables uncertainty quantification and visualization. Most importantly, the <code>.predict()</code> method must be outfitted to return an EquineOutput object that contains both the class probabilities and an out-of-distribution (ood) score.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>The embedding model to use.</p> required <code>head_layers</code> <code>int</code> <p>The number of layers to use in the model head, by default 1.</p> <code>1</code> <p>Attributes:</p> Name Type Description <code>embedding_model</code> <code>Module</code> <p>The neural embedding model to enrich with uncertainty quantification.</p> <code>head_layers</code> <code>int</code> <p>The number of linear layers to append to the embedding model (default 1, not always used).</p> <code>train_summary</code> <code>dict[str, Any]</code> <p>A dictionary containing information about the model training.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If any of the abstract methods are not implemented.</p> Source code in <code>src/equine/equine.py</code> <pre><code>class Equine(torch.nn.Module, ABC):\n    \"\"\"EQUINE Abstract Base Class (ABC):\n    EQUINE is set up to extend torch's nn.Module to enrich it with\n    a method that enables uncertainty quantification and visualization. Most\n    importantly, the `.predict()` method must be outfitted to return an\n    EquineOutput object that contains both the class probabilities\n    *and* an out-of-distribution (ood) score.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        The embedding model to use.\n    head_layers : int, optional\n        The number of layers to use in the model head, by default 1.\n\n    Attributes\n    ----------\n    embedding_model : torch.nn.Module\n        The neural embedding model to enrich with uncertainty quantification.\n    head_layers : int\n        The number of linear layers to append to the embedding model (default 1, not always used).\n    train_summary : dict[str, Any]\n        A dictionary containing information about the model training.\n\n    Raises\n    ------\n    NotImplementedError\n        If any of the abstract methods are not implemented.\n    \"\"\"\n\n    def __init__(self, embedding_model: torch.nn.Module, head_layers: int = 1) -&gt; None:\n        super().__init__()\n        self.embedding_model = embedding_model\n        self.head_layers = head_layers\n        self.train_summary: dict[str, Any] = {\n            \"numTrainExamples\": 0,\n            \"dateTrained\": \"\",\n            \"modelType\": \"\",\n        }\n\n        self.support = None\n        self.support_embeddings = None\n        self.prototypes = None\n\n    @abstractmethod\n    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the model. This is to preserve the usual behavior\n        of torch.nn.Module.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            The input data.\n\n        Returns\n        -------\n        torch.Tensor\n            The output of the model.\n\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n        \"\"\"\n        Upon implementation, predicts the class logits and out-of-distribution (ood) scores for the\n        given input data.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            The input data.\n\n        Returns\n        -------\n        EquineOutput\n            An EquineOutput object containing the class probabilities and OOD scores.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def train_model(self, dataset: TensorDataset, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"\n        Upon implementation, train the model on the given dataset.\n\n        Parameters\n        ----------\n        dataset : TensorDataset\n            TensorDataset containing the training data.\n        **kwargs\n            Additional keyword arguments to pass to the training function.\n\n        Returns\n        -------\n        dict[str, Any]\n            Dictionary containing summary training information.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_prototypes(self) -&gt; torch.Tensor:\n        \"\"\"\n        Upon implementation, returns the prototype embeddings\n\n        Returns\n        -------\n        torch.Tensor\n            A torch tensor of the prototype embeddings\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Upon implementation, save the model to the given file path.\n\n        Parameters\n        ----------\n        path : str\n            File path to save the model to.\n        \"\"\"\n        raise NotImplementedError\n\n    @classmethod  # type: ignore\n    def load(cls: AnyEquine, path: str) -&gt; AnyEquine:  # noqa: F821 # type: ignore\n        \"\"\"\n        Upon implementation, load the model from the given file path.\n\n        Parameters\n        ----------\n        path : str\n            File path to load the model from.\n\n        Returns\n        -------\n        Equine\n            Loaded model object.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.Equine.forward","title":"<code>forward(X)</code>  <code>abstractmethod</code>","text":"<p>Forward pass of the model. This is to preserve the usual behavior of torch.nn.Module.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input data.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output of the model.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the model. This is to preserve the usual behavior\n    of torch.nn.Module.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        The input data.\n\n    Returns\n    -------\n    torch.Tensor\n        The output of the model.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.Equine.get_prototypes","title":"<code>get_prototypes()</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, returns the prototype embeddings</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A torch tensor of the prototype embeddings</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef get_prototypes(self) -&gt; torch.Tensor:\n    \"\"\"\n    Upon implementation, returns the prototype embeddings\n\n    Returns\n    -------\n    torch.Tensor\n        A torch tensor of the prototype embeddings\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.Equine.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Upon implementation, load the model from the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to load the model from.</p> required <p>Returns:</p> Type Description <code>Equine</code> <p>Loaded model object.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@classmethod  # type: ignore\ndef load(cls: AnyEquine, path: str) -&gt; AnyEquine:  # noqa: F821 # type: ignore\n    \"\"\"\n    Upon implementation, load the model from the given file path.\n\n    Parameters\n    ----------\n    path : str\n        File path to load the model from.\n\n    Returns\n    -------\n    Equine\n        Loaded model object.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.Equine.predict","title":"<code>predict(X)</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, predicts the class logits and out-of-distribution (ood) scores for the given input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input data.</p> required <p>Returns:</p> Type Description <code>EquineOutput</code> <p>An EquineOutput object containing the class probabilities and OOD scores.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef predict(self, X: torch.Tensor) -&gt; EquineOutput:\n    \"\"\"\n    Upon implementation, predicts the class logits and out-of-distribution (ood) scores for the\n    given input data.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        The input data.\n\n    Returns\n    -------\n    EquineOutput\n        An EquineOutput object containing the class probabilities and OOD scores.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.Equine.save","title":"<code>save(path)</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, save the model to the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to save the model to.</p> required Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef save(self, path: str) -&gt; None:\n    \"\"\"\n    Upon implementation, save the model to the given file path.\n\n    Parameters\n    ----------\n    path : str\n        File path to save the model to.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.Equine.train_model","title":"<code>train_model(dataset, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, train the model on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>TensorDataset</code> <p>TensorDataset containing the training data.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the training function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing summary training information.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef train_model(self, dataset: TensorDataset, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"\n    Upon implementation, train the model on the given dataset.\n\n    Parameters\n    ----------\n    dataset : TensorDataset\n        TensorDataset containing the training data.\n    **kwargs\n        Additional keyword arguments to pass to the training function.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing summary training information.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP","title":"<code>EquineGP</code>","text":"<p>               Bases: <code>Equine</code></p> <p>An example of an EQUINE model that builds upon the approach in \"Spectral Norm Gaussian Processes\" (SNGP). This wraps any pytorch embedding neural network and provides the <code>forward</code>, <code>predict</code>, <code>save</code>, and <code>load</code> methods required by Equine.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>Neural Network feature embedding.</p> required <code>emb_out_dim</code> <code>int</code> <p>The number of deep features from the feature embedding.</p> required <code>num_classes</code> <code>int</code> <p>The number of output classes this model predicts.</p> required <code>use_temperature</code> <code>bool</code> <p>Whether to use temperature scaling after training.</p> <code>False</code> <code>init_temperature</code> <code>float</code> <p>What to use as the initial temperature (1.0 has no effect).</p> <code>1.0</code> <code>device</code> <code>str</code> <p>Either 'cuda' or 'cpu'.</p> <code>'cpu'</code> Notes <p>Although this model build upon the approach in SNGP, it does not enforce the spectral normalization and ResNet architecture required for SNGP. Instead, it is a simple wrapper around any pytorch embedding neural network. Your mileage may vary.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@beartype\nclass EquineGP(Equine):\n    \"\"\"\n    An example of an EQUINE model that builds upon the approach in \"Spectral Norm\n    Gaussian Processes\" (SNGP). This wraps any pytorch embedding neural network and provides\n    the `forward`, `predict`, `save`, and `load` methods required by Equine.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        Neural Network feature embedding.\n    emb_out_dim : int\n        The number of deep features from the feature embedding.\n    num_classes : int\n        The number of output classes this model predicts.\n    use_temperature : bool, optional\n        Whether to use temperature scaling after training.\n    init_temperature : float, optional\n        What to use as the initial temperature (1.0 has no effect).\n    device : str, optional\n        Either 'cuda' or 'cpu'.\n\n    Notes\n    -----\n    Although this model build upon the approach in SNGP, it does not enforce the spectral normalization\n    and ResNet architecture required for SNGP. Instead, it is a simple wrapper around\n    any pytorch embedding neural network. Your mileage may vary.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model: torch.nn.Module,\n        emb_out_dim: int,\n        num_classes: int,\n        use_temperature: bool = False,\n        init_temperature: float = 1.0,\n        device: str = \"cpu\",\n    ) -&gt; None:\n        super().__init__(embedding_model)\n        self.num_deep_features = emb_out_dim\n        self.num_gp_features = emb_out_dim\n        self.normalize_gp_features = True\n        self.num_random_features = 1024\n        self.num_outputs = num_classes\n        self.mean_field_factor = 25\n        self.ridge_penalty = 1\n        self.feature_scale = 2.0\n        self.use_temperature = use_temperature\n        self.init_temperature = init_temperature\n        self.register_buffer(\n            \"temperature\", torch.Tensor(self.init_temperature * torch.ones(1))\n        )\n        self.model = _Laplace(\n            self.embedding_model,\n            self.num_deep_features,\n            self.num_gp_features,\n            self.normalize_gp_features,\n            self.num_random_features,\n            self.num_outputs,\n            self.feature_scale,\n            self.mean_field_factor,\n            self.ridge_penalty,\n        )\n        self.device_type = device\n        self.device = torch.device(self.device_type)\n        self.model.to(self.device)\n\n    def train_model(\n        self,\n        dataset: TensorDataset,\n        loss_fn: Callable,\n        opt: torch.optim.Optimizer,\n        num_epochs: int,\n        batch_size: int = 64,\n        calib_frac: float = 0.1,\n        num_calibration_epochs: int = 2,\n        calibration_lr: float = 0.01,\n        vis_support: bool = False,\n        support_size: int = 25,\n    ) -&gt; Tuple[dict[str, Any], Optional[DataLoader[Any]]]:\n        \"\"\"\n        Train or fine-tune an EquineGP model.\n\n        Parameters\n        ----------\n        dataset : TensorDataset\n            An iterable, pytorch TensorDataset.\n        loss_fn : Callable\n            A pytorch loss function, e.g., torch.nn.CrossEntropyLoss().\n        opt : torch.optim.Optimizer\n            A pytorch optimizer, e.g., torch.optim.Adam().\n        num_epochs : int\n            The desired number of epochs to use for training.\n        batch_size : int, optional\n            The number of samples to use per batch.\n        calib_frac : float, optional\n            Fraction of training data to use in temperature scaling.\n        num_calibration_epochs : int, optional\n            The desired number of epochs to use for temperature scaling.\n        calibration_lr : float, optional\n            Learning rate for temperature scaling.\n\n        Returns\n        -------\n        Tuple[dict[str, Any], DataLoader]\n            A tuple containing the training history and a dataloader for the calibration data.\n\n        Notes\n        -------\n        - If `use_temperature` is True, temperature scaling will be used after training.\n        - The calibration data is used to calibrate the temperature scaling.\n        \"\"\"\n        if self.use_temperature:\n            X, Y = dataset[:]\n            train_x, calib_x, train_y, calib_y = train_test_split(\n                X, Y, test_size=calib_frac, stratify=Y\n            )  # TODO: Replace sklearn with torch call\n            dataset = TensorDataset(train_x, train_y)\n            self.temperature = torch.Tensor(\n                self.init_temperature * torch.ones(1)\n            ).type_as(self.temperature)\n\n        train_loader = DataLoader(\n            dataset, batch_size=batch_size, shuffle=True, drop_last=True\n        )\n        self.model.set_training_params(\n            len(train_loader.sampler), train_loader.batch_size\n        )\n        self.model.train()\n        for _ in tqdm(range(num_epochs)):\n            self.model.reset_precision_matrix()\n            epoch_loss = 0.0\n            for i, (xs, labels) in enumerate(train_loader):\n                opt.zero_grad()\n                xs = xs.to(self.device)\n                labels = labels.to(self.device)\n                yhats = self.model(xs)\n                loss = loss_fn(yhats, labels.to(torch.long))\n                loss.backward()\n                opt.step()\n                epoch_loss += loss.item()\n        self.model.eval()\n\n        if vis_support:\n            self.update_support(dataset.tensors[0], dataset.tensors[1], support_size)\n\n        calibration_loader = None\n        if self.use_temperature:\n            dataset_calibration = TensorDataset(calib_x, calib_y)\n            calibration_loader = DataLoader(\n                dataset_calibration,\n                batch_size=batch_size,\n                shuffle=True,\n                drop_last=False,\n            )\n            self.calibrate_temperature(\n                calibration_loader, num_calibration_epochs, calibration_lr\n            )\n\n        _, train_y = dataset[:]\n        date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n        self.train_summary = generate_train_summary(self, train_y, date_trained)\n\n        return self.train_summary, calibration_loader\n\n    def update_support(\n        self, support_x: torch.Tensor, support_y: torch.Tensor, support_size: int\n    ) -&gt; None:\n        \"\"\"Function to update protonet support examples with given examples.\n\n        Parameters\n        ----------\n        support_x : torch.Tensor\n            Tensor containing support examples for protonet.\n        support_y : torch.Tensor\n            Tensor containing labels for given support examples.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        labels, counts = torch.unique(support_y, return_counts=True)\n        support = OrderedDict()\n        for label, count in list(zip(labels.tolist(), counts.tolist())):\n            class_support = generate_support(\n                support_x,\n                support_y,\n                support_size=min(count, support_size),\n                selected_labels=[label],\n            )\n            support.update(class_support)\n\n        self.support = support\n\n        support_embeddings = OrderedDict().fromkeys(support.keys())\n        for label in support:\n            support_embeddings[label] = self.compute_embeddings(support[label])\n\n        self.support_embeddings = support_embeddings\n\n        self.prototypes = self.compute_prototypes()\n\n    def compute_embeddings(self, x):\n        f = self.model.feature_extractor(x)\n        f_reduc = self.model.jl(f)\n        if self.model.normalize_gp_features:\n            f_reduc = self.model.normalize(f_reduc)\n\n        return self.model.rff(f_reduc)\n\n    @icontract.require(lambda self: self.support is not None)\n    def compute_prototypes(self) -&gt; torch.Tensor:\n        \"\"\"\n        Method for computing class prototypes based on given support examples.\n        ``Prototypes'' in this context are the means of the support embeddings for each class.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensors of prototypes for each of the given classes in the support.\n        \"\"\"\n        # Compute support embeddings\n        support_embeddings = OrderedDict().fromkeys(self.support.keys())\n        for label in self.support:\n            support_embeddings[label] = self.compute_embeddings(self.support[label])\n\n        # Compute prototype for each class\n        proto_list = []\n        for label in self.support:  # look at doing functorch\n            class_prototype = torch.mean(support_embeddings[label], dim=0)  # type: ignore\n            proto_list.append(class_prototype)\n\n        prototypes = torch.stack(proto_list)\n\n        return prototypes\n\n    @icontract.require(lambda self: self.support is not None)\n    def get_support(self):\n        return self.support\n\n    @icontract.require(lambda self: self.prototypes is not None)\n    def get_prototypes(self):\n        return self.prototypes\n\n    def calibrate_temperature(\n        self,\n        calibration_loader: DataLoader,\n        num_calibration_epochs: int = 1,\n        calibration_lr: float = 0.01,\n    ) -&gt; None:\n        \"\"\"\n        Fine-tune the temperature after training. Note this function is also run at the conclusion of train_model.\n\n        Parameters\n        ----------\n        calibration_loader : DataLoader\n            Data loader returned by train_model.\n        num_calibration_epochs : int, optional\n            Number of epochs to tune temperature.\n        calibration_lr : float, optional\n            Learning rate for temperature optimization.\n        \"\"\"\n        self.temperature.requires_grad = True\n        loss_fn = torch.nn.functional.cross_entropy\n        optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n        for _ in range(num_calibration_epochs):\n            for xs, labels in calibration_loader:\n                optimizer.zero_grad()\n                xs = xs.to(self.device)\n                labels = labels.to(self.device)\n                with torch.no_grad():\n                    logits = self.model(xs)\n                logits = logits / self.temperature\n                loss = loss_fn(logits, labels.to(torch.long))\n                loss.backward()\n                optimizer.step()\n        self.temperature.requires_grad = False\n\n    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        EquineGP forward function, generates logits for classification.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor for generating predictions.\n\n        Returns\n        -------\n        torch.Tensor\n            Output probabilities computed.\n        \"\"\"\n        X = X.to(self.device)\n        preds = self.model(X)\n        return preds / self.temperature.to(self.device)\n\n    @icontract.ensure(\n        lambda result: all((0 &lt;= result.ood_scores) &amp; (result.ood_scores &lt;= 1.0))\n    )\n    def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n        \"\"\"\n        Predict function for EquineGP, inherited and implemented from Equine.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        EquineOutput\n            Output object containing prediction probabilities and OOD scores.\n        \"\"\"\n        logits = self(X)\n        preds = torch.softmax(logits, dim=1)\n        equiprobable = torch.ones(self.num_outputs) / self.num_outputs\n        max_entropy = torch.sum(torch.special.entr(equiprobable))\n        ood_score = torch.sum(torch.special.entr(preds), dim=1) / max_entropy\n        embeddings = self.compute_embeddings(X)\n        eq_out = EquineOutput(\n            classes=preds, ood_scores=ood_score, embeddings=embeddings\n        )  # TODO return embeddings\n        return eq_out\n\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Function to save all model parameters to a file.\n\n        Parameters\n        ----------\n        path : str\n            Filename to write the model.\n        \"\"\"\n        model_settings = {\n            \"emb_out_dim\": self.num_deep_features,\n            \"num_classes\": self.num_outputs,\n            \"use_temperature\": self.use_temperature,\n            \"init_temperature\": self.temperature.item(),\n            \"device\": self.device_type,\n        }\n\n        jit_model = torch.jit.script(self.model.feature_extractor)\n        buffer = io.BytesIO()\n        torch.jit.save(jit_model, buffer)\n        buffer.seek(0)\n\n        laplace_sd = self.model.state_dict()\n        keys_to_delete = []\n        for key in laplace_sd:\n            if \"feature_extractor\" in key:\n                keys_to_delete.append(key)\n        for key in keys_to_delete:\n            del laplace_sd[key]\n\n        save_data = {\n            \"settings\": model_settings,\n            \"support\": self.support,\n            \"num_data\": self.model.num_data,\n            \"train_batch_size\": self.model.train_batch_size,\n            \"laplace_model_save\": laplace_sd,\n            \"embed_jit_save\": buffer,\n            \"train_summary\": self.train_summary,\n        }\n\n        torch.save(save_data, path)  # TODO allow model checkpointing\n\n    @classmethod\n    def load(cls, path: str) -&gt; Equine:\n        \"\"\"\n        Function to load previously saved EquineGP model.\n\n        Parameters\n        ----------\n        path : str\n            Input filename.\n\n        Returns\n        -------\n        EquineGP\n            The reconstituted EquineGP object.\n        \"\"\"\n        model_save = torch.load(path)\n        jit_model = torch.jit.load(model_save[\"embed_jit_save\"])\n        eq_model = cls(jit_model, **model_save[\"settings\"])\n\n        eq_model.train_summary = model_save[\"train_summary\"]\n        eq_model.model.load_state_dict(model_save[\"laplace_model_save\"], strict=False)\n        eq_model.model.seen_data = model_save[\"laplace_model_save\"][\"seen_data\"]\n\n        eq_model.model.set_training_params(\n            model_save[\"num_data\"], model_save[\"train_batch_size\"]\n        )\n        eq_model.eval()\n\n        support = model_save[\"support\"]\n        if support is not None:\n            eq_model.support = support\n            eq_model.prototypes = eq_model.compute_prototypes()\n\n        return eq_model\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.calibrate_temperature","title":"<code>calibrate_temperature(calibration_loader, num_calibration_epochs=1, calibration_lr=0.01)</code>","text":"<p>Fine-tune the temperature after training. Note this function is also run at the conclusion of train_model.</p> <p>Parameters:</p> Name Type Description Default <code>calibration_loader</code> <code>DataLoader</code> <p>Data loader returned by train_model.</p> required <code>num_calibration_epochs</code> <code>int</code> <p>Number of epochs to tune temperature.</p> <code>1</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature optimization.</p> <code>0.01</code> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def calibrate_temperature(\n    self,\n    calibration_loader: DataLoader,\n    num_calibration_epochs: int = 1,\n    calibration_lr: float = 0.01,\n) -&gt; None:\n    \"\"\"\n    Fine-tune the temperature after training. Note this function is also run at the conclusion of train_model.\n\n    Parameters\n    ----------\n    calibration_loader : DataLoader\n        Data loader returned by train_model.\n    num_calibration_epochs : int, optional\n        Number of epochs to tune temperature.\n    calibration_lr : float, optional\n        Learning rate for temperature optimization.\n    \"\"\"\n    self.temperature.requires_grad = True\n    loss_fn = torch.nn.functional.cross_entropy\n    optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n    for _ in range(num_calibration_epochs):\n        for xs, labels in calibration_loader:\n            optimizer.zero_grad()\n            xs = xs.to(self.device)\n            labels = labels.to(self.device)\n            with torch.no_grad():\n                logits = self.model(xs)\n            logits = logits / self.temperature\n            loss = loss_fn(logits, labels.to(torch.long))\n            loss.backward()\n            optimizer.step()\n    self.temperature.requires_grad = False\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.compute_prototypes","title":"<code>compute_prototypes()</code>","text":"<p>Method for computing class prototypes based on given support examples. ``Prototypes'' in this context are the means of the support embeddings for each class.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensors of prototypes for each of the given classes in the support.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@icontract.require(lambda self: self.support is not None)\ndef compute_prototypes(self) -&gt; torch.Tensor:\n    \"\"\"\n    Method for computing class prototypes based on given support examples.\n    ``Prototypes'' in this context are the means of the support embeddings for each class.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensors of prototypes for each of the given classes in the support.\n    \"\"\"\n    # Compute support embeddings\n    support_embeddings = OrderedDict().fromkeys(self.support.keys())\n    for label in self.support:\n        support_embeddings[label] = self.compute_embeddings(self.support[label])\n\n    # Compute prototype for each class\n    proto_list = []\n    for label in self.support:  # look at doing functorch\n        class_prototype = torch.mean(support_embeddings[label], dim=0)  # type: ignore\n        proto_list.append(class_prototype)\n\n    prototypes = torch.stack(proto_list)\n\n    return prototypes\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.forward","title":"<code>forward(X)</code>","text":"<p>EquineGP forward function, generates logits for classification.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor for generating predictions.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output probabilities computed.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    EquineGP forward function, generates logits for classification.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor for generating predictions.\n\n    Returns\n    -------\n    torch.Tensor\n        Output probabilities computed.\n    \"\"\"\n    X = X.to(self.device)\n    preds = self.model(X)\n    return preds / self.temperature.to(self.device)\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Function to load previously saved EquineGP model.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Input filename.</p> required <p>Returns:</p> Type Description <code>EquineGP</code> <p>The reconstituted EquineGP object.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@classmethod\ndef load(cls, path: str) -&gt; Equine:\n    \"\"\"\n    Function to load previously saved EquineGP model.\n\n    Parameters\n    ----------\n    path : str\n        Input filename.\n\n    Returns\n    -------\n    EquineGP\n        The reconstituted EquineGP object.\n    \"\"\"\n    model_save = torch.load(path)\n    jit_model = torch.jit.load(model_save[\"embed_jit_save\"])\n    eq_model = cls(jit_model, **model_save[\"settings\"])\n\n    eq_model.train_summary = model_save[\"train_summary\"]\n    eq_model.model.load_state_dict(model_save[\"laplace_model_save\"], strict=False)\n    eq_model.model.seen_data = model_save[\"laplace_model_save\"][\"seen_data\"]\n\n    eq_model.model.set_training_params(\n        model_save[\"num_data\"], model_save[\"train_batch_size\"]\n    )\n    eq_model.eval()\n\n    support = model_save[\"support\"]\n    if support is not None:\n        eq_model.support = support\n        eq_model.prototypes = eq_model.compute_prototypes()\n\n    return eq_model\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.predict","title":"<code>predict(X)</code>","text":"<p>Predict function for EquineGP, inherited and implemented from Equine.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>EquineOutput</code> <p>Output object containing prediction probabilities and OOD scores.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@icontract.ensure(\n    lambda result: all((0 &lt;= result.ood_scores) &amp; (result.ood_scores &lt;= 1.0))\n)\ndef predict(self, X: torch.Tensor) -&gt; EquineOutput:\n    \"\"\"\n    Predict function for EquineGP, inherited and implemented from Equine.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    EquineOutput\n        Output object containing prediction probabilities and OOD scores.\n    \"\"\"\n    logits = self(X)\n    preds = torch.softmax(logits, dim=1)\n    equiprobable = torch.ones(self.num_outputs) / self.num_outputs\n    max_entropy = torch.sum(torch.special.entr(equiprobable))\n    ood_score = torch.sum(torch.special.entr(preds), dim=1) / max_entropy\n    embeddings = self.compute_embeddings(X)\n    eq_out = EquineOutput(\n        classes=preds, ood_scores=ood_score, embeddings=embeddings\n    )  # TODO return embeddings\n    return eq_out\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.save","title":"<code>save(path)</code>","text":"<p>Function to save all model parameters to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Filename to write the model.</p> required Source code in <code>src/equine/equine_gp.py</code> <pre><code>def save(self, path: str) -&gt; None:\n    \"\"\"\n    Function to save all model parameters to a file.\n\n    Parameters\n    ----------\n    path : str\n        Filename to write the model.\n    \"\"\"\n    model_settings = {\n        \"emb_out_dim\": self.num_deep_features,\n        \"num_classes\": self.num_outputs,\n        \"use_temperature\": self.use_temperature,\n        \"init_temperature\": self.temperature.item(),\n        \"device\": self.device_type,\n    }\n\n    jit_model = torch.jit.script(self.model.feature_extractor)\n    buffer = io.BytesIO()\n    torch.jit.save(jit_model, buffer)\n    buffer.seek(0)\n\n    laplace_sd = self.model.state_dict()\n    keys_to_delete = []\n    for key in laplace_sd:\n        if \"feature_extractor\" in key:\n            keys_to_delete.append(key)\n    for key in keys_to_delete:\n        del laplace_sd[key]\n\n    save_data = {\n        \"settings\": model_settings,\n        \"support\": self.support,\n        \"num_data\": self.model.num_data,\n        \"train_batch_size\": self.model.train_batch_size,\n        \"laplace_model_save\": laplace_sd,\n        \"embed_jit_save\": buffer,\n        \"train_summary\": self.train_summary,\n    }\n\n    torch.save(save_data, path)  # TODO allow model checkpointing\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.train_model","title":"<code>train_model(dataset, loss_fn, opt, num_epochs, batch_size=64, calib_frac=0.1, num_calibration_epochs=2, calibration_lr=0.01, vis_support=False, support_size=25)</code>","text":"<p>Train or fine-tune an EquineGP model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>TensorDataset</code> <p>An iterable, pytorch TensorDataset.</p> required <code>loss_fn</code> <code>Callable</code> <p>A pytorch loss function, e.g., torch.nn.CrossEntropyLoss().</p> required <code>opt</code> <code>Optimizer</code> <p>A pytorch optimizer, e.g., torch.optim.Adam().</p> required <code>num_epochs</code> <code>int</code> <p>The desired number of epochs to use for training.</p> required <code>batch_size</code> <code>int</code> <p>The number of samples to use per batch.</p> <code>64</code> <code>calib_frac</code> <code>float</code> <p>Fraction of training data to use in temperature scaling.</p> <code>0.1</code> <code>num_calibration_epochs</code> <code>int</code> <p>The desired number of epochs to use for temperature scaling.</p> <code>2</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature scaling.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>Tuple[dict[str, Any], DataLoader]</code> <p>A tuple containing the training history and a dataloader for the calibration data.</p> Notes <ul> <li>If <code>use_temperature</code> is True, temperature scaling will be used after training.</li> <li>The calibration data is used to calibrate the temperature scaling.</li> </ul> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def train_model(\n    self,\n    dataset: TensorDataset,\n    loss_fn: Callable,\n    opt: torch.optim.Optimizer,\n    num_epochs: int,\n    batch_size: int = 64,\n    calib_frac: float = 0.1,\n    num_calibration_epochs: int = 2,\n    calibration_lr: float = 0.01,\n    vis_support: bool = False,\n    support_size: int = 25,\n) -&gt; Tuple[dict[str, Any], Optional[DataLoader[Any]]]:\n    \"\"\"\n    Train or fine-tune an EquineGP model.\n\n    Parameters\n    ----------\n    dataset : TensorDataset\n        An iterable, pytorch TensorDataset.\n    loss_fn : Callable\n        A pytorch loss function, e.g., torch.nn.CrossEntropyLoss().\n    opt : torch.optim.Optimizer\n        A pytorch optimizer, e.g., torch.optim.Adam().\n    num_epochs : int\n        The desired number of epochs to use for training.\n    batch_size : int, optional\n        The number of samples to use per batch.\n    calib_frac : float, optional\n        Fraction of training data to use in temperature scaling.\n    num_calibration_epochs : int, optional\n        The desired number of epochs to use for temperature scaling.\n    calibration_lr : float, optional\n        Learning rate for temperature scaling.\n\n    Returns\n    -------\n    Tuple[dict[str, Any], DataLoader]\n        A tuple containing the training history and a dataloader for the calibration data.\n\n    Notes\n    -------\n    - If `use_temperature` is True, temperature scaling will be used after training.\n    - The calibration data is used to calibrate the temperature scaling.\n    \"\"\"\n    if self.use_temperature:\n        X, Y = dataset[:]\n        train_x, calib_x, train_y, calib_y = train_test_split(\n            X, Y, test_size=calib_frac, stratify=Y\n        )  # TODO: Replace sklearn with torch call\n        dataset = TensorDataset(train_x, train_y)\n        self.temperature = torch.Tensor(\n            self.init_temperature * torch.ones(1)\n        ).type_as(self.temperature)\n\n    train_loader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=True, drop_last=True\n    )\n    self.model.set_training_params(\n        len(train_loader.sampler), train_loader.batch_size\n    )\n    self.model.train()\n    for _ in tqdm(range(num_epochs)):\n        self.model.reset_precision_matrix()\n        epoch_loss = 0.0\n        for i, (xs, labels) in enumerate(train_loader):\n            opt.zero_grad()\n            xs = xs.to(self.device)\n            labels = labels.to(self.device)\n            yhats = self.model(xs)\n            loss = loss_fn(yhats, labels.to(torch.long))\n            loss.backward()\n            opt.step()\n            epoch_loss += loss.item()\n    self.model.eval()\n\n    if vis_support:\n        self.update_support(dataset.tensors[0], dataset.tensors[1], support_size)\n\n    calibration_loader = None\n    if self.use_temperature:\n        dataset_calibration = TensorDataset(calib_x, calib_y)\n        calibration_loader = DataLoader(\n            dataset_calibration,\n            batch_size=batch_size,\n            shuffle=True,\n            drop_last=False,\n        )\n        self.calibrate_temperature(\n            calibration_loader, num_calibration_epochs, calibration_lr\n        )\n\n    _, train_y = dataset[:]\n    date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n    self.train_summary = generate_train_summary(self, train_y, date_trained)\n\n    return self.train_summary, calibration_loader\n</code></pre>"},{"location":"reference/equine/#equine.EquineGP.update_support","title":"<code>update_support(support_x, support_y, support_size)</code>","text":"<p>Function to update protonet support examples with given examples.</p> <p>Parameters:</p> Name Type Description Default <code>support_x</code> <code>Tensor</code> <p>Tensor containing support examples for protonet.</p> required <code>support_y</code> <code>Tensor</code> <p>Tensor containing labels for given support examples.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def update_support(\n    self, support_x: torch.Tensor, support_y: torch.Tensor, support_size: int\n) -&gt; None:\n    \"\"\"Function to update protonet support examples with given examples.\n\n    Parameters\n    ----------\n    support_x : torch.Tensor\n        Tensor containing support examples for protonet.\n    support_y : torch.Tensor\n        Tensor containing labels for given support examples.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    labels, counts = torch.unique(support_y, return_counts=True)\n    support = OrderedDict()\n    for label, count in list(zip(labels.tolist(), counts.tolist())):\n        class_support = generate_support(\n            support_x,\n            support_y,\n            support_size=min(count, support_size),\n            selected_labels=[label],\n        )\n        support.update(class_support)\n\n    self.support = support\n\n    support_embeddings = OrderedDict().fromkeys(support.keys())\n    for label in support:\n        support_embeddings[label] = self.compute_embeddings(support[label])\n\n    self.support_embeddings = support_embeddings\n\n    self.prototypes = self.compute_prototypes()\n</code></pre>"},{"location":"reference/equine/#equine.EquineOutput","title":"<code>EquineOutput</code>  <code>dataclass</code>","text":"<p>Output object containing prediction probabilities, OOD scores, and embeddings, which can be used for visualization.</p> <p>Attributes:</p> Name Type Description <code>classes</code> <code>Tensor</code> <p>Tensor of predicted class probabilities.</p> <code>ood_scores</code> <code>Tensor</code> <p>Tensor of out-of-distribution (OOD) scores.</p> <code>embeddings</code> <code>Tensor</code> <p>Tensor of embeddings produced by the model.</p> Source code in <code>src/equine/equine_output.py</code> <pre><code>@dataclass\nclass EquineOutput:\n    \"\"\"\n    Output object containing prediction probabilities, OOD scores, and embeddings, which can be used for visualization.\n\n    Attributes\n    ----------\n    classes : Tensor\n        Tensor of predicted class probabilities.\n    ood_scores : Tensor\n        Tensor of out-of-distribution (OOD) scores.\n    embeddings : Tensor\n        Tensor of embeddings produced by the model.\n    \"\"\"\n\n    classes: Tensor\n    ood_scores: Tensor\n    embeddings: Tensor\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet","title":"<code>EquineProtonet</code>","text":"<p>               Bases: <code>Equine</code></p> <p>A class representing an EQUINE model that utilizes protonets and (optionally) relative Mahalanobis distances to generate OOD and model confidence scores. This wraps any pytorch embedding neural network and provides the <code>forward</code>, <code>predict</code>, <code>save</code>, and <code>load</code> methods required by Equine.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>Neural Network feature embedding model.</p> required <code>emb_out_dim</code> <code>int</code> <p>The number of output features from the embedding model.</p> required <code>cov_type</code> <code>CovType</code> <p>The type of covariance to use when training the protonet [UNIT, DIAG, FULL], by default CovType.UNIT.</p> <code>UNIT</code> <code>relative_mahal</code> <code>bool</code> <p>Use relative mahalanobis distance for OOD calculations. If false, uses standard mahalanobis distance instead, by default True.</p> <code>True</code> <code>use_temperature</code> <code>bool</code> <p>Whether to use temperature scaling after training, by default False.</p> <code>False</code> <code>init_temperature</code> <code>float</code> <p>What to use as the initial temperature (1.0 has no effect), by default 1.0.</p> <code>1.0</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@beartype\nclass EquineProtonet(Equine):\n    \"\"\"\n    A class representing an EQUINE model that utilizes protonets and (optionally) relative Mahalanobis distances\n    to generate OOD and model confidence scores. This wraps any pytorch embedding neural network\n    and provides the `forward`, `predict`, `save`, and `load` methods required by Equine.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        Neural Network feature embedding model.\n    emb_out_dim : int\n        The number of output features from the embedding model.\n    cov_type : CovType, optional\n        The type of covariance to use when training the protonet [UNIT, DIAG, FULL], by default CovType.UNIT.\n    relative_mahal : bool, optional\n        Use relative mahalanobis distance for OOD calculations. If false, uses standard mahalanobis distance instead, by default True.\n    use_temperature : bool, optional\n        Whether to use temperature scaling after training, by default False.\n    init_temperature : float, optional\n        What to use as the initial temperature (1.0 has no effect), by default 1.0.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model,\n        emb_out_dim: int,\n        cov_type: CovType = CovType.UNIT,\n        relative_mahal: bool = True,\n        use_temperature: bool = False,\n        init_temperature: float = 1.0,\n    ) -&gt; None:\n        super().__init__(embedding_model)\n        self.cov_type = cov_type\n        self.cov_reg_type = COV_REG_TYPE\n        self.relative_mahal = relative_mahal\n        self.emb_out_dim = emb_out_dim\n        self.epsilon = DEFAULT_EPSILON\n        self.outlier_score_kde = None\n        self.model_summary = None\n        self.use_temperature = use_temperature\n        self.init_temperature = init_temperature\n        self.register_buffer(\n            \"temperature\", torch.Tensor(self.init_temperature * torch.ones(1))\n        )\n\n        self.model = Protonet(\n            embedding_model,\n            self.emb_out_dim,\n            self.cov_type,\n            self.cov_reg_type,\n            self.epsilon,\n        )\n\n    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Generates logits for classification based on the input tensor.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            The input tensor for generating predictions.\n\n        Returns\n        -------\n        torch.Tensor\n            The output class predictions.\n        \"\"\"\n        preds, _ = self.model(X)\n        return preds\n\n    @icontract.require(lambda calib_frac: calib_frac &gt; 0 and calib_frac &lt; 1)\n    def train_model(\n        self,\n        dataset: TensorDataset,\n        num_episodes: int,\n        calib_frac: float = 0.2,\n        support_size: int = 25,\n        way: int = 3,\n        episode_size: int = 100,\n        loss_fn: Callable = torch.nn.functional.cross_entropy,\n        opt_class: Callable = torch.optim.Adam,\n        num_calibration_epochs: int = 2,\n        calibration_lr: float = 0.01,\n    ) -&gt; tuple[dict[str, Any], torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Train or fine-tune an EquineProtonet model.\n\n        Parameters\n        ----------\n        dataset : TensorDataset\n            Input pytorch TensorDataset of training data for model.\n        num_episodes : int\n            The desired number of episodes to use for training.\n        calib_frac : float, optional\n            Fraction of given training data to reserve for model calibration, by default 0.2.\n        support_size : int, optional\n            Number of support examples to generate for each class, by default 25.\n        way : int, optional\n            Number of classes to train on per episode, by default 3.\n        episode_size : int, optional\n            Number of examples to use per episode, by default 100.\n        loss_fn : Callable, optional\n            A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.\n        opt_class : Callable, optional\n            A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.\n        num_calibration_epochs : int, optional\n            The desired number of epochs to use for temperature scaling, by default 2.\n        calibration_lr : float, optional\n            Learning rate for temperature scaling, by default 0.01.\n\n        Returns\n        -------\n        tuple[dict[str, Any], torch.Tensor, torch.Tensor]\n            A tuple containing the model summary, the held out calibration data, and the calibration labels.\n        \"\"\"\n        self.train()\n\n        if self.use_temperature:\n            self.temperature = torch.Tensor(\n                self.init_temperature * torch.ones(1)\n            ).type_as(self.temperature)\n\n        X, Y = dataset[:]\n\n        train_x, calib_x, train_y, calib_y = train_test_split(\n            X, Y, test_size=calib_frac, stratify=Y\n        )  # TODO: Replace sklearn with torch call\n        optimizer = opt_class(self.parameters())\n\n        for i in tqdm(range(num_episodes)):\n            optimizer.zero_grad()\n\n            support, episode_x, episode_y = generate_episode(\n                train_x, train_y, support_size, way, episode_size\n            )\n            self.model.update_support(support)\n\n            _, dists = self.model(episode_x)\n            loss_value = loss_fn(torch.neg(dists), episode_y)\n            loss_value.backward()\n            optimizer.step()\n\n        self.eval()\n        full_support = generate_support(\n            train_x,\n            train_y,\n            support_size,\n            selected_labels=torch.unique(train_y).tolist(),\n        )\n\n        self.model.update_support(\n            full_support\n        )  # update support with final selected examples\n\n        X_embed = self.model.compute_embeddings(calib_x)\n        pred_probs, dists = self.model(calib_x)\n        ood_dists = self._compute_ood_dist(X_embed, pred_probs, dists)\n        self._fit_outlier_scores(ood_dists, calib_y)\n\n        if self.use_temperature:\n            self.calibrate_temperature(\n                calib_x, calib_y, num_calibration_epochs, calibration_lr\n            )\n\n        date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n        self.train_summary = generate_train_summary(self, train_y, date_trained)\n        return self.train_summary, calib_x, calib_y\n\n    def calibrate_temperature(\n        self,\n        calib_x: torch.Tensor,\n        calib_y: torch.Tensor,\n        num_calibration_epochs: int = 1,\n        calibration_lr: float = 0.01,\n    ) -&gt; None:\n        \"\"\"\n        Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.\n\n        Parameters\n        ----------\n        calib_x : torch.Tensor\n            Training data to be used for temperature calibration.\n        calib_y : torch.Tensor\n            Labels corresponding to `calib_x`.\n        num_calibration_epochs : int, optional\n            Number of epochs to tune temperature, by default 1.\n        calibration_lr : float, optional\n            Learning rate for temperature optimization, by default 0.01.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.temperature.requires_grad = True\n        optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n        for t in range(num_calibration_epochs):\n            optimizer.zero_grad()\n            with torch.no_grad():\n                pred_probs, dists = self.model(calib_x)\n            dists = dists / self.temperature\n            loss = torch.nn.functional.cross_entropy(\n                torch.neg(dists), calib_y.to(torch.long)\n            )\n            loss.backward()\n            optimizer.step()\n        self.temperature.requires_grad = False\n\n    @icontract.ensure(lambda self: self.model.support_embeddings is not None)\n    def _fit_outlier_scores(\n        self, ood_dists: torch.Tensor, calib_y: torch.Tensor\n    ) -&gt; None:\n        \"\"\"\n        Private function to fit outlier scores with a kernel density estimate (KDE).\n\n        Parameters\n        ----------\n        ood_dists : torch.Tensor\n            Tensor of computed OOD distances.\n        calib_y : torch.Tensor\n            Tensor of class labels for `ood_dists` examples.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.outlier_score_kde = OrderedDict.fromkeys(\n            self.model.support_embeddings.keys()\n        )\n\n        for label in self.outlier_score_kde:\n            class_ood_dists = ood_dists[calib_y == int(label)].detach().numpy()\n            class_kde = gaussian_kde(class_ood_dists)  # TODO convert to torch func\n            self.outlier_score_kde[label] = class_kde\n\n    def _compute_outlier_scores(self, ood_dists, predictions) -&gt; torch.Tensor:\n        \"\"\"\n        Private function to compute OOD scores using the calculated kernel density estimate (KDE).\n\n        Parameters\n        ----------\n        ood_dists : torch.Tensor\n            Tensor of computed OOD distances.\n        predictions : torch.Tensor\n            Tensor of model protonet predictions.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of OOD scores for the given examples.\n        \"\"\"\n        ood_scores = torch.zeros_like(ood_dists)\n        for i in range(len(predictions)):\n            # Use KDE and RMD corresponding to the predicted class\n            predicted_class = int(torch.argmax(predictions[i, :]))\n            p_value = self.outlier_score_kde[int(predicted_class)].integrate_box_1d(\n                ood_dists[i].detach().numpy(), torch.inf\n            )\n            ood_scores[i] = 1.0 - p_value\n\n        return ood_scores\n\n    @icontract.ensure(lambda result: len(result) &gt; 0)\n    def _compute_ood_dist(\n        self,\n        X_embeddings: torch.Tensor,\n        predictions: torch.Tensor,\n        distances: torch.Tensor,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Private function to compute OOD distances using a distance function.\n\n        Parameters\n        ----------\n        X_embeddings : torch.Tensor\n            Tensor of example embeddings.\n        predictions : torch.Tensor\n            Tensor of model protonet predictions for the given embeddings.\n        distances : torch.Tensor\n            Tensor of calculated protonet distances for the given embeddings.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of OOD distances for the given embeddings.\n        \"\"\"\n        preds = torch.argmax(predictions, dim=1)\n        preds = preds.unsqueeze(dim=-1)\n        # Calculate (Relative) Mahalanobis Distance:\n        if self.relative_mahal:\n            null_distance = self.model.compute_distance(\n                X_embeddings, self.model.global_mean, self.model.global_covariance\n            )\n            null_distance = null_distance.unsqueeze(dim=-1)\n            ood_dist = distances.gather(1, preds) - null_distance\n        else:\n            ood_dist = distances.gather(1, preds)\n\n        ood_dist = torch.reshape(ood_dist, (-1,))\n        return ood_dist\n\n    def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n        \"\"\"Predict function for EquineProtonet, inherited and implemented from Equine.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        EquineOutput\n            Output object containing prediction probabilities and OOD scores.\n        \"\"\"\n        X_embed = self.model.compute_embeddings(X)\n        if X_embed.shape == torch.Size([self.model.emb_out_dim]):\n            X_embed = X_embed.unsqueeze(dim=0)  # Handle single examples\n        preds, dists = self.model(X)\n        if self.use_temperature:\n            dists = dists / self.temperature\n            preds = torch.softmax(torch.negative(dists), dim=1)\n        ood_dist = self._compute_ood_dist(X_embed, preds, dists)\n        ood_scores = self._compute_outlier_scores(ood_dist, preds)\n\n        return EquineOutput(classes=preds, ood_scores=ood_scores, embeddings=X_embed)\n\n    @icontract.require(lambda calib_frac: (calib_frac &gt; 0.0) and (calib_frac &lt; 1.0))\n    def update_support(\n        self, support_x: torch.Tensor, support_y: torch.Tensor, calib_frac: float\n    ) -&gt; None:\n        \"\"\"Function to update protonet support examples with given examples.\n\n        Parameters\n        ----------\n        support_x : torch.Tensor\n            Tensor containing support examples for protonet.\n        support_y : torch.Tensor\n            Tensor containing labels for given support examples.\n        calib_frac : float\n            Fraction of given support data to use for OOD calibration.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        support_x, calib_x, support_y, calib_y = train_test_split(\n            support_x, support_y, test_size=calib_frac, stratify=support_y\n        )\n        labels, counts = torch.unique(support_y, return_counts=True)\n        support = OrderedDict()\n        for label, count in list(zip(labels.tolist(), counts.tolist())):\n            class_support = generate_support(\n                support_x,\n                support_y,\n                support_size=count,\n                selected_labels=[label],\n            )\n            support.update(class_support)\n\n        self.model.update_support(support)\n\n        X_embed = self.model.compute_embeddings(calib_x)\n        preds, dists = self.model(calib_x)\n        ood_dists = self._compute_ood_dist(X_embed, preds, dists)\n\n        self._fit_outlier_scores(ood_dists, calib_y)\n\n    @icontract.require(lambda self: self.model.support is not None)\n    def get_support(self):\n        return self.model.support\n\n    @icontract.require(lambda self: self.model.prototypes is not None)\n    def get_prototypes(self):\n        return self.model.prototypes\n\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Save all model parameters to a file.\n\n        Parameters\n        ----------\n        path : str\n            Filename to write the model.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        model_settings = {\n            \"cov_type\": self.cov_type,\n            \"emb_out_dim\": self.emb_out_dim,\n            \"use_temperature\": self.use_temperature,\n            \"init_temperature\": self.temperature.item(),\n        }\n\n        jit_model = torch.jit.script(self.model.embedding_model)  # type: ignore\n        buffer = io.BytesIO()\n        torch.jit.save(jit_model, buffer)  # type: ignore\n        buffer.seek(0)\n\n        save_data = {\n            \"settings\": model_settings,\n            \"support\": self.model.support,\n            \"outlier_kde\": self.outlier_score_kde,\n            \"model_head_save\": self.model.model_head.state_dict(),\n            \"embed_jit_save\": buffer,\n            \"train_summary\": self.train_summary,\n        }\n\n        torch.save(save_data, path)  # TODO allow model checkpointing\n\n    @classmethod\n    def load(cls, path: str) -&gt; Equine:  # noqa: F821\n        \"\"\"\n        Load a previously saved EquineProtonet model.\n\n        Parameters\n        ----------\n        path : str\n            The filename of the saved model.\n\n        Returns\n        -------\n        EquineProtonet\n            The reconstituted EquineProtonet object.\n        \"\"\"\n        model_save = torch.load(path)\n        support = model_save[\"support\"]\n        jit_model = torch.jit.load(model_save[\"embed_jit_save\"])  # type: ignore\n        eq_model = cls(jit_model, **model_save[\"settings\"])\n\n        eq_model.model.model_head.load_state_dict(model_save[\"model_head_save\"])\n        eq_model.eval()\n        eq_model.model.update_support(support)\n        eq_model.outlier_score_kde = model_save[\"outlier_kde\"]\n        eq_model.train_summary = model_save[\"train_summary\"]\n\n        return eq_model\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.calibrate_temperature","title":"<code>calibrate_temperature(calib_x, calib_y, num_calibration_epochs=1, calibration_lr=0.01)</code>","text":"<p>Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.</p> <p>Parameters:</p> Name Type Description Default <code>calib_x</code> <code>Tensor</code> <p>Training data to be used for temperature calibration.</p> required <code>calib_y</code> <code>Tensor</code> <p>Labels corresponding to <code>calib_x</code>.</p> required <code>num_calibration_epochs</code> <code>int</code> <p>Number of epochs to tune temperature, by default 1.</p> <code>1</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature optimization, by default 0.01.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def calibrate_temperature(\n    self,\n    calib_x: torch.Tensor,\n    calib_y: torch.Tensor,\n    num_calibration_epochs: int = 1,\n    calibration_lr: float = 0.01,\n) -&gt; None:\n    \"\"\"\n    Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.\n\n    Parameters\n    ----------\n    calib_x : torch.Tensor\n        Training data to be used for temperature calibration.\n    calib_y : torch.Tensor\n        Labels corresponding to `calib_x`.\n    num_calibration_epochs : int, optional\n        Number of epochs to tune temperature, by default 1.\n    calibration_lr : float, optional\n        Learning rate for temperature optimization, by default 0.01.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self.temperature.requires_grad = True\n    optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n    for t in range(num_calibration_epochs):\n        optimizer.zero_grad()\n        with torch.no_grad():\n            pred_probs, dists = self.model(calib_x)\n        dists = dists / self.temperature\n        loss = torch.nn.functional.cross_entropy(\n            torch.neg(dists), calib_y.to(torch.long)\n        )\n        loss.backward()\n        optimizer.step()\n    self.temperature.requires_grad = False\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.forward","title":"<code>forward(X)</code>","text":"<p>Generates logits for classification based on the input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input tensor for generating predictions.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output class predictions.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Generates logits for classification based on the input tensor.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        The input tensor for generating predictions.\n\n    Returns\n    -------\n    torch.Tensor\n        The output class predictions.\n    \"\"\"\n    preds, _ = self.model(X)\n    return preds\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved EquineProtonet model.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The filename of the saved model.</p> required <p>Returns:</p> Type Description <code>EquineProtonet</code> <p>The reconstituted EquineProtonet object.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@classmethod\ndef load(cls, path: str) -&gt; Equine:  # noqa: F821\n    \"\"\"\n    Load a previously saved EquineProtonet model.\n\n    Parameters\n    ----------\n    path : str\n        The filename of the saved model.\n\n    Returns\n    -------\n    EquineProtonet\n        The reconstituted EquineProtonet object.\n    \"\"\"\n    model_save = torch.load(path)\n    support = model_save[\"support\"]\n    jit_model = torch.jit.load(model_save[\"embed_jit_save\"])  # type: ignore\n    eq_model = cls(jit_model, **model_save[\"settings\"])\n\n    eq_model.model.model_head.load_state_dict(model_save[\"model_head_save\"])\n    eq_model.eval()\n    eq_model.model.update_support(support)\n    eq_model.outlier_score_kde = model_save[\"outlier_kde\"]\n    eq_model.train_summary = model_save[\"train_summary\"]\n\n    return eq_model\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.predict","title":"<code>predict(X)</code>","text":"<p>Predict function for EquineProtonet, inherited and implemented from Equine.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>EquineOutput</code> <p>Output object containing prediction probabilities and OOD scores.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n    \"\"\"Predict function for EquineProtonet, inherited and implemented from Equine.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    EquineOutput\n        Output object containing prediction probabilities and OOD scores.\n    \"\"\"\n    X_embed = self.model.compute_embeddings(X)\n    if X_embed.shape == torch.Size([self.model.emb_out_dim]):\n        X_embed = X_embed.unsqueeze(dim=0)  # Handle single examples\n    preds, dists = self.model(X)\n    if self.use_temperature:\n        dists = dists / self.temperature\n        preds = torch.softmax(torch.negative(dists), dim=1)\n    ood_dist = self._compute_ood_dist(X_embed, preds, dists)\n    ood_scores = self._compute_outlier_scores(ood_dist, preds)\n\n    return EquineOutput(classes=preds, ood_scores=ood_scores, embeddings=X_embed)\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.save","title":"<code>save(path)</code>","text":"<p>Save all model parameters to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Filename to write the model.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def save(self, path: str) -&gt; None:\n    \"\"\"\n    Save all model parameters to a file.\n\n    Parameters\n    ----------\n    path : str\n        Filename to write the model.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    model_settings = {\n        \"cov_type\": self.cov_type,\n        \"emb_out_dim\": self.emb_out_dim,\n        \"use_temperature\": self.use_temperature,\n        \"init_temperature\": self.temperature.item(),\n    }\n\n    jit_model = torch.jit.script(self.model.embedding_model)  # type: ignore\n    buffer = io.BytesIO()\n    torch.jit.save(jit_model, buffer)  # type: ignore\n    buffer.seek(0)\n\n    save_data = {\n        \"settings\": model_settings,\n        \"support\": self.model.support,\n        \"outlier_kde\": self.outlier_score_kde,\n        \"model_head_save\": self.model.model_head.state_dict(),\n        \"embed_jit_save\": buffer,\n        \"train_summary\": self.train_summary,\n    }\n\n    torch.save(save_data, path)  # TODO allow model checkpointing\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.train_model","title":"<code>train_model(dataset, num_episodes, calib_frac=0.2, support_size=25, way=3, episode_size=100, loss_fn=torch.nn.functional.cross_entropy, opt_class=torch.optim.Adam, num_calibration_epochs=2, calibration_lr=0.01)</code>","text":"<p>Train or fine-tune an EquineProtonet model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>TensorDataset</code> <p>Input pytorch TensorDataset of training data for model.</p> required <code>num_episodes</code> <code>int</code> <p>The desired number of episodes to use for training.</p> required <code>calib_frac</code> <code>float</code> <p>Fraction of given training data to reserve for model calibration, by default 0.2.</p> <code>0.2</code> <code>support_size</code> <code>int</code> <p>Number of support examples to generate for each class, by default 25.</p> <code>25</code> <code>way</code> <code>int</code> <p>Number of classes to train on per episode, by default 3.</p> <code>3</code> <code>episode_size</code> <code>int</code> <p>Number of examples to use per episode, by default 100.</p> <code>100</code> <code>loss_fn</code> <code>Callable</code> <p>A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.</p> <code>cross_entropy</code> <code>opt_class</code> <code>Callable</code> <p>A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.</p> <code>Adam</code> <code>num_calibration_epochs</code> <code>int</code> <p>The desired number of epochs to use for temperature scaling, by default 2.</p> <code>2</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature scaling, by default 0.01.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>tuple[dict[str, Any], Tensor, Tensor]</code> <p>A tuple containing the model summary, the held out calibration data, and the calibration labels.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda calib_frac: calib_frac &gt; 0 and calib_frac &lt; 1)\ndef train_model(\n    self,\n    dataset: TensorDataset,\n    num_episodes: int,\n    calib_frac: float = 0.2,\n    support_size: int = 25,\n    way: int = 3,\n    episode_size: int = 100,\n    loss_fn: Callable = torch.nn.functional.cross_entropy,\n    opt_class: Callable = torch.optim.Adam,\n    num_calibration_epochs: int = 2,\n    calibration_lr: float = 0.01,\n) -&gt; tuple[dict[str, Any], torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Train or fine-tune an EquineProtonet model.\n\n    Parameters\n    ----------\n    dataset : TensorDataset\n        Input pytorch TensorDataset of training data for model.\n    num_episodes : int\n        The desired number of episodes to use for training.\n    calib_frac : float, optional\n        Fraction of given training data to reserve for model calibration, by default 0.2.\n    support_size : int, optional\n        Number of support examples to generate for each class, by default 25.\n    way : int, optional\n        Number of classes to train on per episode, by default 3.\n    episode_size : int, optional\n        Number of examples to use per episode, by default 100.\n    loss_fn : Callable, optional\n        A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.\n    opt_class : Callable, optional\n        A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.\n    num_calibration_epochs : int, optional\n        The desired number of epochs to use for temperature scaling, by default 2.\n    calibration_lr : float, optional\n        Learning rate for temperature scaling, by default 0.01.\n\n    Returns\n    -------\n    tuple[dict[str, Any], torch.Tensor, torch.Tensor]\n        A tuple containing the model summary, the held out calibration data, and the calibration labels.\n    \"\"\"\n    self.train()\n\n    if self.use_temperature:\n        self.temperature = torch.Tensor(\n            self.init_temperature * torch.ones(1)\n        ).type_as(self.temperature)\n\n    X, Y = dataset[:]\n\n    train_x, calib_x, train_y, calib_y = train_test_split(\n        X, Y, test_size=calib_frac, stratify=Y\n    )  # TODO: Replace sklearn with torch call\n    optimizer = opt_class(self.parameters())\n\n    for i in tqdm(range(num_episodes)):\n        optimizer.zero_grad()\n\n        support, episode_x, episode_y = generate_episode(\n            train_x, train_y, support_size, way, episode_size\n        )\n        self.model.update_support(support)\n\n        _, dists = self.model(episode_x)\n        loss_value = loss_fn(torch.neg(dists), episode_y)\n        loss_value.backward()\n        optimizer.step()\n\n    self.eval()\n    full_support = generate_support(\n        train_x,\n        train_y,\n        support_size,\n        selected_labels=torch.unique(train_y).tolist(),\n    )\n\n    self.model.update_support(\n        full_support\n    )  # update support with final selected examples\n\n    X_embed = self.model.compute_embeddings(calib_x)\n    pred_probs, dists = self.model(calib_x)\n    ood_dists = self._compute_ood_dist(X_embed, pred_probs, dists)\n    self._fit_outlier_scores(ood_dists, calib_y)\n\n    if self.use_temperature:\n        self.calibrate_temperature(\n            calib_x, calib_y, num_calibration_epochs, calibration_lr\n        )\n\n    date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n    self.train_summary = generate_train_summary(self, train_y, date_trained)\n    return self.train_summary, calib_x, calib_y\n</code></pre>"},{"location":"reference/equine/#equine.EquineProtonet.update_support","title":"<code>update_support(support_x, support_y, calib_frac)</code>","text":"<p>Function to update protonet support examples with given examples.</p> <p>Parameters:</p> Name Type Description Default <code>support_x</code> <code>Tensor</code> <p>Tensor containing support examples for protonet.</p> required <code>support_y</code> <code>Tensor</code> <p>Tensor containing labels for given support examples.</p> required <code>calib_frac</code> <code>float</code> <p>Fraction of given support data to use for OOD calibration.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda calib_frac: (calib_frac &gt; 0.0) and (calib_frac &lt; 1.0))\ndef update_support(\n    self, support_x: torch.Tensor, support_y: torch.Tensor, calib_frac: float\n) -&gt; None:\n    \"\"\"Function to update protonet support examples with given examples.\n\n    Parameters\n    ----------\n    support_x : torch.Tensor\n        Tensor containing support examples for protonet.\n    support_y : torch.Tensor\n        Tensor containing labels for given support examples.\n    calib_frac : float\n        Fraction of given support data to use for OOD calibration.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    support_x, calib_x, support_y, calib_y = train_test_split(\n        support_x, support_y, test_size=calib_frac, stratify=support_y\n    )\n    labels, counts = torch.unique(support_y, return_counts=True)\n    support = OrderedDict()\n    for label, count in list(zip(labels.tolist(), counts.tolist())):\n        class_support = generate_support(\n            support_x,\n            support_y,\n            support_size=count,\n            selected_labels=[label],\n        )\n        support.update(class_support)\n\n    self.model.update_support(support)\n\n    X_embed = self.model.compute_embeddings(calib_x)\n    preds, dists = self.model(calib_x)\n    ood_dists = self._compute_ood_dist(X_embed, preds, dists)\n\n    self._fit_outlier_scores(ood_dists, calib_y)\n</code></pre>"},{"location":"reference/equine/#equine.brier_score","title":"<code>brier_score(y_hat, y_test)</code>","text":"<p>Compute the Brier score for a multiclass problem.</p> <p>Parameters:</p> Name Type Description Default <code>y_hat</code> <code>Tensor</code> <p>Probabilities for each class.</p> required <code>y_test</code> <code>Tensor</code> <p>Integer argument class labels (ground truth).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Brier score.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda y_hat, y_test: y_hat.size(dim=0) == y_test.size(dim=0))\n@icontract.ensure(lambda result: result &gt;= 0.0)\n@beartype\ndef brier_score(y_hat: torch.Tensor, y_test: torch.Tensor) -&gt; float:\n    \"\"\"\n    Compute the Brier score for a multiclass problem.\n\n    Parameters\n    ----------\n    y_hat : torch.Tensor\n        Probabilities for each class.\n    y_test : torch.Tensor\n        Integer argument class labels (ground truth).\n\n    Returns\n    -------\n    float\n        Brier score.\n    \"\"\"\n    (_, num_classes) = y_hat.size()\n    one_hot_y_test = torch.nn.functional.one_hot(y_test.long(), num_classes=num_classes)\n    bs = torch.mean(torch.sum((y_hat - one_hot_y_test) ** 2, dim=1)).item()\n    return bs\n</code></pre>"},{"location":"reference/equine/#equine.brier_skill_score","title":"<code>brier_skill_score(y_hat, y_test)</code>","text":"<p>Compute the Brier skill score as compared to randomly guessing.</p> <p>Parameters:</p> Name Type Description Default <code>y_hat</code> <code>Tensor</code> <p>Probabilities for each class.</p> required <code>y_test</code> <code>Tensor</code> <p>Integer argument class labels (ground truth).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Brier skill score.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda y_hat, y_test: y_hat.size(dim=0) == y_test.size(dim=0))\n@icontract.ensure(lambda result: result &lt;= 1.0)\n@beartype\ndef brier_skill_score(y_hat: torch.Tensor, y_test: torch.Tensor) -&gt; float:\n    \"\"\"\n    Compute the Brier skill score as compared to randomly guessing.\n\n    Parameters\n    ----------\n    y_hat : torch.Tensor\n        Probabilities for each class.\n    y_test : torch.Tensor\n        Integer argument class labels (ground truth).\n\n    Returns\n    -------\n    float\n        Brier skill score.\n    \"\"\"\n    (_, num_classes) = y_hat.size()\n    random_guess = (1.0 / num_classes) * torch.ones(y_hat.size())\n    bs0 = brier_score(random_guess, y_test)\n    bs1 = brier_score(y_hat, y_test)\n    bss = 1.0 - bs1 / bs0\n    return bss\n</code></pre>"},{"location":"reference/equine/#equine.expected_calibration_error","title":"<code>expected_calibration_error(y_hat, y_test)</code>","text":"<p>Compute the expected calibration error (ECE) for a multiclass problem.</p> <p>Parameters:</p> Name Type Description Default <code>y_hat</code> <code>Tensor</code> <p>Probabilities for each class.</p> required <code>y_test</code> <code>Tensor</code> <p>Class label indices (ground truth).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Expected calibration error.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda y_hat, y_test: y_hat.size(dim=0) == y_test.size(dim=0))\n@icontract.ensure(lambda result: (0.0 &lt;= result) and (result &lt;= 1.0))\n@beartype\ndef expected_calibration_error(y_hat: torch.Tensor, y_test: torch.Tensor) -&gt; float:\n    \"\"\"\n    Compute the expected calibration error (ECE) for a multiclass problem.\n\n    Parameters\n    ----------\n    y_hat : torch.Tensor\n        Probabilities for each class.\n    y_test : torch.Tensor\n        Class label indices (ground truth).\n\n    Returns\n    -------\n    float\n        Expected calibration error.\n    \"\"\"\n    (_, num_classes) = y_hat.size()\n    metric = MulticlassCalibrationError(num_classes=num_classes, n_bins=25, norm=\"l1\")\n    ece = metric(y_hat, y_test).item()\n    return ece\n</code></pre>"},{"location":"reference/equine/#equine.generate_episode","title":"<code>generate_episode(train_x, train_y, support_size, way, episode_size)</code>","text":"<p>Generate a single episode of data for a few-shot learning task.</p> <p>Parameters:</p> Name Type Description Default <code>train_x</code> <code>Tensor</code> <p>Input training data.</p> required <code>train_y</code> <code>Tensor</code> <p>Corresponding classification labels.</p> required <code>support_size</code> <code>int</code> <p>Number of support examples for each class.</p> required <code>way</code> <code>int</code> <p>Number of classes in the episode.</p> required <code>episode_size</code> <code>int</code> <p>Total number of examples in the episode.</p> required <p>Returns:</p> Type Description <code>Tuple[dict[Any, Tensor], Tensor, Tensor]</code> <p>Tuple of support examples, query examples, and query labels.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda train_x: len(train_x.shape) &gt;= 2)\n@icontract.require(lambda train_y: len(train_y.shape) == 1)\n@icontract.require(lambda support_size: support_size &gt; 1)\n@icontract.require(lambda way: way &gt; 0)\n@icontract.require(lambda episode_size: episode_size &gt; 0)\n@icontract.ensure(lambda result: len(result) == 3)\n@icontract.ensure(lambda result: result[1].shape[0] == result[2].shape[0])\n@icontract.ensure(lambda way, result: len(result[0]) == way)\n@icontract.ensure(\n    lambda support_size, result: all(\n        len(support) == support_size for support in result[0].values()\n    )\n)\n@beartype\ndef generate_episode(\n    train_x: torch.Tensor,\n    train_y: torch.Tensor,\n    support_size: int,\n    way: int,\n    episode_size: int,\n) -&gt; Tuple[dict[Any, torch.Tensor], torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Generate a single episode of data for a few-shot learning task.\n\n    Parameters\n    ----------\n    train_x : torch.Tensor\n        Input training data.\n    train_y : torch.Tensor\n        Corresponding classification labels.\n    support_size : int\n        Number of support examples for each class.\n    way : int\n        Number of classes in the episode.\n    episode_size : int\n        Total number of examples in the episode.\n\n    Returns\n    -------\n    Tuple[dict[Any, torch.Tensor], torch.Tensor, torch.Tensor]\n        Tuple of support examples, query examples, and query labels.\n    \"\"\"\n    labels, counts = torch.unique(train_y, return_counts=True)\n    if way &gt; len(labels):\n        raise ValueError(\n            f\"The way (#classes in each episode), {way}, must be &lt;= number of labels, {len(labels)}\"\n        )\n\n    selected_labels = sorted(\n        labels[torch.randperm(labels.shape[0])][:way].tolist()\n    )  # need to be in same order every time\n\n    for label, count in list(zip(labels, counts)):\n        if (label in selected_labels) and (count &lt; support_size):\n            raise ValueError(f\"Not enough support examples in class {label}\")\n    shuffled_idxs = _get_shuffle_idxs_by_class(train_y, selected_labels)\n\n    support = generate_support(\n        train_x, train_y, support_size, selected_labels, shuffled_idxs\n    )\n\n    examples_per_task = episode_size // way\n\n    episode_data_list = []\n    episode_label_list = []\n    episode_support = OrderedDict()\n    for episode_label, label in enumerate(selected_labels):\n        shuffled_x = train_x[shuffled_idxs[label]]\n        shuffled_y = torch.Tensor(\n            [episode_label] * len(shuffled_idxs[label])\n        )  # need sequential labels for episode\n\n        num_remaining_examples = shuffled_x.shape[0] - support_size\n        assert num_remaining_examples &gt; 0, (\n            \"Cannot have \"\n            + str(num_remaining_examples)\n            + \" left with support_size \"\n            + str(support_size)\n            + \" and shape \"\n            + str(shuffled_x.shape)\n            + \" from train_x shaped \"\n            + str(train_x.shape)\n        )\n        episode_end_idx = support_size + min(num_remaining_examples, examples_per_task)\n\n        episode_data_list.append(shuffled_x[support_size:episode_end_idx])\n        episode_label_list.append(shuffled_y[support_size:episode_end_idx])\n        episode_support[episode_label] = support[label]\n\n    episode_x = torch.concat(episode_data_list)\n    episode_y = torch.concat(episode_label_list)\n\n    return episode_support, episode_x, episode_y.squeeze().to(torch.long)\n</code></pre>"},{"location":"reference/equine/#equine.generate_model_metrics","title":"<code>generate_model_metrics(eq_preds, true_y)</code>","text":"<p>Generate various metrics for evaluating a model's performance.</p> <p>Parameters:</p> Name Type Description Default <code>eq_preds</code> <code>EquineOutput</code> <p>Model predictions.</p> required <code>true_y</code> <code>Tensor</code> <p>True class labels.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of model metrics.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(\n    lambda eq_preds, true_y: eq_preds.classes.size(dim=0) == true_y.size(dim=0)\n)\n@beartype\ndef generate_model_metrics(\n    eq_preds: EquineOutput, true_y: torch.Tensor\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate various metrics for evaluating a model's performance.\n\n    Parameters\n    ----------\n    eq_preds : EquineOutput\n        Model predictions.\n    true_y : torch.Tensor\n        True class labels.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary of model metrics.\n    \"\"\"\n    pred_y = torch.argmax(eq_preds.classes, dim=1)\n    metrics = {\n        \"accuracy\": accuracy_score(true_y, pred_y),\n        \"microF1Score\": f1_score(true_y, pred_y, average=\"micro\"),\n        \"confusionMatrix\": confusion_matrix(true_y, pred_y).tolist(),\n        \"brierScore\": brier_score(eq_preds.classes, true_y),\n        \"brierSkillScore\": brier_skill_score(eq_preds.classes, true_y),\n        \"expectedCalibrationError\": expected_calibration_error(\n            eq_preds.classes, true_y\n        ),\n    }\n    return metrics\n</code></pre>"},{"location":"reference/equine/#equine.generate_model_summary","title":"<code>generate_model_summary(model, eq_preds, test_y)</code>","text":"<p>Generate a summary of the model's performance.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Equine</code> <p>Model object.</p> required <code>eq_preds</code> <code>EquineOutput</code> <p>Model predictions.</p> required <code>test_y</code> <code>Tensor</code> <p>True class labels.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing model summary.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(\n    lambda eq_preds, test_y: test_y.shape[0] == eq_preds.classes.shape[0]\n)\n@beartype\ndef generate_model_summary(\n    model: Equine,\n    eq_preds: EquineOutput,\n    test_y: torch.Tensor,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate a summary of the model's performance.\n\n    Parameters\n    ----------\n    model : Equine\n        Model object.\n    eq_preds : EquineOutput\n        Model predictions.\n    test_y : torch.Tensor\n        True class labels.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing model summary.\n    \"\"\"\n    summary = generate_model_metrics(eq_preds, test_y)\n    summary[\"numTestExamples\"] = get_num_examples_per_label(test_y)\n    summary.update(model.train_summary)  # union of train_summary and generated metrics\n\n    return summary\n</code></pre>"},{"location":"reference/equine/#equine.generate_support","title":"<code>generate_support(train_x, train_y, support_size, selected_labels, shuffled_indexes=None)</code>","text":"<p>Randomly select <code>support_size</code> examples of <code>way</code> classes from the examples in <code>train_x</code> with corresponding labels in <code>train_y</code> and return them as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>train_x</code> <code>Tensor</code> <p>Input training data.</p> required <code>train_y</code> <code>Tensor</code> <p>Corresponding classification labels.</p> required <code>support_size</code> <code>int</code> <p>Number of support examples for each class.</p> required <code>selected_labels</code> <code>List</code> <p>Selected class labels to generate examples from.</p> required <code>shuffled_indexes</code> <code>Union[None, dict[Any, Tensor]]</code> <p>Simply use the precomputed indexes if they are available</p> <code>None</code> <p>Returns:</p> Type Description <code>OrderedDict[int, Tensor]</code> <p>Ordered dictionary of class labels with corresponding support examples.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda train_x, train_y: len(train_x) &lt;= len(train_y))\n@icontract.require(\n    lambda selected_labels, train_x: (0 &lt; len(selected_labels))\n    &amp; (len(selected_labels) &lt; len(train_x))\n)\n@icontract.require(\n    lambda support_size, train_x: (0 &lt; support_size) &amp; (support_size &lt; len(train_x))\n)\n@icontract.require(\n    lambda support_size, selected_labels, train_x: support_size * len(selected_labels)\n    &lt;= len(train_x)\n)\n@icontract.require(\n    lambda selected_labels, shuffled_indexes: (\n        (len(shuffled_indexes.keys()) == len(selected_labels))\n        if shuffled_indexes is not None\n        else True\n    )\n)\n@icontract.ensure(\n    lambda result, selected_labels: len(result.keys()) == len(selected_labels)\n)\n@beartype\ndef generate_support(\n    train_x: torch.Tensor,\n    train_y: torch.Tensor,\n    support_size: int,\n    selected_labels: List[Any],\n    shuffled_indexes: Union[None, dict[Any, torch.Tensor]] = None,\n) -&gt; OrderedDict[int, torch.Tensor]:\n    \"\"\"\n    Randomly select `support_size` examples of `way` classes from the examples in\n    `train_x` with corresponding labels in `train_y` and return them as a dictionary.\n\n    Parameters\n    ----------\n    train_x : torch.Tensor\n        Input training data.\n    train_y : torch.Tensor\n        Corresponding classification labels.\n    support_size : int\n        Number of support examples for each class.\n    selected_labels : List\n        Selected class labels to generate examples from.\n    shuffled_indexes: Union[None, dict[Any, torch.Tensor]], optional\n        Simply use the precomputed indexes if they are available\n\n    Returns\n    -------\n    OrderedDict[int, torch.Tensor]\n        Ordered dictionary of class labels with corresponding support examples.\n    \"\"\"\n    labels, counts = torch.unique(train_y, return_counts=True)\n    if shuffled_indexes is None:\n        for label, count in list(zip(labels, counts)):\n            if (label in selected_labels) and (count &lt; support_size):\n                raise ValueError(f\"Not enough support examples in class {label}\")\n        shuffled_idxs = _get_shuffle_idxs_by_class(train_y, selected_labels)\n    else:\n        shuffled_idxs = shuffled_indexes\n\n    support = OrderedDict[int, torch.Tensor]()\n    for label in selected_labels:\n        shuffled_x = train_x[shuffled_idxs[label]]\n\n        assert torch.unique(train_y[shuffled_idxs[label]]).tolist() == [\n            label\n        ], \"Not enough support for label \" + str(label)\n        selected_support = shuffled_x[:support_size]\n        support[int(label)] = selected_support\n\n    return support\n</code></pre>"},{"location":"reference/equine/#equine.generate_train_summary","title":"<code>generate_train_summary(model, train_y, date_trained)</code>","text":"<p>Generate a summary of the training data.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Equine</code> <p>Model object.</p> required <code>train_y</code> <code>Tensor</code> <p>Training labels.</p> required <code>date_trained</code> <code>str</code> <p>Date of training.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing training summary.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda train_y: train_y.shape[0] &gt; 0)\n@beartype\ndef generate_train_summary(\n    model: Equine, train_y: torch.Tensor, date_trained: str\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate a summary of the training data.\n\n    Parameters\n    ----------\n    model : Equine\n        Model object.\n    train_y : torch.Tensor\n        Training labels.\n    date_trained : str\n        Date of training.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing training summary.\n    \"\"\"\n    train_summary = {\n        \"numTrainExamples\": get_num_examples_per_label(train_y),\n        \"dateTrained\": date_trained,\n        \"modelType\": model.__class__.__name__,\n    }\n    return train_summary\n</code></pre>"},{"location":"reference/equine/#equine.mahalanobis_distance_nosq","title":"<code>mahalanobis_distance_nosq(x, cov)</code>","text":"<p>Compute Mahalanobis distance x^T C x (without square root), assume cov is symmetric positive definite</p> <pre><code>Parameters\n</code></pre> <pre><code>x : torch.Tensor\n    vectors to compute distances for\ncov : torch.Tensor\n    covariance matrix, assumes first dimension is number of classes\n</code></pre> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda cov: cov.shape[-2] == cov.shape[-1])\ndef mahalanobis_distance_nosq(x: torch.Tensor, cov: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute Mahalanobis distance x^T C x (without square root), assume cov is symmetric positive definite\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            vectors to compute distances for\n        cov : torch.Tensor\n            covariance matrix, assumes first dimension is number of classes\n    \"\"\"\n    U, S, _ = torch.linalg.svd(cov)\n    S_inv_sqrt = torch.stack(\n        [torch.diag(torch.sqrt(1.0 / S[i])) for i in range(S.shape[0])], dim=0\n    )\n    prod = torch.matmul(S_inv_sqrt, torch.transpose(U, 1, 2))\n    dist = torch.sum(torch.square(torch.matmul(prod, x)), dim=1)\n    return dist\n</code></pre>"},{"location":"reference/equine/_version/","title":"_version","text":""},{"location":"reference/equine/equine/","title":"equine","text":""},{"location":"reference/equine/equine/#equine.equine.Equine","title":"<code>Equine</code>","text":"<p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>EQUINE Abstract Base Class (ABC): EQUINE is set up to extend torch's nn.Module to enrich it with a method that enables uncertainty quantification and visualization. Most importantly, the <code>.predict()</code> method must be outfitted to return an EquineOutput object that contains both the class probabilities and an out-of-distribution (ood) score.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>The embedding model to use.</p> required <code>head_layers</code> <code>int</code> <p>The number of layers to use in the model head, by default 1.</p> <code>1</code> <p>Attributes:</p> Name Type Description <code>embedding_model</code> <code>Module</code> <p>The neural embedding model to enrich with uncertainty quantification.</p> <code>head_layers</code> <code>int</code> <p>The number of linear layers to append to the embedding model (default 1, not always used).</p> <code>train_summary</code> <code>dict[str, Any]</code> <p>A dictionary containing information about the model training.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If any of the abstract methods are not implemented.</p> Source code in <code>src/equine/equine.py</code> <pre><code>class Equine(torch.nn.Module, ABC):\n    \"\"\"EQUINE Abstract Base Class (ABC):\n    EQUINE is set up to extend torch's nn.Module to enrich it with\n    a method that enables uncertainty quantification and visualization. Most\n    importantly, the `.predict()` method must be outfitted to return an\n    EquineOutput object that contains both the class probabilities\n    *and* an out-of-distribution (ood) score.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        The embedding model to use.\n    head_layers : int, optional\n        The number of layers to use in the model head, by default 1.\n\n    Attributes\n    ----------\n    embedding_model : torch.nn.Module\n        The neural embedding model to enrich with uncertainty quantification.\n    head_layers : int\n        The number of linear layers to append to the embedding model (default 1, not always used).\n    train_summary : dict[str, Any]\n        A dictionary containing information about the model training.\n\n    Raises\n    ------\n    NotImplementedError\n        If any of the abstract methods are not implemented.\n    \"\"\"\n\n    def __init__(self, embedding_model: torch.nn.Module, head_layers: int = 1) -&gt; None:\n        super().__init__()\n        self.embedding_model = embedding_model\n        self.head_layers = head_layers\n        self.train_summary: dict[str, Any] = {\n            \"numTrainExamples\": 0,\n            \"dateTrained\": \"\",\n            \"modelType\": \"\",\n        }\n\n        self.support = None\n        self.support_embeddings = None\n        self.prototypes = None\n\n    @abstractmethod\n    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the model. This is to preserve the usual behavior\n        of torch.nn.Module.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            The input data.\n\n        Returns\n        -------\n        torch.Tensor\n            The output of the model.\n\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n        \"\"\"\n        Upon implementation, predicts the class logits and out-of-distribution (ood) scores for the\n        given input data.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            The input data.\n\n        Returns\n        -------\n        EquineOutput\n            An EquineOutput object containing the class probabilities and OOD scores.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def train_model(self, dataset: TensorDataset, **kwargs: Any) -&gt; dict[str, Any]:\n        \"\"\"\n        Upon implementation, train the model on the given dataset.\n\n        Parameters\n        ----------\n        dataset : TensorDataset\n            TensorDataset containing the training data.\n        **kwargs\n            Additional keyword arguments to pass to the training function.\n\n        Returns\n        -------\n        dict[str, Any]\n            Dictionary containing summary training information.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_prototypes(self) -&gt; torch.Tensor:\n        \"\"\"\n        Upon implementation, returns the prototype embeddings\n\n        Returns\n        -------\n        torch.Tensor\n            A torch tensor of the prototype embeddings\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Upon implementation, save the model to the given file path.\n\n        Parameters\n        ----------\n        path : str\n            File path to save the model to.\n        \"\"\"\n        raise NotImplementedError\n\n    @classmethod  # type: ignore\n    def load(cls: AnyEquine, path: str) -&gt; AnyEquine:  # noqa: F821 # type: ignore\n        \"\"\"\n        Upon implementation, load the model from the given file path.\n\n        Parameters\n        ----------\n        path : str\n            File path to load the model from.\n\n        Returns\n        -------\n        Equine\n            Loaded model object.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine/#equine.equine.Equine.forward","title":"<code>forward(X)</code>  <code>abstractmethod</code>","text":"<p>Forward pass of the model. This is to preserve the usual behavior of torch.nn.Module.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input data.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output of the model.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the model. This is to preserve the usual behavior\n    of torch.nn.Module.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        The input data.\n\n    Returns\n    -------\n    torch.Tensor\n        The output of the model.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine/#equine.equine.Equine.get_prototypes","title":"<code>get_prototypes()</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, returns the prototype embeddings</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A torch tensor of the prototype embeddings</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef get_prototypes(self) -&gt; torch.Tensor:\n    \"\"\"\n    Upon implementation, returns the prototype embeddings\n\n    Returns\n    -------\n    torch.Tensor\n        A torch tensor of the prototype embeddings\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine/#equine.equine.Equine.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Upon implementation, load the model from the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to load the model from.</p> required <p>Returns:</p> Type Description <code>Equine</code> <p>Loaded model object.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@classmethod  # type: ignore\ndef load(cls: AnyEquine, path: str) -&gt; AnyEquine:  # noqa: F821 # type: ignore\n    \"\"\"\n    Upon implementation, load the model from the given file path.\n\n    Parameters\n    ----------\n    path : str\n        File path to load the model from.\n\n    Returns\n    -------\n    Equine\n        Loaded model object.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine/#equine.equine.Equine.predict","title":"<code>predict(X)</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, predicts the class logits and out-of-distribution (ood) scores for the given input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input data.</p> required <p>Returns:</p> Type Description <code>EquineOutput</code> <p>An EquineOutput object containing the class probabilities and OOD scores.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef predict(self, X: torch.Tensor) -&gt; EquineOutput:\n    \"\"\"\n    Upon implementation, predicts the class logits and out-of-distribution (ood) scores for the\n    given input data.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        The input data.\n\n    Returns\n    -------\n    EquineOutput\n        An EquineOutput object containing the class probabilities and OOD scores.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine/#equine.equine.Equine.save","title":"<code>save(path)</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, save the model to the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to save the model to.</p> required Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef save(self, path: str) -&gt; None:\n    \"\"\"\n    Upon implementation, save the model to the given file path.\n\n    Parameters\n    ----------\n    path : str\n        File path to save the model to.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine/#equine.equine.Equine.train_model","title":"<code>train_model(dataset, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Upon implementation, train the model on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>TensorDataset</code> <p>TensorDataset containing the training data.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the training function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing summary training information.</p> Source code in <code>src/equine/equine.py</code> <pre><code>@abstractmethod\ndef train_model(self, dataset: TensorDataset, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"\n    Upon implementation, train the model on the given dataset.\n\n    Parameters\n    ----------\n    dataset : TensorDataset\n        TensorDataset containing the training data.\n    **kwargs\n        Additional keyword arguments to pass to the training function.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing summary training information.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/equine/equine_gp/","title":"equine_gp","text":""},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP","title":"<code>EquineGP</code>","text":"<p>               Bases: <code>Equine</code></p> <p>An example of an EQUINE model that builds upon the approach in \"Spectral Norm Gaussian Processes\" (SNGP). This wraps any pytorch embedding neural network and provides the <code>forward</code>, <code>predict</code>, <code>save</code>, and <code>load</code> methods required by Equine.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>Neural Network feature embedding.</p> required <code>emb_out_dim</code> <code>int</code> <p>The number of deep features from the feature embedding.</p> required <code>num_classes</code> <code>int</code> <p>The number of output classes this model predicts.</p> required <code>use_temperature</code> <code>bool</code> <p>Whether to use temperature scaling after training.</p> <code>False</code> <code>init_temperature</code> <code>float</code> <p>What to use as the initial temperature (1.0 has no effect).</p> <code>1.0</code> <code>device</code> <code>str</code> <p>Either 'cuda' or 'cpu'.</p> <code>'cpu'</code> Notes <p>Although this model build upon the approach in SNGP, it does not enforce the spectral normalization and ResNet architecture required for SNGP. Instead, it is a simple wrapper around any pytorch embedding neural network. Your mileage may vary.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@beartype\nclass EquineGP(Equine):\n    \"\"\"\n    An example of an EQUINE model that builds upon the approach in \"Spectral Norm\n    Gaussian Processes\" (SNGP). This wraps any pytorch embedding neural network and provides\n    the `forward`, `predict`, `save`, and `load` methods required by Equine.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        Neural Network feature embedding.\n    emb_out_dim : int\n        The number of deep features from the feature embedding.\n    num_classes : int\n        The number of output classes this model predicts.\n    use_temperature : bool, optional\n        Whether to use temperature scaling after training.\n    init_temperature : float, optional\n        What to use as the initial temperature (1.0 has no effect).\n    device : str, optional\n        Either 'cuda' or 'cpu'.\n\n    Notes\n    -----\n    Although this model build upon the approach in SNGP, it does not enforce the spectral normalization\n    and ResNet architecture required for SNGP. Instead, it is a simple wrapper around\n    any pytorch embedding neural network. Your mileage may vary.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model: torch.nn.Module,\n        emb_out_dim: int,\n        num_classes: int,\n        use_temperature: bool = False,\n        init_temperature: float = 1.0,\n        device: str = \"cpu\",\n    ) -&gt; None:\n        super().__init__(embedding_model)\n        self.num_deep_features = emb_out_dim\n        self.num_gp_features = emb_out_dim\n        self.normalize_gp_features = True\n        self.num_random_features = 1024\n        self.num_outputs = num_classes\n        self.mean_field_factor = 25\n        self.ridge_penalty = 1\n        self.feature_scale = 2.0\n        self.use_temperature = use_temperature\n        self.init_temperature = init_temperature\n        self.register_buffer(\n            \"temperature\", torch.Tensor(self.init_temperature * torch.ones(1))\n        )\n        self.model = _Laplace(\n            self.embedding_model,\n            self.num_deep_features,\n            self.num_gp_features,\n            self.normalize_gp_features,\n            self.num_random_features,\n            self.num_outputs,\n            self.feature_scale,\n            self.mean_field_factor,\n            self.ridge_penalty,\n        )\n        self.device_type = device\n        self.device = torch.device(self.device_type)\n        self.model.to(self.device)\n\n    def train_model(\n        self,\n        dataset: TensorDataset,\n        loss_fn: Callable,\n        opt: torch.optim.Optimizer,\n        num_epochs: int,\n        batch_size: int = 64,\n        calib_frac: float = 0.1,\n        num_calibration_epochs: int = 2,\n        calibration_lr: float = 0.01,\n        vis_support: bool = False,\n        support_size: int = 25,\n    ) -&gt; Tuple[dict[str, Any], Optional[DataLoader[Any]]]:\n        \"\"\"\n        Train or fine-tune an EquineGP model.\n\n        Parameters\n        ----------\n        dataset : TensorDataset\n            An iterable, pytorch TensorDataset.\n        loss_fn : Callable\n            A pytorch loss function, e.g., torch.nn.CrossEntropyLoss().\n        opt : torch.optim.Optimizer\n            A pytorch optimizer, e.g., torch.optim.Adam().\n        num_epochs : int\n            The desired number of epochs to use for training.\n        batch_size : int, optional\n            The number of samples to use per batch.\n        calib_frac : float, optional\n            Fraction of training data to use in temperature scaling.\n        num_calibration_epochs : int, optional\n            The desired number of epochs to use for temperature scaling.\n        calibration_lr : float, optional\n            Learning rate for temperature scaling.\n\n        Returns\n        -------\n        Tuple[dict[str, Any], DataLoader]\n            A tuple containing the training history and a dataloader for the calibration data.\n\n        Notes\n        -------\n        - If `use_temperature` is True, temperature scaling will be used after training.\n        - The calibration data is used to calibrate the temperature scaling.\n        \"\"\"\n        if self.use_temperature:\n            X, Y = dataset[:]\n            train_x, calib_x, train_y, calib_y = train_test_split(\n                X, Y, test_size=calib_frac, stratify=Y\n            )  # TODO: Replace sklearn with torch call\n            dataset = TensorDataset(train_x, train_y)\n            self.temperature = torch.Tensor(\n                self.init_temperature * torch.ones(1)\n            ).type_as(self.temperature)\n\n        train_loader = DataLoader(\n            dataset, batch_size=batch_size, shuffle=True, drop_last=True\n        )\n        self.model.set_training_params(\n            len(train_loader.sampler), train_loader.batch_size\n        )\n        self.model.train()\n        for _ in tqdm(range(num_epochs)):\n            self.model.reset_precision_matrix()\n            epoch_loss = 0.0\n            for i, (xs, labels) in enumerate(train_loader):\n                opt.zero_grad()\n                xs = xs.to(self.device)\n                labels = labels.to(self.device)\n                yhats = self.model(xs)\n                loss = loss_fn(yhats, labels.to(torch.long))\n                loss.backward()\n                opt.step()\n                epoch_loss += loss.item()\n        self.model.eval()\n\n        if vis_support:\n            self.update_support(dataset.tensors[0], dataset.tensors[1], support_size)\n\n        calibration_loader = None\n        if self.use_temperature:\n            dataset_calibration = TensorDataset(calib_x, calib_y)\n            calibration_loader = DataLoader(\n                dataset_calibration,\n                batch_size=batch_size,\n                shuffle=True,\n                drop_last=False,\n            )\n            self.calibrate_temperature(\n                calibration_loader, num_calibration_epochs, calibration_lr\n            )\n\n        _, train_y = dataset[:]\n        date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n        self.train_summary = generate_train_summary(self, train_y, date_trained)\n\n        return self.train_summary, calibration_loader\n\n    def update_support(\n        self, support_x: torch.Tensor, support_y: torch.Tensor, support_size: int\n    ) -&gt; None:\n        \"\"\"Function to update protonet support examples with given examples.\n\n        Parameters\n        ----------\n        support_x : torch.Tensor\n            Tensor containing support examples for protonet.\n        support_y : torch.Tensor\n            Tensor containing labels for given support examples.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        labels, counts = torch.unique(support_y, return_counts=True)\n        support = OrderedDict()\n        for label, count in list(zip(labels.tolist(), counts.tolist())):\n            class_support = generate_support(\n                support_x,\n                support_y,\n                support_size=min(count, support_size),\n                selected_labels=[label],\n            )\n            support.update(class_support)\n\n        self.support = support\n\n        support_embeddings = OrderedDict().fromkeys(support.keys())\n        for label in support:\n            support_embeddings[label] = self.compute_embeddings(support[label])\n\n        self.support_embeddings = support_embeddings\n\n        self.prototypes = self.compute_prototypes()\n\n    def compute_embeddings(self, x):\n        f = self.model.feature_extractor(x)\n        f_reduc = self.model.jl(f)\n        if self.model.normalize_gp_features:\n            f_reduc = self.model.normalize(f_reduc)\n\n        return self.model.rff(f_reduc)\n\n    @icontract.require(lambda self: self.support is not None)\n    def compute_prototypes(self) -&gt; torch.Tensor:\n        \"\"\"\n        Method for computing class prototypes based on given support examples.\n        ``Prototypes'' in this context are the means of the support embeddings for each class.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensors of prototypes for each of the given classes in the support.\n        \"\"\"\n        # Compute support embeddings\n        support_embeddings = OrderedDict().fromkeys(self.support.keys())\n        for label in self.support:\n            support_embeddings[label] = self.compute_embeddings(self.support[label])\n\n        # Compute prototype for each class\n        proto_list = []\n        for label in self.support:  # look at doing functorch\n            class_prototype = torch.mean(support_embeddings[label], dim=0)  # type: ignore\n            proto_list.append(class_prototype)\n\n        prototypes = torch.stack(proto_list)\n\n        return prototypes\n\n    @icontract.require(lambda self: self.support is not None)\n    def get_support(self):\n        return self.support\n\n    @icontract.require(lambda self: self.prototypes is not None)\n    def get_prototypes(self):\n        return self.prototypes\n\n    def calibrate_temperature(\n        self,\n        calibration_loader: DataLoader,\n        num_calibration_epochs: int = 1,\n        calibration_lr: float = 0.01,\n    ) -&gt; None:\n        \"\"\"\n        Fine-tune the temperature after training. Note this function is also run at the conclusion of train_model.\n\n        Parameters\n        ----------\n        calibration_loader : DataLoader\n            Data loader returned by train_model.\n        num_calibration_epochs : int, optional\n            Number of epochs to tune temperature.\n        calibration_lr : float, optional\n            Learning rate for temperature optimization.\n        \"\"\"\n        self.temperature.requires_grad = True\n        loss_fn = torch.nn.functional.cross_entropy\n        optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n        for _ in range(num_calibration_epochs):\n            for xs, labels in calibration_loader:\n                optimizer.zero_grad()\n                xs = xs.to(self.device)\n                labels = labels.to(self.device)\n                with torch.no_grad():\n                    logits = self.model(xs)\n                logits = logits / self.temperature\n                loss = loss_fn(logits, labels.to(torch.long))\n                loss.backward()\n                optimizer.step()\n        self.temperature.requires_grad = False\n\n    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        EquineGP forward function, generates logits for classification.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor for generating predictions.\n\n        Returns\n        -------\n        torch.Tensor\n            Output probabilities computed.\n        \"\"\"\n        X = X.to(self.device)\n        preds = self.model(X)\n        return preds / self.temperature.to(self.device)\n\n    @icontract.ensure(\n        lambda result: all((0 &lt;= result.ood_scores) &amp; (result.ood_scores &lt;= 1.0))\n    )\n    def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n        \"\"\"\n        Predict function for EquineGP, inherited and implemented from Equine.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        EquineOutput\n            Output object containing prediction probabilities and OOD scores.\n        \"\"\"\n        logits = self(X)\n        preds = torch.softmax(logits, dim=1)\n        equiprobable = torch.ones(self.num_outputs) / self.num_outputs\n        max_entropy = torch.sum(torch.special.entr(equiprobable))\n        ood_score = torch.sum(torch.special.entr(preds), dim=1) / max_entropy\n        embeddings = self.compute_embeddings(X)\n        eq_out = EquineOutput(\n            classes=preds, ood_scores=ood_score, embeddings=embeddings\n        )  # TODO return embeddings\n        return eq_out\n\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Function to save all model parameters to a file.\n\n        Parameters\n        ----------\n        path : str\n            Filename to write the model.\n        \"\"\"\n        model_settings = {\n            \"emb_out_dim\": self.num_deep_features,\n            \"num_classes\": self.num_outputs,\n            \"use_temperature\": self.use_temperature,\n            \"init_temperature\": self.temperature.item(),\n            \"device\": self.device_type,\n        }\n\n        jit_model = torch.jit.script(self.model.feature_extractor)\n        buffer = io.BytesIO()\n        torch.jit.save(jit_model, buffer)\n        buffer.seek(0)\n\n        laplace_sd = self.model.state_dict()\n        keys_to_delete = []\n        for key in laplace_sd:\n            if \"feature_extractor\" in key:\n                keys_to_delete.append(key)\n        for key in keys_to_delete:\n            del laplace_sd[key]\n\n        save_data = {\n            \"settings\": model_settings,\n            \"support\": self.support,\n            \"num_data\": self.model.num_data,\n            \"train_batch_size\": self.model.train_batch_size,\n            \"laplace_model_save\": laplace_sd,\n            \"embed_jit_save\": buffer,\n            \"train_summary\": self.train_summary,\n        }\n\n        torch.save(save_data, path)  # TODO allow model checkpointing\n\n    @classmethod\n    def load(cls, path: str) -&gt; Equine:\n        \"\"\"\n        Function to load previously saved EquineGP model.\n\n        Parameters\n        ----------\n        path : str\n            Input filename.\n\n        Returns\n        -------\n        EquineGP\n            The reconstituted EquineGP object.\n        \"\"\"\n        model_save = torch.load(path)\n        jit_model = torch.jit.load(model_save[\"embed_jit_save\"])\n        eq_model = cls(jit_model, **model_save[\"settings\"])\n\n        eq_model.train_summary = model_save[\"train_summary\"]\n        eq_model.model.load_state_dict(model_save[\"laplace_model_save\"], strict=False)\n        eq_model.model.seen_data = model_save[\"laplace_model_save\"][\"seen_data\"]\n\n        eq_model.model.set_training_params(\n            model_save[\"num_data\"], model_save[\"train_batch_size\"]\n        )\n        eq_model.eval()\n\n        support = model_save[\"support\"]\n        if support is not None:\n            eq_model.support = support\n            eq_model.prototypes = eq_model.compute_prototypes()\n\n        return eq_model\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.calibrate_temperature","title":"<code>calibrate_temperature(calibration_loader, num_calibration_epochs=1, calibration_lr=0.01)</code>","text":"<p>Fine-tune the temperature after training. Note this function is also run at the conclusion of train_model.</p> <p>Parameters:</p> Name Type Description Default <code>calibration_loader</code> <code>DataLoader</code> <p>Data loader returned by train_model.</p> required <code>num_calibration_epochs</code> <code>int</code> <p>Number of epochs to tune temperature.</p> <code>1</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature optimization.</p> <code>0.01</code> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def calibrate_temperature(\n    self,\n    calibration_loader: DataLoader,\n    num_calibration_epochs: int = 1,\n    calibration_lr: float = 0.01,\n) -&gt; None:\n    \"\"\"\n    Fine-tune the temperature after training. Note this function is also run at the conclusion of train_model.\n\n    Parameters\n    ----------\n    calibration_loader : DataLoader\n        Data loader returned by train_model.\n    num_calibration_epochs : int, optional\n        Number of epochs to tune temperature.\n    calibration_lr : float, optional\n        Learning rate for temperature optimization.\n    \"\"\"\n    self.temperature.requires_grad = True\n    loss_fn = torch.nn.functional.cross_entropy\n    optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n    for _ in range(num_calibration_epochs):\n        for xs, labels in calibration_loader:\n            optimizer.zero_grad()\n            xs = xs.to(self.device)\n            labels = labels.to(self.device)\n            with torch.no_grad():\n                logits = self.model(xs)\n            logits = logits / self.temperature\n            loss = loss_fn(logits, labels.to(torch.long))\n            loss.backward()\n            optimizer.step()\n    self.temperature.requires_grad = False\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.compute_prototypes","title":"<code>compute_prototypes()</code>","text":"<p>Method for computing class prototypes based on given support examples. ``Prototypes'' in this context are the means of the support embeddings for each class.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensors of prototypes for each of the given classes in the support.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@icontract.require(lambda self: self.support is not None)\ndef compute_prototypes(self) -&gt; torch.Tensor:\n    \"\"\"\n    Method for computing class prototypes based on given support examples.\n    ``Prototypes'' in this context are the means of the support embeddings for each class.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensors of prototypes for each of the given classes in the support.\n    \"\"\"\n    # Compute support embeddings\n    support_embeddings = OrderedDict().fromkeys(self.support.keys())\n    for label in self.support:\n        support_embeddings[label] = self.compute_embeddings(self.support[label])\n\n    # Compute prototype for each class\n    proto_list = []\n    for label in self.support:  # look at doing functorch\n        class_prototype = torch.mean(support_embeddings[label], dim=0)  # type: ignore\n        proto_list.append(class_prototype)\n\n    prototypes = torch.stack(proto_list)\n\n    return prototypes\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.forward","title":"<code>forward(X)</code>","text":"<p>EquineGP forward function, generates logits for classification.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor for generating predictions.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output probabilities computed.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    EquineGP forward function, generates logits for classification.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor for generating predictions.\n\n    Returns\n    -------\n    torch.Tensor\n        Output probabilities computed.\n    \"\"\"\n    X = X.to(self.device)\n    preds = self.model(X)\n    return preds / self.temperature.to(self.device)\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Function to load previously saved EquineGP model.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Input filename.</p> required <p>Returns:</p> Type Description <code>EquineGP</code> <p>The reconstituted EquineGP object.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@classmethod\ndef load(cls, path: str) -&gt; Equine:\n    \"\"\"\n    Function to load previously saved EquineGP model.\n\n    Parameters\n    ----------\n    path : str\n        Input filename.\n\n    Returns\n    -------\n    EquineGP\n        The reconstituted EquineGP object.\n    \"\"\"\n    model_save = torch.load(path)\n    jit_model = torch.jit.load(model_save[\"embed_jit_save\"])\n    eq_model = cls(jit_model, **model_save[\"settings\"])\n\n    eq_model.train_summary = model_save[\"train_summary\"]\n    eq_model.model.load_state_dict(model_save[\"laplace_model_save\"], strict=False)\n    eq_model.model.seen_data = model_save[\"laplace_model_save\"][\"seen_data\"]\n\n    eq_model.model.set_training_params(\n        model_save[\"num_data\"], model_save[\"train_batch_size\"]\n    )\n    eq_model.eval()\n\n    support = model_save[\"support\"]\n    if support is not None:\n        eq_model.support = support\n        eq_model.prototypes = eq_model.compute_prototypes()\n\n    return eq_model\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.predict","title":"<code>predict(X)</code>","text":"<p>Predict function for EquineGP, inherited and implemented from Equine.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>EquineOutput</code> <p>Output object containing prediction probabilities and OOD scores.</p> Source code in <code>src/equine/equine_gp.py</code> <pre><code>@icontract.ensure(\n    lambda result: all((0 &lt;= result.ood_scores) &amp; (result.ood_scores &lt;= 1.0))\n)\ndef predict(self, X: torch.Tensor) -&gt; EquineOutput:\n    \"\"\"\n    Predict function for EquineGP, inherited and implemented from Equine.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    EquineOutput\n        Output object containing prediction probabilities and OOD scores.\n    \"\"\"\n    logits = self(X)\n    preds = torch.softmax(logits, dim=1)\n    equiprobable = torch.ones(self.num_outputs) / self.num_outputs\n    max_entropy = torch.sum(torch.special.entr(equiprobable))\n    ood_score = torch.sum(torch.special.entr(preds), dim=1) / max_entropy\n    embeddings = self.compute_embeddings(X)\n    eq_out = EquineOutput(\n        classes=preds, ood_scores=ood_score, embeddings=embeddings\n    )  # TODO return embeddings\n    return eq_out\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.save","title":"<code>save(path)</code>","text":"<p>Function to save all model parameters to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Filename to write the model.</p> required Source code in <code>src/equine/equine_gp.py</code> <pre><code>def save(self, path: str) -&gt; None:\n    \"\"\"\n    Function to save all model parameters to a file.\n\n    Parameters\n    ----------\n    path : str\n        Filename to write the model.\n    \"\"\"\n    model_settings = {\n        \"emb_out_dim\": self.num_deep_features,\n        \"num_classes\": self.num_outputs,\n        \"use_temperature\": self.use_temperature,\n        \"init_temperature\": self.temperature.item(),\n        \"device\": self.device_type,\n    }\n\n    jit_model = torch.jit.script(self.model.feature_extractor)\n    buffer = io.BytesIO()\n    torch.jit.save(jit_model, buffer)\n    buffer.seek(0)\n\n    laplace_sd = self.model.state_dict()\n    keys_to_delete = []\n    for key in laplace_sd:\n        if \"feature_extractor\" in key:\n            keys_to_delete.append(key)\n    for key in keys_to_delete:\n        del laplace_sd[key]\n\n    save_data = {\n        \"settings\": model_settings,\n        \"support\": self.support,\n        \"num_data\": self.model.num_data,\n        \"train_batch_size\": self.model.train_batch_size,\n        \"laplace_model_save\": laplace_sd,\n        \"embed_jit_save\": buffer,\n        \"train_summary\": self.train_summary,\n    }\n\n    torch.save(save_data, path)  # TODO allow model checkpointing\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.train_model","title":"<code>train_model(dataset, loss_fn, opt, num_epochs, batch_size=64, calib_frac=0.1, num_calibration_epochs=2, calibration_lr=0.01, vis_support=False, support_size=25)</code>","text":"<p>Train or fine-tune an EquineGP model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>TensorDataset</code> <p>An iterable, pytorch TensorDataset.</p> required <code>loss_fn</code> <code>Callable</code> <p>A pytorch loss function, e.g., torch.nn.CrossEntropyLoss().</p> required <code>opt</code> <code>Optimizer</code> <p>A pytorch optimizer, e.g., torch.optim.Adam().</p> required <code>num_epochs</code> <code>int</code> <p>The desired number of epochs to use for training.</p> required <code>batch_size</code> <code>int</code> <p>The number of samples to use per batch.</p> <code>64</code> <code>calib_frac</code> <code>float</code> <p>Fraction of training data to use in temperature scaling.</p> <code>0.1</code> <code>num_calibration_epochs</code> <code>int</code> <p>The desired number of epochs to use for temperature scaling.</p> <code>2</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature scaling.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>Tuple[dict[str, Any], DataLoader]</code> <p>A tuple containing the training history and a dataloader for the calibration data.</p> Notes <ul> <li>If <code>use_temperature</code> is True, temperature scaling will be used after training.</li> <li>The calibration data is used to calibrate the temperature scaling.</li> </ul> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def train_model(\n    self,\n    dataset: TensorDataset,\n    loss_fn: Callable,\n    opt: torch.optim.Optimizer,\n    num_epochs: int,\n    batch_size: int = 64,\n    calib_frac: float = 0.1,\n    num_calibration_epochs: int = 2,\n    calibration_lr: float = 0.01,\n    vis_support: bool = False,\n    support_size: int = 25,\n) -&gt; Tuple[dict[str, Any], Optional[DataLoader[Any]]]:\n    \"\"\"\n    Train or fine-tune an EquineGP model.\n\n    Parameters\n    ----------\n    dataset : TensorDataset\n        An iterable, pytorch TensorDataset.\n    loss_fn : Callable\n        A pytorch loss function, e.g., torch.nn.CrossEntropyLoss().\n    opt : torch.optim.Optimizer\n        A pytorch optimizer, e.g., torch.optim.Adam().\n    num_epochs : int\n        The desired number of epochs to use for training.\n    batch_size : int, optional\n        The number of samples to use per batch.\n    calib_frac : float, optional\n        Fraction of training data to use in temperature scaling.\n    num_calibration_epochs : int, optional\n        The desired number of epochs to use for temperature scaling.\n    calibration_lr : float, optional\n        Learning rate for temperature scaling.\n\n    Returns\n    -------\n    Tuple[dict[str, Any], DataLoader]\n        A tuple containing the training history and a dataloader for the calibration data.\n\n    Notes\n    -------\n    - If `use_temperature` is True, temperature scaling will be used after training.\n    - The calibration data is used to calibrate the temperature scaling.\n    \"\"\"\n    if self.use_temperature:\n        X, Y = dataset[:]\n        train_x, calib_x, train_y, calib_y = train_test_split(\n            X, Y, test_size=calib_frac, stratify=Y\n        )  # TODO: Replace sklearn with torch call\n        dataset = TensorDataset(train_x, train_y)\n        self.temperature = torch.Tensor(\n            self.init_temperature * torch.ones(1)\n        ).type_as(self.temperature)\n\n    train_loader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=True, drop_last=True\n    )\n    self.model.set_training_params(\n        len(train_loader.sampler), train_loader.batch_size\n    )\n    self.model.train()\n    for _ in tqdm(range(num_epochs)):\n        self.model.reset_precision_matrix()\n        epoch_loss = 0.0\n        for i, (xs, labels) in enumerate(train_loader):\n            opt.zero_grad()\n            xs = xs.to(self.device)\n            labels = labels.to(self.device)\n            yhats = self.model(xs)\n            loss = loss_fn(yhats, labels.to(torch.long))\n            loss.backward()\n            opt.step()\n            epoch_loss += loss.item()\n    self.model.eval()\n\n    if vis_support:\n        self.update_support(dataset.tensors[0], dataset.tensors[1], support_size)\n\n    calibration_loader = None\n    if self.use_temperature:\n        dataset_calibration = TensorDataset(calib_x, calib_y)\n        calibration_loader = DataLoader(\n            dataset_calibration,\n            batch_size=batch_size,\n            shuffle=True,\n            drop_last=False,\n        )\n        self.calibrate_temperature(\n            calibration_loader, num_calibration_epochs, calibration_lr\n        )\n\n    _, train_y = dataset[:]\n    date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n    self.train_summary = generate_train_summary(self, train_y, date_trained)\n\n    return self.train_summary, calibration_loader\n</code></pre>"},{"location":"reference/equine/equine_gp/#equine.equine_gp.EquineGP.update_support","title":"<code>update_support(support_x, support_y, support_size)</code>","text":"<p>Function to update protonet support examples with given examples.</p> <p>Parameters:</p> Name Type Description Default <code>support_x</code> <code>Tensor</code> <p>Tensor containing support examples for protonet.</p> required <code>support_y</code> <code>Tensor</code> <p>Tensor containing labels for given support examples.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_gp.py</code> <pre><code>def update_support(\n    self, support_x: torch.Tensor, support_y: torch.Tensor, support_size: int\n) -&gt; None:\n    \"\"\"Function to update protonet support examples with given examples.\n\n    Parameters\n    ----------\n    support_x : torch.Tensor\n        Tensor containing support examples for protonet.\n    support_y : torch.Tensor\n        Tensor containing labels for given support examples.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    labels, counts = torch.unique(support_y, return_counts=True)\n    support = OrderedDict()\n    for label, count in list(zip(labels.tolist(), counts.tolist())):\n        class_support = generate_support(\n            support_x,\n            support_y,\n            support_size=min(count, support_size),\n            selected_labels=[label],\n        )\n        support.update(class_support)\n\n    self.support = support\n\n    support_embeddings = OrderedDict().fromkeys(support.keys())\n    for label in support:\n        support_embeddings[label] = self.compute_embeddings(support[label])\n\n    self.support_embeddings = support_embeddings\n\n    self.prototypes = self.compute_prototypes()\n</code></pre>"},{"location":"reference/equine/equine_output/","title":"equine_output","text":""},{"location":"reference/equine/equine_output/#equine.equine_output.EquineOutput","title":"<code>EquineOutput</code>  <code>dataclass</code>","text":"<p>Output object containing prediction probabilities, OOD scores, and embeddings, which can be used for visualization.</p> <p>Attributes:</p> Name Type Description <code>classes</code> <code>Tensor</code> <p>Tensor of predicted class probabilities.</p> <code>ood_scores</code> <code>Tensor</code> <p>Tensor of out-of-distribution (OOD) scores.</p> <code>embeddings</code> <code>Tensor</code> <p>Tensor of embeddings produced by the model.</p> Source code in <code>src/equine/equine_output.py</code> <pre><code>@dataclass\nclass EquineOutput:\n    \"\"\"\n    Output object containing prediction probabilities, OOD scores, and embeddings, which can be used for visualization.\n\n    Attributes\n    ----------\n    classes : Tensor\n        Tensor of predicted class probabilities.\n    ood_scores : Tensor\n        Tensor of out-of-distribution (OOD) scores.\n    embeddings : Tensor\n        Tensor of embeddings produced by the model.\n    \"\"\"\n\n    classes: Tensor\n    ood_scores: Tensor\n    embeddings: Tensor\n</code></pre>"},{"location":"reference/equine/equine_protonet/","title":"equine_protonet","text":""},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet","title":"<code>EquineProtonet</code>","text":"<p>               Bases: <code>Equine</code></p> <p>A class representing an EQUINE model that utilizes protonets and (optionally) relative Mahalanobis distances to generate OOD and model confidence scores. This wraps any pytorch embedding neural network and provides the <code>forward</code>, <code>predict</code>, <code>save</code>, and <code>load</code> methods required by Equine.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>Neural Network feature embedding model.</p> required <code>emb_out_dim</code> <code>int</code> <p>The number of output features from the embedding model.</p> required <code>cov_type</code> <code>CovType</code> <p>The type of covariance to use when training the protonet [UNIT, DIAG, FULL], by default CovType.UNIT.</p> <code>UNIT</code> <code>relative_mahal</code> <code>bool</code> <p>Use relative mahalanobis distance for OOD calculations. If false, uses standard mahalanobis distance instead, by default True.</p> <code>True</code> <code>use_temperature</code> <code>bool</code> <p>Whether to use temperature scaling after training, by default False.</p> <code>False</code> <code>init_temperature</code> <code>float</code> <p>What to use as the initial temperature (1.0 has no effect), by default 1.0.</p> <code>1.0</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@beartype\nclass EquineProtonet(Equine):\n    \"\"\"\n    A class representing an EQUINE model that utilizes protonets and (optionally) relative Mahalanobis distances\n    to generate OOD and model confidence scores. This wraps any pytorch embedding neural network\n    and provides the `forward`, `predict`, `save`, and `load` methods required by Equine.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        Neural Network feature embedding model.\n    emb_out_dim : int\n        The number of output features from the embedding model.\n    cov_type : CovType, optional\n        The type of covariance to use when training the protonet [UNIT, DIAG, FULL], by default CovType.UNIT.\n    relative_mahal : bool, optional\n        Use relative mahalanobis distance for OOD calculations. If false, uses standard mahalanobis distance instead, by default True.\n    use_temperature : bool, optional\n        Whether to use temperature scaling after training, by default False.\n    init_temperature : float, optional\n        What to use as the initial temperature (1.0 has no effect), by default 1.0.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model,\n        emb_out_dim: int,\n        cov_type: CovType = CovType.UNIT,\n        relative_mahal: bool = True,\n        use_temperature: bool = False,\n        init_temperature: float = 1.0,\n    ) -&gt; None:\n        super().__init__(embedding_model)\n        self.cov_type = cov_type\n        self.cov_reg_type = COV_REG_TYPE\n        self.relative_mahal = relative_mahal\n        self.emb_out_dim = emb_out_dim\n        self.epsilon = DEFAULT_EPSILON\n        self.outlier_score_kde = None\n        self.model_summary = None\n        self.use_temperature = use_temperature\n        self.init_temperature = init_temperature\n        self.register_buffer(\n            \"temperature\", torch.Tensor(self.init_temperature * torch.ones(1))\n        )\n\n        self.model = Protonet(\n            embedding_model,\n            self.emb_out_dim,\n            self.cov_type,\n            self.cov_reg_type,\n            self.epsilon,\n        )\n\n    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Generates logits for classification based on the input tensor.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            The input tensor for generating predictions.\n\n        Returns\n        -------\n        torch.Tensor\n            The output class predictions.\n        \"\"\"\n        preds, _ = self.model(X)\n        return preds\n\n    @icontract.require(lambda calib_frac: calib_frac &gt; 0 and calib_frac &lt; 1)\n    def train_model(\n        self,\n        dataset: TensorDataset,\n        num_episodes: int,\n        calib_frac: float = 0.2,\n        support_size: int = 25,\n        way: int = 3,\n        episode_size: int = 100,\n        loss_fn: Callable = torch.nn.functional.cross_entropy,\n        opt_class: Callable = torch.optim.Adam,\n        num_calibration_epochs: int = 2,\n        calibration_lr: float = 0.01,\n    ) -&gt; tuple[dict[str, Any], torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Train or fine-tune an EquineProtonet model.\n\n        Parameters\n        ----------\n        dataset : TensorDataset\n            Input pytorch TensorDataset of training data for model.\n        num_episodes : int\n            The desired number of episodes to use for training.\n        calib_frac : float, optional\n            Fraction of given training data to reserve for model calibration, by default 0.2.\n        support_size : int, optional\n            Number of support examples to generate for each class, by default 25.\n        way : int, optional\n            Number of classes to train on per episode, by default 3.\n        episode_size : int, optional\n            Number of examples to use per episode, by default 100.\n        loss_fn : Callable, optional\n            A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.\n        opt_class : Callable, optional\n            A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.\n        num_calibration_epochs : int, optional\n            The desired number of epochs to use for temperature scaling, by default 2.\n        calibration_lr : float, optional\n            Learning rate for temperature scaling, by default 0.01.\n\n        Returns\n        -------\n        tuple[dict[str, Any], torch.Tensor, torch.Tensor]\n            A tuple containing the model summary, the held out calibration data, and the calibration labels.\n        \"\"\"\n        self.train()\n\n        if self.use_temperature:\n            self.temperature = torch.Tensor(\n                self.init_temperature * torch.ones(1)\n            ).type_as(self.temperature)\n\n        X, Y = dataset[:]\n\n        train_x, calib_x, train_y, calib_y = train_test_split(\n            X, Y, test_size=calib_frac, stratify=Y\n        )  # TODO: Replace sklearn with torch call\n        optimizer = opt_class(self.parameters())\n\n        for i in tqdm(range(num_episodes)):\n            optimizer.zero_grad()\n\n            support, episode_x, episode_y = generate_episode(\n                train_x, train_y, support_size, way, episode_size\n            )\n            self.model.update_support(support)\n\n            _, dists = self.model(episode_x)\n            loss_value = loss_fn(torch.neg(dists), episode_y)\n            loss_value.backward()\n            optimizer.step()\n\n        self.eval()\n        full_support = generate_support(\n            train_x,\n            train_y,\n            support_size,\n            selected_labels=torch.unique(train_y).tolist(),\n        )\n\n        self.model.update_support(\n            full_support\n        )  # update support with final selected examples\n\n        X_embed = self.model.compute_embeddings(calib_x)\n        pred_probs, dists = self.model(calib_x)\n        ood_dists = self._compute_ood_dist(X_embed, pred_probs, dists)\n        self._fit_outlier_scores(ood_dists, calib_y)\n\n        if self.use_temperature:\n            self.calibrate_temperature(\n                calib_x, calib_y, num_calibration_epochs, calibration_lr\n            )\n\n        date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n        self.train_summary = generate_train_summary(self, train_y, date_trained)\n        return self.train_summary, calib_x, calib_y\n\n    def calibrate_temperature(\n        self,\n        calib_x: torch.Tensor,\n        calib_y: torch.Tensor,\n        num_calibration_epochs: int = 1,\n        calibration_lr: float = 0.01,\n    ) -&gt; None:\n        \"\"\"\n        Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.\n\n        Parameters\n        ----------\n        calib_x : torch.Tensor\n            Training data to be used for temperature calibration.\n        calib_y : torch.Tensor\n            Labels corresponding to `calib_x`.\n        num_calibration_epochs : int, optional\n            Number of epochs to tune temperature, by default 1.\n        calibration_lr : float, optional\n            Learning rate for temperature optimization, by default 0.01.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.temperature.requires_grad = True\n        optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n        for t in range(num_calibration_epochs):\n            optimizer.zero_grad()\n            with torch.no_grad():\n                pred_probs, dists = self.model(calib_x)\n            dists = dists / self.temperature\n            loss = torch.nn.functional.cross_entropy(\n                torch.neg(dists), calib_y.to(torch.long)\n            )\n            loss.backward()\n            optimizer.step()\n        self.temperature.requires_grad = False\n\n    @icontract.ensure(lambda self: self.model.support_embeddings is not None)\n    def _fit_outlier_scores(\n        self, ood_dists: torch.Tensor, calib_y: torch.Tensor\n    ) -&gt; None:\n        \"\"\"\n        Private function to fit outlier scores with a kernel density estimate (KDE).\n\n        Parameters\n        ----------\n        ood_dists : torch.Tensor\n            Tensor of computed OOD distances.\n        calib_y : torch.Tensor\n            Tensor of class labels for `ood_dists` examples.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.outlier_score_kde = OrderedDict.fromkeys(\n            self.model.support_embeddings.keys()\n        )\n\n        for label in self.outlier_score_kde:\n            class_ood_dists = ood_dists[calib_y == int(label)].detach().numpy()\n            class_kde = gaussian_kde(class_ood_dists)  # TODO convert to torch func\n            self.outlier_score_kde[label] = class_kde\n\n    def _compute_outlier_scores(self, ood_dists, predictions) -&gt; torch.Tensor:\n        \"\"\"\n        Private function to compute OOD scores using the calculated kernel density estimate (KDE).\n\n        Parameters\n        ----------\n        ood_dists : torch.Tensor\n            Tensor of computed OOD distances.\n        predictions : torch.Tensor\n            Tensor of model protonet predictions.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of OOD scores for the given examples.\n        \"\"\"\n        ood_scores = torch.zeros_like(ood_dists)\n        for i in range(len(predictions)):\n            # Use KDE and RMD corresponding to the predicted class\n            predicted_class = int(torch.argmax(predictions[i, :]))\n            p_value = self.outlier_score_kde[int(predicted_class)].integrate_box_1d(\n                ood_dists[i].detach().numpy(), torch.inf\n            )\n            ood_scores[i] = 1.0 - p_value\n\n        return ood_scores\n\n    @icontract.ensure(lambda result: len(result) &gt; 0)\n    def _compute_ood_dist(\n        self,\n        X_embeddings: torch.Tensor,\n        predictions: torch.Tensor,\n        distances: torch.Tensor,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Private function to compute OOD distances using a distance function.\n\n        Parameters\n        ----------\n        X_embeddings : torch.Tensor\n            Tensor of example embeddings.\n        predictions : torch.Tensor\n            Tensor of model protonet predictions for the given embeddings.\n        distances : torch.Tensor\n            Tensor of calculated protonet distances for the given embeddings.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of OOD distances for the given embeddings.\n        \"\"\"\n        preds = torch.argmax(predictions, dim=1)\n        preds = preds.unsqueeze(dim=-1)\n        # Calculate (Relative) Mahalanobis Distance:\n        if self.relative_mahal:\n            null_distance = self.model.compute_distance(\n                X_embeddings, self.model.global_mean, self.model.global_covariance\n            )\n            null_distance = null_distance.unsqueeze(dim=-1)\n            ood_dist = distances.gather(1, preds) - null_distance\n        else:\n            ood_dist = distances.gather(1, preds)\n\n        ood_dist = torch.reshape(ood_dist, (-1,))\n        return ood_dist\n\n    def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n        \"\"\"Predict function for EquineProtonet, inherited and implemented from Equine.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        EquineOutput\n            Output object containing prediction probabilities and OOD scores.\n        \"\"\"\n        X_embed = self.model.compute_embeddings(X)\n        if X_embed.shape == torch.Size([self.model.emb_out_dim]):\n            X_embed = X_embed.unsqueeze(dim=0)  # Handle single examples\n        preds, dists = self.model(X)\n        if self.use_temperature:\n            dists = dists / self.temperature\n            preds = torch.softmax(torch.negative(dists), dim=1)\n        ood_dist = self._compute_ood_dist(X_embed, preds, dists)\n        ood_scores = self._compute_outlier_scores(ood_dist, preds)\n\n        return EquineOutput(classes=preds, ood_scores=ood_scores, embeddings=X_embed)\n\n    @icontract.require(lambda calib_frac: (calib_frac &gt; 0.0) and (calib_frac &lt; 1.0))\n    def update_support(\n        self, support_x: torch.Tensor, support_y: torch.Tensor, calib_frac: float\n    ) -&gt; None:\n        \"\"\"Function to update protonet support examples with given examples.\n\n        Parameters\n        ----------\n        support_x : torch.Tensor\n            Tensor containing support examples for protonet.\n        support_y : torch.Tensor\n            Tensor containing labels for given support examples.\n        calib_frac : float\n            Fraction of given support data to use for OOD calibration.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        support_x, calib_x, support_y, calib_y = train_test_split(\n            support_x, support_y, test_size=calib_frac, stratify=support_y\n        )\n        labels, counts = torch.unique(support_y, return_counts=True)\n        support = OrderedDict()\n        for label, count in list(zip(labels.tolist(), counts.tolist())):\n            class_support = generate_support(\n                support_x,\n                support_y,\n                support_size=count,\n                selected_labels=[label],\n            )\n            support.update(class_support)\n\n        self.model.update_support(support)\n\n        X_embed = self.model.compute_embeddings(calib_x)\n        preds, dists = self.model(calib_x)\n        ood_dists = self._compute_ood_dist(X_embed, preds, dists)\n\n        self._fit_outlier_scores(ood_dists, calib_y)\n\n    @icontract.require(lambda self: self.model.support is not None)\n    def get_support(self):\n        return self.model.support\n\n    @icontract.require(lambda self: self.model.prototypes is not None)\n    def get_prototypes(self):\n        return self.model.prototypes\n\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Save all model parameters to a file.\n\n        Parameters\n        ----------\n        path : str\n            Filename to write the model.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        model_settings = {\n            \"cov_type\": self.cov_type,\n            \"emb_out_dim\": self.emb_out_dim,\n            \"use_temperature\": self.use_temperature,\n            \"init_temperature\": self.temperature.item(),\n        }\n\n        jit_model = torch.jit.script(self.model.embedding_model)  # type: ignore\n        buffer = io.BytesIO()\n        torch.jit.save(jit_model, buffer)  # type: ignore\n        buffer.seek(0)\n\n        save_data = {\n            \"settings\": model_settings,\n            \"support\": self.model.support,\n            \"outlier_kde\": self.outlier_score_kde,\n            \"model_head_save\": self.model.model_head.state_dict(),\n            \"embed_jit_save\": buffer,\n            \"train_summary\": self.train_summary,\n        }\n\n        torch.save(save_data, path)  # TODO allow model checkpointing\n\n    @classmethod\n    def load(cls, path: str) -&gt; Equine:  # noqa: F821\n        \"\"\"\n        Load a previously saved EquineProtonet model.\n\n        Parameters\n        ----------\n        path : str\n            The filename of the saved model.\n\n        Returns\n        -------\n        EquineProtonet\n            The reconstituted EquineProtonet object.\n        \"\"\"\n        model_save = torch.load(path)\n        support = model_save[\"support\"]\n        jit_model = torch.jit.load(model_save[\"embed_jit_save\"])  # type: ignore\n        eq_model = cls(jit_model, **model_save[\"settings\"])\n\n        eq_model.model.model_head.load_state_dict(model_save[\"model_head_save\"])\n        eq_model.eval()\n        eq_model.model.update_support(support)\n        eq_model.outlier_score_kde = model_save[\"outlier_kde\"]\n        eq_model.train_summary = model_save[\"train_summary\"]\n\n        return eq_model\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.calibrate_temperature","title":"<code>calibrate_temperature(calib_x, calib_y, num_calibration_epochs=1, calibration_lr=0.01)</code>","text":"<p>Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.</p> <p>Parameters:</p> Name Type Description Default <code>calib_x</code> <code>Tensor</code> <p>Training data to be used for temperature calibration.</p> required <code>calib_y</code> <code>Tensor</code> <p>Labels corresponding to <code>calib_x</code>.</p> required <code>num_calibration_epochs</code> <code>int</code> <p>Number of epochs to tune temperature, by default 1.</p> <code>1</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature optimization, by default 0.01.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def calibrate_temperature(\n    self,\n    calib_x: torch.Tensor,\n    calib_y: torch.Tensor,\n    num_calibration_epochs: int = 1,\n    calibration_lr: float = 0.01,\n) -&gt; None:\n    \"\"\"\n    Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.\n\n    Parameters\n    ----------\n    calib_x : torch.Tensor\n        Training data to be used for temperature calibration.\n    calib_y : torch.Tensor\n        Labels corresponding to `calib_x`.\n    num_calibration_epochs : int, optional\n        Number of epochs to tune temperature, by default 1.\n    calibration_lr : float, optional\n        Learning rate for temperature optimization, by default 0.01.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self.temperature.requires_grad = True\n    optimizer = torch.optim.Adam([self.temperature], lr=calibration_lr)\n    for t in range(num_calibration_epochs):\n        optimizer.zero_grad()\n        with torch.no_grad():\n            pred_probs, dists = self.model(calib_x)\n        dists = dists / self.temperature\n        loss = torch.nn.functional.cross_entropy(\n            torch.neg(dists), calib_y.to(torch.long)\n        )\n        loss.backward()\n        optimizer.step()\n    self.temperature.requires_grad = False\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.forward","title":"<code>forward(X)</code>","text":"<p>Generates logits for classification based on the input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input tensor for generating predictions.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output class predictions.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def forward(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Generates logits for classification based on the input tensor.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        The input tensor for generating predictions.\n\n    Returns\n    -------\n    torch.Tensor\n        The output class predictions.\n    \"\"\"\n    preds, _ = self.model(X)\n    return preds\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved EquineProtonet model.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The filename of the saved model.</p> required <p>Returns:</p> Type Description <code>EquineProtonet</code> <p>The reconstituted EquineProtonet object.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@classmethod\ndef load(cls, path: str) -&gt; Equine:  # noqa: F821\n    \"\"\"\n    Load a previously saved EquineProtonet model.\n\n    Parameters\n    ----------\n    path : str\n        The filename of the saved model.\n\n    Returns\n    -------\n    EquineProtonet\n        The reconstituted EquineProtonet object.\n    \"\"\"\n    model_save = torch.load(path)\n    support = model_save[\"support\"]\n    jit_model = torch.jit.load(model_save[\"embed_jit_save\"])  # type: ignore\n    eq_model = cls(jit_model, **model_save[\"settings\"])\n\n    eq_model.model.model_head.load_state_dict(model_save[\"model_head_save\"])\n    eq_model.eval()\n    eq_model.model.update_support(support)\n    eq_model.outlier_score_kde = model_save[\"outlier_kde\"]\n    eq_model.train_summary = model_save[\"train_summary\"]\n\n    return eq_model\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.predict","title":"<code>predict(X)</code>","text":"<p>Predict function for EquineProtonet, inherited and implemented from Equine.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>EquineOutput</code> <p>Output object containing prediction probabilities and OOD scores.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def predict(self, X: torch.Tensor) -&gt; EquineOutput:\n    \"\"\"Predict function for EquineProtonet, inherited and implemented from Equine.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    EquineOutput\n        Output object containing prediction probabilities and OOD scores.\n    \"\"\"\n    X_embed = self.model.compute_embeddings(X)\n    if X_embed.shape == torch.Size([self.model.emb_out_dim]):\n        X_embed = X_embed.unsqueeze(dim=0)  # Handle single examples\n    preds, dists = self.model(X)\n    if self.use_temperature:\n        dists = dists / self.temperature\n        preds = torch.softmax(torch.negative(dists), dim=1)\n    ood_dist = self._compute_ood_dist(X_embed, preds, dists)\n    ood_scores = self._compute_outlier_scores(ood_dist, preds)\n\n    return EquineOutput(classes=preds, ood_scores=ood_scores, embeddings=X_embed)\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.save","title":"<code>save(path)</code>","text":"<p>Save all model parameters to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Filename to write the model.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def save(self, path: str) -&gt; None:\n    \"\"\"\n    Save all model parameters to a file.\n\n    Parameters\n    ----------\n    path : str\n        Filename to write the model.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    model_settings = {\n        \"cov_type\": self.cov_type,\n        \"emb_out_dim\": self.emb_out_dim,\n        \"use_temperature\": self.use_temperature,\n        \"init_temperature\": self.temperature.item(),\n    }\n\n    jit_model = torch.jit.script(self.model.embedding_model)  # type: ignore\n    buffer = io.BytesIO()\n    torch.jit.save(jit_model, buffer)  # type: ignore\n    buffer.seek(0)\n\n    save_data = {\n        \"settings\": model_settings,\n        \"support\": self.model.support,\n        \"outlier_kde\": self.outlier_score_kde,\n        \"model_head_save\": self.model.model_head.state_dict(),\n        \"embed_jit_save\": buffer,\n        \"train_summary\": self.train_summary,\n    }\n\n    torch.save(save_data, path)  # TODO allow model checkpointing\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.train_model","title":"<code>train_model(dataset, num_episodes, calib_frac=0.2, support_size=25, way=3, episode_size=100, loss_fn=torch.nn.functional.cross_entropy, opt_class=torch.optim.Adam, num_calibration_epochs=2, calibration_lr=0.01)</code>","text":"<p>Train or fine-tune an EquineProtonet model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>TensorDataset</code> <p>Input pytorch TensorDataset of training data for model.</p> required <code>num_episodes</code> <code>int</code> <p>The desired number of episodes to use for training.</p> required <code>calib_frac</code> <code>float</code> <p>Fraction of given training data to reserve for model calibration, by default 0.2.</p> <code>0.2</code> <code>support_size</code> <code>int</code> <p>Number of support examples to generate for each class, by default 25.</p> <code>25</code> <code>way</code> <code>int</code> <p>Number of classes to train on per episode, by default 3.</p> <code>3</code> <code>episode_size</code> <code>int</code> <p>Number of examples to use per episode, by default 100.</p> <code>100</code> <code>loss_fn</code> <code>Callable</code> <p>A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.</p> <code>cross_entropy</code> <code>opt_class</code> <code>Callable</code> <p>A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.</p> <code>Adam</code> <code>num_calibration_epochs</code> <code>int</code> <p>The desired number of epochs to use for temperature scaling, by default 2.</p> <code>2</code> <code>calibration_lr</code> <code>float</code> <p>Learning rate for temperature scaling, by default 0.01.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>tuple[dict[str, Any], Tensor, Tensor]</code> <p>A tuple containing the model summary, the held out calibration data, and the calibration labels.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda calib_frac: calib_frac &gt; 0 and calib_frac &lt; 1)\ndef train_model(\n    self,\n    dataset: TensorDataset,\n    num_episodes: int,\n    calib_frac: float = 0.2,\n    support_size: int = 25,\n    way: int = 3,\n    episode_size: int = 100,\n    loss_fn: Callable = torch.nn.functional.cross_entropy,\n    opt_class: Callable = torch.optim.Adam,\n    num_calibration_epochs: int = 2,\n    calibration_lr: float = 0.01,\n) -&gt; tuple[dict[str, Any], torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Train or fine-tune an EquineProtonet model.\n\n    Parameters\n    ----------\n    dataset : TensorDataset\n        Input pytorch TensorDataset of training data for model.\n    num_episodes : int\n        The desired number of episodes to use for training.\n    calib_frac : float, optional\n        Fraction of given training data to reserve for model calibration, by default 0.2.\n    support_size : int, optional\n        Number of support examples to generate for each class, by default 25.\n    way : int, optional\n        Number of classes to train on per episode, by default 3.\n    episode_size : int, optional\n        Number of examples to use per episode, by default 100.\n    loss_fn : Callable, optional\n        A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.\n    opt_class : Callable, optional\n        A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.\n    num_calibration_epochs : int, optional\n        The desired number of epochs to use for temperature scaling, by default 2.\n    calibration_lr : float, optional\n        Learning rate for temperature scaling, by default 0.01.\n\n    Returns\n    -------\n    tuple[dict[str, Any], torch.Tensor, torch.Tensor]\n        A tuple containing the model summary, the held out calibration data, and the calibration labels.\n    \"\"\"\n    self.train()\n\n    if self.use_temperature:\n        self.temperature = torch.Tensor(\n            self.init_temperature * torch.ones(1)\n        ).type_as(self.temperature)\n\n    X, Y = dataset[:]\n\n    train_x, calib_x, train_y, calib_y = train_test_split(\n        X, Y, test_size=calib_frac, stratify=Y\n    )  # TODO: Replace sklearn with torch call\n    optimizer = opt_class(self.parameters())\n\n    for i in tqdm(range(num_episodes)):\n        optimizer.zero_grad()\n\n        support, episode_x, episode_y = generate_episode(\n            train_x, train_y, support_size, way, episode_size\n        )\n        self.model.update_support(support)\n\n        _, dists = self.model(episode_x)\n        loss_value = loss_fn(torch.neg(dists), episode_y)\n        loss_value.backward()\n        optimizer.step()\n\n    self.eval()\n    full_support = generate_support(\n        train_x,\n        train_y,\n        support_size,\n        selected_labels=torch.unique(train_y).tolist(),\n    )\n\n    self.model.update_support(\n        full_support\n    )  # update support with final selected examples\n\n    X_embed = self.model.compute_embeddings(calib_x)\n    pred_probs, dists = self.model(calib_x)\n    ood_dists = self._compute_ood_dist(X_embed, pred_probs, dists)\n    self._fit_outlier_scores(ood_dists, calib_y)\n\n    if self.use_temperature:\n        self.calibrate_temperature(\n            calib_x, calib_y, num_calibration_epochs, calibration_lr\n        )\n\n    date_trained = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n    self.train_summary = generate_train_summary(self, train_y, date_trained)\n    return self.train_summary, calib_x, calib_y\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.EquineProtonet.update_support","title":"<code>update_support(support_x, support_y, calib_frac)</code>","text":"<p>Function to update protonet support examples with given examples.</p> <p>Parameters:</p> Name Type Description Default <code>support_x</code> <code>Tensor</code> <p>Tensor containing support examples for protonet.</p> required <code>support_y</code> <code>Tensor</code> <p>Tensor containing labels for given support examples.</p> required <code>calib_frac</code> <code>float</code> <p>Fraction of given support data to use for OOD calibration.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda calib_frac: (calib_frac &gt; 0.0) and (calib_frac &lt; 1.0))\ndef update_support(\n    self, support_x: torch.Tensor, support_y: torch.Tensor, calib_frac: float\n) -&gt; None:\n    \"\"\"Function to update protonet support examples with given examples.\n\n    Parameters\n    ----------\n    support_x : torch.Tensor\n        Tensor containing support examples for protonet.\n    support_y : torch.Tensor\n        Tensor containing labels for given support examples.\n    calib_frac : float\n        Fraction of given support data to use for OOD calibration.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    support_x, calib_x, support_y, calib_y = train_test_split(\n        support_x, support_y, test_size=calib_frac, stratify=support_y\n    )\n    labels, counts = torch.unique(support_y, return_counts=True)\n    support = OrderedDict()\n    for label, count in list(zip(labels.tolist(), counts.tolist())):\n        class_support = generate_support(\n            support_x,\n            support_y,\n            support_size=count,\n            selected_labels=[label],\n        )\n        support.update(class_support)\n\n    self.model.update_support(support)\n\n    X_embed = self.model.compute_embeddings(calib_x)\n    preds, dists = self.model(calib_x)\n    ood_dists = self._compute_ood_dist(X_embed, preds, dists)\n\n    self._fit_outlier_scores(ood_dists, calib_y)\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet","title":"<code>Protonet</code>","text":"<p>               Bases: <code>Module</code></p> <p>Private class that implements a prototypical neural network for use in EQUINE.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@beartype\nclass Protonet(torch.nn.Module):\n    \"\"\"\n    Private class that implements a prototypical neural network for use in EQUINE.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model: torch.nn.Module,\n        emb_out_dim: int,\n        cov_type: CovType,\n        cov_reg_type: str,\n        epsilon: float,\n    ) -&gt; None:\n        \"\"\"\n        Protonet class constructor.\n\n        Parameters\n        ----------\n        embedding_model : torch.nn.Module\n            The PyTorch embedding model to generate logits with.\n        emb_out_dim : int\n            Dimension size of given embedding model's output.\n        cov_type : CovType\n            Type of covariance to use when computing distances [unit, diag, full].\n        cov_reg_type : str\n            Type of regularization to use when generating the covariance matrix [epsilon, shared].\n        epsilon : float\n            Epsilon value to use for covariance regularization.\n        \"\"\"\n        super().__init__()\n        self.embedding_model = embedding_model\n        self.cov_type = cov_type\n        self.cov_reg_type = cov_reg_type\n        self.epsilon = epsilon\n        self.emb_out_dim = emb_out_dim\n\n        self.support = None\n        # self.support_embeddings = None\n        self.model_head = self.create_model_head(emb_out_dim)\n\n    def create_model_head(self, emb_out_dim: int):\n        \"\"\"\n        Method for adding a PyTorch layer on top of the given embedding model. This layer\n        is intended to offer extra degrees of freedom for distance learning in the embedding space.\n\n        Parameters\n        ----------\n        emb_out_dim : int\n            Dimension size of the embedding model output.\n\n        Returns\n        -------\n        torch.nn.Linear\n            The created PyTorch model layer.\n        \"\"\"\n        return torch.nn.Linear(emb_out_dim, emb_out_dim)\n\n    def compute_embeddings(self, X: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Method for calculating model embeddings using both the given embedding model and the added model head.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor to compute embeddings on.\n\n        Returns\n        -------\n        torch.Tensor\n            Fully computed embedding tensors for the given X tensor.\n        \"\"\"\n        model_embeddings = self.embedding_model(X)\n        head_embeddings = self.model_head(model_embeddings)\n        return head_embeddings\n\n    @icontract.require(lambda self: self.support_embeddings is not None)\n    def compute_prototypes(self) -&gt; torch.Tensor:\n        \"\"\"\n        Method for computing class prototypes based on given support examples.\n        ``Prototypes'' in this context are the means of the support embeddings for each class.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensors of prototypes for each of the given classes in the support.\n        \"\"\"\n        # Compute prototype for each class\n        proto_list = []\n        for label in self.support_embeddings:  # look at doing functorch\n            class_prototype = torch.mean(self.support_embeddings[label], dim=0)  # type: ignore\n            proto_list.append(class_prototype)\n\n        prototypes = torch.stack(proto_list)\n\n        return prototypes\n\n    @icontract.require(lambda self: len(self.support_embeddings) &gt; 0)\n    def compute_covariance(self, cov_type: CovType) -&gt; torch.Tensor:\n        \"\"\"\n        Method for generating the (regularized) support example covariance matrix(es) used for calculating distances.\n        Note that this method is only called once per episode, and the resulting tensor is used for all queries.\n\n        Parameters\n        ----------\n        cov_type : CovType\n            Type of covariance to use [unit, diag, full].\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor containing the generated regularized covariance matrix.\n        \"\"\"\n        class_cov_dict = OrderedDict().fromkeys(self.support_embeddings.keys())\n        for label in self.support_embeddings.keys():\n            class_covariance = self.compute_covariance_by_type(\n                cov_type, self.support_embeddings[label]\n            )\n            class_cov_dict[label] = class_covariance\n\n        reg_covariance_dict = self.regularize_covariance(class_cov_dict, cov_type)\n        reg_covariance = torch.stack(list(reg_covariance_dict.values()))\n\n        return reg_covariance  # TODO try putting everything on GPU with .to() and see if faster\n\n    def compute_covariance_by_type(\n        self, cov_type: CovType, embedding: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"Method to select appropriate covariance matrix type based on cov_type\n        :param cov_type: Type of covariance to use [unit, diag, full]\n        :param embedding: embedding tensor to use when generating the covariance matrix\n        :return torch.Tensor: Tensor containing the requested covariance matrix\n        \"\"\"\n        if cov_type == CovType.FULL:\n            class_covariance = torch.cov(embedding.T)\n        elif cov_type == CovType.DIAGONAL:\n            class_covariance = torch.var(embedding, dim=0)\n        elif cov_type == CovType.UNIT:\n            class_covariance = torch.ones(self.emb_out_dim)\n        else:\n            raise ValueError\n\n        return class_covariance\n\n    def regularize_covariance(\n        self, class_cov_dict: OrderedDict[int, torch.Tensor], cov_type: CovType\n    ) -&gt; OrderedDict[int, torch.Tensor]:\n        \"\"\"\n        Method to add regularization to each class covariance matrix based on the selected regularization type.\n\n        Parameters\n        ----------\n        class_cov_dict : OrderedDict[int, torch.Tensor]\n            A dictionary containing each class and the corresponding covariance matrix.\n        cov_type : CovType\n            Type of covariance to use [unit, diag, full].\n\n        Returns\n        -------\n        dict[float, torch.Tensor]\n            Dictionary containing the regularized class covariance matrices.\n        \"\"\"\n\n        if cov_type == CovType.FULL:\n            regularization = torch.diag(self.epsilon * torch.ones(self.emb_out_dim))\n        elif cov_type == CovType.DIAGONAL:\n            regularization = self.epsilon * torch.ones(self.emb_out_dim)\n        elif cov_type == CovType.UNIT:\n            regularization = torch.zeros(self.emb_out_dim)\n        else:\n            raise ValueError(\"Unknown Covariance Type\")\n\n        if self.cov_reg_type == \"shared\":\n            if cov_type != CovType.FULL and cov_type != CovType.DIAGONAL:\n                for label in self.support_embeddings:\n                    class_cov_dict[label] = class_cov_dict[label] + regularization\n                warnings.warn(\n                    \"Covariance type UNIT is incompatible with shared regularization, \\\n                    reverting to epsilon regularization\"\n                )\n                return class_cov_dict\n\n            shared_covariance = self.compute_shared_covariance(class_cov_dict, cov_type)\n\n            for label in self.support_embeddings:\n                num_class_support = self.support_embeddings[label].shape[0]\n                lamb = num_class_support / (num_class_support + 1)\n\n                class_cov_dict[label] = (\n                    lamb * class_cov_dict[label]\n                    + (1 - lamb) * shared_covariance\n                    + regularization\n                )\n\n        elif self.cov_reg_type == \"epsilon\":\n            for label in self.support_embeddings:\n                class_cov_dict[label] = class_cov_dict[label] + regularization\n\n        return class_cov_dict\n\n    def compute_shared_covariance(\n        self, class_cov_dict: OrderedDict[int, torch.Tensor], cov_type: CovType\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Method to calculate a shared covariance matrix.\n\n        The shared covariance matrix is calculated as the weighted average of the class covariance matrices,\n        where the weights are the number of support examples for each class. This is useful when the number of\n        support examples for each class is small.\n\n        Parameters\n        ----------\n        class_cov_dict : OrderedDict[int, torch.Tensor]\n            A dictionary containing each class and the corresponding covariance matrix.\n        cov_type : CovType\n            Type of covariance to use [unit, diag, full].\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor containing the shared covariance matrix.\n        \"\"\"\n        total_support = sum([x.shape[0] for x in class_cov_dict.values()])\n\n        if cov_type == CovType.FULL:\n            shared_covariance = torch.zeros((self.emb_out_dim, self.emb_out_dim))\n        elif cov_type == CovType.DIAGONAL:\n            shared_covariance = torch.zeros(self.emb_out_dim)\n        else:\n            raise ValueError(\n                \"Shared covariance can only be used with FULL or DIAGONAL (not UNIT) covariance types\"\n            )\n\n        for label in class_cov_dict:\n            num_class_support = class_cov_dict[label].shape[0]\n            shared_covariance = (\n                shared_covariance + (num_class_support - 1) * class_cov_dict[label]\n            )  # undo N-1 div from cov\n\n        shared_covariance = shared_covariance / (\n            total_support - 1\n        )  # redo N-1 div for shared cov\n\n        return shared_covariance\n\n    @icontract.require(lambda X_embed, mu: X_embed.shape[-1] == mu.shape[-1])\n    @icontract.ensure(lambda result: torch.all(result &gt;= 0))\n    def compute_distance(\n        self, X_embed: torch.Tensor, mu: torch.Tensor, cov: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Method to compute the distances to class prototypes for the given embeddings.\n\n        Parameters\n        ----------\n        X_embed : torch.Tensor\n            The embeddings of the query examples.\n        mu : torch.Tensor\n            The class prototypes (means of the support embeddings).\n        cov : torch.Tensor\n            The support covariance matrix.\n\n        Returns\n        -------\n        torch.Tensor\n            The calculated distances from each of the class prototypes for the given embeddings.\n        \"\"\"\n        _queries = torch.unsqueeze(X_embed, 1)  # examples x 1 x dimension\n        diff = torch.sub(mu, _queries)  # examples x classes x dimension\n\n        if len(cov.shape) == 2:  # (diagonal covariance)\n            # examples x classes x dimension\n            dist = torch.nan_to_num(torch.div(diff**2, cov))\n            dist = torch.sum(dist, dim=2)  # examples x classes\n            dist = dist.squeeze(dim=1)\n            dist = torch.sqrt(dist + self.epsilon)  # examples x classes\n        else:  # len(cov.shape) == 3: (full covariance)\n            diff = diff.permute(1, 2, 0)  # classes x dimension x examples\n            dist = mahalanobis_distance_nosq(diff, cov)\n            dist = torch.sqrt(dist.permute(1, 0) + self.epsilon)  # examples x classes\n            dist = dist.squeeze(dim=1)\n        return dist\n\n    def compute_classes(self, distances: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Method to compute predicted classes from distances via a softmax function.\n\n        Parameters\n        ----------\n        distances : torch.Tensor\n            The distances of embeddings to class prototypes.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of class predictions.\n        \"\"\"\n        softmax = torch.nn.functional.softmax(torch.neg(distances), dim=-1)\n        return softmax\n\n    def forward(self, X: torch.Tensor) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Protonet forward function, generates class probability predictions and distances from prototypes.\n\n        Parameters\n        ----------\n        X : torch.Tensor\n            Input tensor of queries for generating predictions.\n\n        Returns\n        -------\n        tuple[torch.Tensor, torch.Tensor]\n            Tuple containing class probability predictions, and class distances from prototypes.\n        \"\"\"\n        if self.support is None or self.support_embeddings is None:\n            raise ValueError(\n                \"No support examples found. Protonet Model requires model support to \\\n                    be set with the 'update_support()' method before calling forward.\"\n            )\n\n        X_embed = self.compute_embeddings(X)\n        if X_embed.shape == torch.Size([self.emb_out_dim]):\n            X_embed = X_embed.unsqueeze(dim=0)  # handle single examples\n        distances = self.compute_distance(X_embed, self.prototypes, self.covariance)\n        classes = self.compute_classes(distances)\n\n        return classes, distances\n\n    def update_support(self, support: OrderedDict[int, torch.Tensor]) -&gt; None:\n        \"\"\"\n        Method to update the support examples, and all the calculations that rely on them.\n\n        Parameters\n        ----------\n        support : OrderedDict\n            Ordered dict containing class labels and their associated support examples.\n        \"\"\"\n        self.support = support  # TODO torch.nn.ParameterDict(support)\n\n        support_embs = OrderedDict().fromkeys(support.keys())\n        for label in support:\n            support_embs[label] = self.compute_embeddings(support[label])\n\n        self.support_embeddings = (\n            support_embs  # TODO torch.nn.ParameterDict(support_embs)\n        )\n\n        self.prototypes = self.compute_prototypes()\n\n        if self.training is False:\n            self.compute_global_moments()\n            self.covariance = self.compute_covariance(cov_type=PRED_COV_TYPE)\n        else:\n            self.covariance = self.compute_covariance(cov_type=self.cov_type)\n\n    @icontract.require(lambda self: self.support_embeddings is not None)\n    def compute_global_moments(self) -&gt; None:\n        \"\"\"Method to calculate the global moments of the support embeddings for use in OOD score generation\"\"\"\n        embeddings = torch.cat(list(self.support_embeddings.values()))\n        self.global_covariance = torch.unsqueeze(\n            self.compute_covariance_by_type(OOD_COV_TYPE, embeddings), dim=0\n        )\n        self.global_mean = torch.mean(embeddings, dim=0)\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.__init__","title":"<code>__init__(embedding_model, emb_out_dim, cov_type, cov_reg_type, epsilon)</code>","text":"<p>Protonet class constructor.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>Module</code> <p>The PyTorch embedding model to generate logits with.</p> required <code>emb_out_dim</code> <code>int</code> <p>Dimension size of given embedding model's output.</p> required <code>cov_type</code> <code>CovType</code> <p>Type of covariance to use when computing distances [unit, diag, full].</p> required <code>cov_reg_type</code> <code>str</code> <p>Type of regularization to use when generating the covariance matrix [epsilon, shared].</p> required <code>epsilon</code> <code>float</code> <p>Epsilon value to use for covariance regularization.</p> required Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def __init__(\n    self,\n    embedding_model: torch.nn.Module,\n    emb_out_dim: int,\n    cov_type: CovType,\n    cov_reg_type: str,\n    epsilon: float,\n) -&gt; None:\n    \"\"\"\n    Protonet class constructor.\n\n    Parameters\n    ----------\n    embedding_model : torch.nn.Module\n        The PyTorch embedding model to generate logits with.\n    emb_out_dim : int\n        Dimension size of given embedding model's output.\n    cov_type : CovType\n        Type of covariance to use when computing distances [unit, diag, full].\n    cov_reg_type : str\n        Type of regularization to use when generating the covariance matrix [epsilon, shared].\n    epsilon : float\n        Epsilon value to use for covariance regularization.\n    \"\"\"\n    super().__init__()\n    self.embedding_model = embedding_model\n    self.cov_type = cov_type\n    self.cov_reg_type = cov_reg_type\n    self.epsilon = epsilon\n    self.emb_out_dim = emb_out_dim\n\n    self.support = None\n    # self.support_embeddings = None\n    self.model_head = self.create_model_head(emb_out_dim)\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_classes","title":"<code>compute_classes(distances)</code>","text":"<p>Method to compute predicted classes from distances via a softmax function.</p> <p>Parameters:</p> Name Type Description Default <code>distances</code> <code>Tensor</code> <p>The distances of embeddings to class prototypes.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of class predictions.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def compute_classes(self, distances: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Method to compute predicted classes from distances via a softmax function.\n\n    Parameters\n    ----------\n    distances : torch.Tensor\n        The distances of embeddings to class prototypes.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of class predictions.\n    \"\"\"\n    softmax = torch.nn.functional.softmax(torch.neg(distances), dim=-1)\n    return softmax\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_covariance","title":"<code>compute_covariance(cov_type)</code>","text":"<p>Method for generating the (regularized) support example covariance matrix(es) used for calculating distances. Note that this method is only called once per episode, and the resulting tensor is used for all queries.</p> <p>Parameters:</p> Name Type Description Default <code>cov_type</code> <code>CovType</code> <p>Type of covariance to use [unit, diag, full].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor containing the generated regularized covariance matrix.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda self: len(self.support_embeddings) &gt; 0)\ndef compute_covariance(self, cov_type: CovType) -&gt; torch.Tensor:\n    \"\"\"\n    Method for generating the (regularized) support example covariance matrix(es) used for calculating distances.\n    Note that this method is only called once per episode, and the resulting tensor is used for all queries.\n\n    Parameters\n    ----------\n    cov_type : CovType\n        Type of covariance to use [unit, diag, full].\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor containing the generated regularized covariance matrix.\n    \"\"\"\n    class_cov_dict = OrderedDict().fromkeys(self.support_embeddings.keys())\n    for label in self.support_embeddings.keys():\n        class_covariance = self.compute_covariance_by_type(\n            cov_type, self.support_embeddings[label]\n        )\n        class_cov_dict[label] = class_covariance\n\n    reg_covariance_dict = self.regularize_covariance(class_cov_dict, cov_type)\n    reg_covariance = torch.stack(list(reg_covariance_dict.values()))\n\n    return reg_covariance  # TODO try putting everything on GPU with .to() and see if faster\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_covariance_by_type","title":"<code>compute_covariance_by_type(cov_type, embedding)</code>","text":"<p>Method to select appropriate covariance matrix type based on cov_type :param cov_type: Type of covariance to use [unit, diag, full] :param embedding: embedding tensor to use when generating the covariance matrix :return torch.Tensor: Tensor containing the requested covariance matrix</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def compute_covariance_by_type(\n    self, cov_type: CovType, embedding: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"Method to select appropriate covariance matrix type based on cov_type\n    :param cov_type: Type of covariance to use [unit, diag, full]\n    :param embedding: embedding tensor to use when generating the covariance matrix\n    :return torch.Tensor: Tensor containing the requested covariance matrix\n    \"\"\"\n    if cov_type == CovType.FULL:\n        class_covariance = torch.cov(embedding.T)\n    elif cov_type == CovType.DIAGONAL:\n        class_covariance = torch.var(embedding, dim=0)\n    elif cov_type == CovType.UNIT:\n        class_covariance = torch.ones(self.emb_out_dim)\n    else:\n        raise ValueError\n\n    return class_covariance\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_distance","title":"<code>compute_distance(X_embed, mu, cov)</code>","text":"<p>Method to compute the distances to class prototypes for the given embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>X_embed</code> <code>Tensor</code> <p>The embeddings of the query examples.</p> required <code>mu</code> <code>Tensor</code> <p>The class prototypes (means of the support embeddings).</p> required <code>cov</code> <code>Tensor</code> <p>The support covariance matrix.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The calculated distances from each of the class prototypes for the given embeddings.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda X_embed, mu: X_embed.shape[-1] == mu.shape[-1])\n@icontract.ensure(lambda result: torch.all(result &gt;= 0))\ndef compute_distance(\n    self, X_embed: torch.Tensor, mu: torch.Tensor, cov: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Method to compute the distances to class prototypes for the given embeddings.\n\n    Parameters\n    ----------\n    X_embed : torch.Tensor\n        The embeddings of the query examples.\n    mu : torch.Tensor\n        The class prototypes (means of the support embeddings).\n    cov : torch.Tensor\n        The support covariance matrix.\n\n    Returns\n    -------\n    torch.Tensor\n        The calculated distances from each of the class prototypes for the given embeddings.\n    \"\"\"\n    _queries = torch.unsqueeze(X_embed, 1)  # examples x 1 x dimension\n    diff = torch.sub(mu, _queries)  # examples x classes x dimension\n\n    if len(cov.shape) == 2:  # (diagonal covariance)\n        # examples x classes x dimension\n        dist = torch.nan_to_num(torch.div(diff**2, cov))\n        dist = torch.sum(dist, dim=2)  # examples x classes\n        dist = dist.squeeze(dim=1)\n        dist = torch.sqrt(dist + self.epsilon)  # examples x classes\n    else:  # len(cov.shape) == 3: (full covariance)\n        diff = diff.permute(1, 2, 0)  # classes x dimension x examples\n        dist = mahalanobis_distance_nosq(diff, cov)\n        dist = torch.sqrt(dist.permute(1, 0) + self.epsilon)  # examples x classes\n        dist = dist.squeeze(dim=1)\n    return dist\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_embeddings","title":"<code>compute_embeddings(X)</code>","text":"<p>Method for calculating model embeddings using both the given embedding model and the added model head.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor to compute embeddings on.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Fully computed embedding tensors for the given X tensor.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def compute_embeddings(self, X: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Method for calculating model embeddings using both the given embedding model and the added model head.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor to compute embeddings on.\n\n    Returns\n    -------\n    torch.Tensor\n        Fully computed embedding tensors for the given X tensor.\n    \"\"\"\n    model_embeddings = self.embedding_model(X)\n    head_embeddings = self.model_head(model_embeddings)\n    return head_embeddings\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_global_moments","title":"<code>compute_global_moments()</code>","text":"<p>Method to calculate the global moments of the support embeddings for use in OOD score generation</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda self: self.support_embeddings is not None)\ndef compute_global_moments(self) -&gt; None:\n    \"\"\"Method to calculate the global moments of the support embeddings for use in OOD score generation\"\"\"\n    embeddings = torch.cat(list(self.support_embeddings.values()))\n    self.global_covariance = torch.unsqueeze(\n        self.compute_covariance_by_type(OOD_COV_TYPE, embeddings), dim=0\n    )\n    self.global_mean = torch.mean(embeddings, dim=0)\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_prototypes","title":"<code>compute_prototypes()</code>","text":"<p>Method for computing class prototypes based on given support examples. ``Prototypes'' in this context are the means of the support embeddings for each class.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensors of prototypes for each of the given classes in the support.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>@icontract.require(lambda self: self.support_embeddings is not None)\ndef compute_prototypes(self) -&gt; torch.Tensor:\n    \"\"\"\n    Method for computing class prototypes based on given support examples.\n    ``Prototypes'' in this context are the means of the support embeddings for each class.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensors of prototypes for each of the given classes in the support.\n    \"\"\"\n    # Compute prototype for each class\n    proto_list = []\n    for label in self.support_embeddings:  # look at doing functorch\n        class_prototype = torch.mean(self.support_embeddings[label], dim=0)  # type: ignore\n        proto_list.append(class_prototype)\n\n    prototypes = torch.stack(proto_list)\n\n    return prototypes\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.compute_shared_covariance","title":"<code>compute_shared_covariance(class_cov_dict, cov_type)</code>","text":"<p>Method to calculate a shared covariance matrix.</p> <p>The shared covariance matrix is calculated as the weighted average of the class covariance matrices, where the weights are the number of support examples for each class. This is useful when the number of support examples for each class is small.</p> <p>Parameters:</p> Name Type Description Default <code>class_cov_dict</code> <code>OrderedDict[int, Tensor]</code> <p>A dictionary containing each class and the corresponding covariance matrix.</p> required <code>cov_type</code> <code>CovType</code> <p>Type of covariance to use [unit, diag, full].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor containing the shared covariance matrix.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def compute_shared_covariance(\n    self, class_cov_dict: OrderedDict[int, torch.Tensor], cov_type: CovType\n) -&gt; torch.Tensor:\n    \"\"\"\n    Method to calculate a shared covariance matrix.\n\n    The shared covariance matrix is calculated as the weighted average of the class covariance matrices,\n    where the weights are the number of support examples for each class. This is useful when the number of\n    support examples for each class is small.\n\n    Parameters\n    ----------\n    class_cov_dict : OrderedDict[int, torch.Tensor]\n        A dictionary containing each class and the corresponding covariance matrix.\n    cov_type : CovType\n        Type of covariance to use [unit, diag, full].\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor containing the shared covariance matrix.\n    \"\"\"\n    total_support = sum([x.shape[0] for x in class_cov_dict.values()])\n\n    if cov_type == CovType.FULL:\n        shared_covariance = torch.zeros((self.emb_out_dim, self.emb_out_dim))\n    elif cov_type == CovType.DIAGONAL:\n        shared_covariance = torch.zeros(self.emb_out_dim)\n    else:\n        raise ValueError(\n            \"Shared covariance can only be used with FULL or DIAGONAL (not UNIT) covariance types\"\n        )\n\n    for label in class_cov_dict:\n        num_class_support = class_cov_dict[label].shape[0]\n        shared_covariance = (\n            shared_covariance + (num_class_support - 1) * class_cov_dict[label]\n        )  # undo N-1 div from cov\n\n    shared_covariance = shared_covariance / (\n        total_support - 1\n    )  # redo N-1 div for shared cov\n\n    return shared_covariance\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.create_model_head","title":"<code>create_model_head(emb_out_dim)</code>","text":"<p>Method for adding a PyTorch layer on top of the given embedding model. This layer is intended to offer extra degrees of freedom for distance learning in the embedding space.</p> <p>Parameters:</p> Name Type Description Default <code>emb_out_dim</code> <code>int</code> <p>Dimension size of the embedding model output.</p> required <p>Returns:</p> Type Description <code>Linear</code> <p>The created PyTorch model layer.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def create_model_head(self, emb_out_dim: int):\n    \"\"\"\n    Method for adding a PyTorch layer on top of the given embedding model. This layer\n    is intended to offer extra degrees of freedom for distance learning in the embedding space.\n\n    Parameters\n    ----------\n    emb_out_dim : int\n        Dimension size of the embedding model output.\n\n    Returns\n    -------\n    torch.nn.Linear\n        The created PyTorch model layer.\n    \"\"\"\n    return torch.nn.Linear(emb_out_dim, emb_out_dim)\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.forward","title":"<code>forward(X)</code>","text":"<p>Protonet forward function, generates class probability predictions and distances from prototypes.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>Input tensor of queries for generating predictions.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Tuple containing class probability predictions, and class distances from prototypes.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def forward(self, X: torch.Tensor) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Protonet forward function, generates class probability predictions and distances from prototypes.\n\n    Parameters\n    ----------\n    X : torch.Tensor\n        Input tensor of queries for generating predictions.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        Tuple containing class probability predictions, and class distances from prototypes.\n    \"\"\"\n    if self.support is None or self.support_embeddings is None:\n        raise ValueError(\n            \"No support examples found. Protonet Model requires model support to \\\n                be set with the 'update_support()' method before calling forward.\"\n        )\n\n    X_embed = self.compute_embeddings(X)\n    if X_embed.shape == torch.Size([self.emb_out_dim]):\n        X_embed = X_embed.unsqueeze(dim=0)  # handle single examples\n    distances = self.compute_distance(X_embed, self.prototypes, self.covariance)\n    classes = self.compute_classes(distances)\n\n    return classes, distances\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.regularize_covariance","title":"<code>regularize_covariance(class_cov_dict, cov_type)</code>","text":"<p>Method to add regularization to each class covariance matrix based on the selected regularization type.</p> <p>Parameters:</p> Name Type Description Default <code>class_cov_dict</code> <code>OrderedDict[int, Tensor]</code> <p>A dictionary containing each class and the corresponding covariance matrix.</p> required <code>cov_type</code> <code>CovType</code> <p>Type of covariance to use [unit, diag, full].</p> required <p>Returns:</p> Type Description <code>dict[float, Tensor]</code> <p>Dictionary containing the regularized class covariance matrices.</p> Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def regularize_covariance(\n    self, class_cov_dict: OrderedDict[int, torch.Tensor], cov_type: CovType\n) -&gt; OrderedDict[int, torch.Tensor]:\n    \"\"\"\n    Method to add regularization to each class covariance matrix based on the selected regularization type.\n\n    Parameters\n    ----------\n    class_cov_dict : OrderedDict[int, torch.Tensor]\n        A dictionary containing each class and the corresponding covariance matrix.\n    cov_type : CovType\n        Type of covariance to use [unit, diag, full].\n\n    Returns\n    -------\n    dict[float, torch.Tensor]\n        Dictionary containing the regularized class covariance matrices.\n    \"\"\"\n\n    if cov_type == CovType.FULL:\n        regularization = torch.diag(self.epsilon * torch.ones(self.emb_out_dim))\n    elif cov_type == CovType.DIAGONAL:\n        regularization = self.epsilon * torch.ones(self.emb_out_dim)\n    elif cov_type == CovType.UNIT:\n        regularization = torch.zeros(self.emb_out_dim)\n    else:\n        raise ValueError(\"Unknown Covariance Type\")\n\n    if self.cov_reg_type == \"shared\":\n        if cov_type != CovType.FULL and cov_type != CovType.DIAGONAL:\n            for label in self.support_embeddings:\n                class_cov_dict[label] = class_cov_dict[label] + regularization\n            warnings.warn(\n                \"Covariance type UNIT is incompatible with shared regularization, \\\n                reverting to epsilon regularization\"\n            )\n            return class_cov_dict\n\n        shared_covariance = self.compute_shared_covariance(class_cov_dict, cov_type)\n\n        for label in self.support_embeddings:\n            num_class_support = self.support_embeddings[label].shape[0]\n            lamb = num_class_support / (num_class_support + 1)\n\n            class_cov_dict[label] = (\n                lamb * class_cov_dict[label]\n                + (1 - lamb) * shared_covariance\n                + regularization\n            )\n\n    elif self.cov_reg_type == \"epsilon\":\n        for label in self.support_embeddings:\n            class_cov_dict[label] = class_cov_dict[label] + regularization\n\n    return class_cov_dict\n</code></pre>"},{"location":"reference/equine/equine_protonet/#equine.equine_protonet.Protonet.update_support","title":"<code>update_support(support)</code>","text":"<p>Method to update the support examples, and all the calculations that rely on them.</p> <p>Parameters:</p> Name Type Description Default <code>support</code> <code>OrderedDict</code> <p>Ordered dict containing class labels and their associated support examples.</p> required Source code in <code>src/equine/equine_protonet.py</code> <pre><code>def update_support(self, support: OrderedDict[int, torch.Tensor]) -&gt; None:\n    \"\"\"\n    Method to update the support examples, and all the calculations that rely on them.\n\n    Parameters\n    ----------\n    support : OrderedDict\n        Ordered dict containing class labels and their associated support examples.\n    \"\"\"\n    self.support = support  # TODO torch.nn.ParameterDict(support)\n\n    support_embs = OrderedDict().fromkeys(support.keys())\n    for label in support:\n        support_embs[label] = self.compute_embeddings(support[label])\n\n    self.support_embeddings = (\n        support_embs  # TODO torch.nn.ParameterDict(support_embs)\n    )\n\n    self.prototypes = self.compute_prototypes()\n\n    if self.training is False:\n        self.compute_global_moments()\n        self.covariance = self.compute_covariance(cov_type=PRED_COV_TYPE)\n    else:\n        self.covariance = self.compute_covariance(cov_type=self.cov_type)\n</code></pre>"},{"location":"reference/equine/utils/","title":"utils","text":""},{"location":"reference/equine/utils/#equine.utils.brier_score","title":"<code>brier_score(y_hat, y_test)</code>","text":"<p>Compute the Brier score for a multiclass problem.</p> <p>Parameters:</p> Name Type Description Default <code>y_hat</code> <code>Tensor</code> <p>Probabilities for each class.</p> required <code>y_test</code> <code>Tensor</code> <p>Integer argument class labels (ground truth).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Brier score.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda y_hat, y_test: y_hat.size(dim=0) == y_test.size(dim=0))\n@icontract.ensure(lambda result: result &gt;= 0.0)\n@beartype\ndef brier_score(y_hat: torch.Tensor, y_test: torch.Tensor) -&gt; float:\n    \"\"\"\n    Compute the Brier score for a multiclass problem.\n\n    Parameters\n    ----------\n    y_hat : torch.Tensor\n        Probabilities for each class.\n    y_test : torch.Tensor\n        Integer argument class labels (ground truth).\n\n    Returns\n    -------\n    float\n        Brier score.\n    \"\"\"\n    (_, num_classes) = y_hat.size()\n    one_hot_y_test = torch.nn.functional.one_hot(y_test.long(), num_classes=num_classes)\n    bs = torch.mean(torch.sum((y_hat - one_hot_y_test) ** 2, dim=1)).item()\n    return bs\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.brier_skill_score","title":"<code>brier_skill_score(y_hat, y_test)</code>","text":"<p>Compute the Brier skill score as compared to randomly guessing.</p> <p>Parameters:</p> Name Type Description Default <code>y_hat</code> <code>Tensor</code> <p>Probabilities for each class.</p> required <code>y_test</code> <code>Tensor</code> <p>Integer argument class labels (ground truth).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Brier skill score.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda y_hat, y_test: y_hat.size(dim=0) == y_test.size(dim=0))\n@icontract.ensure(lambda result: result &lt;= 1.0)\n@beartype\ndef brier_skill_score(y_hat: torch.Tensor, y_test: torch.Tensor) -&gt; float:\n    \"\"\"\n    Compute the Brier skill score as compared to randomly guessing.\n\n    Parameters\n    ----------\n    y_hat : torch.Tensor\n        Probabilities for each class.\n    y_test : torch.Tensor\n        Integer argument class labels (ground truth).\n\n    Returns\n    -------\n    float\n        Brier skill score.\n    \"\"\"\n    (_, num_classes) = y_hat.size()\n    random_guess = (1.0 / num_classes) * torch.ones(y_hat.size())\n    bs0 = brier_score(random_guess, y_test)\n    bs1 = brier_score(y_hat, y_test)\n    bss = 1.0 - bs1 / bs0\n    return bss\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.expected_calibration_error","title":"<code>expected_calibration_error(y_hat, y_test)</code>","text":"<p>Compute the expected calibration error (ECE) for a multiclass problem.</p> <p>Parameters:</p> Name Type Description Default <code>y_hat</code> <code>Tensor</code> <p>Probabilities for each class.</p> required <code>y_test</code> <code>Tensor</code> <p>Class label indices (ground truth).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Expected calibration error.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda y_hat, y_test: y_hat.size(dim=0) == y_test.size(dim=0))\n@icontract.ensure(lambda result: (0.0 &lt;= result) and (result &lt;= 1.0))\n@beartype\ndef expected_calibration_error(y_hat: torch.Tensor, y_test: torch.Tensor) -&gt; float:\n    \"\"\"\n    Compute the expected calibration error (ECE) for a multiclass problem.\n\n    Parameters\n    ----------\n    y_hat : torch.Tensor\n        Probabilities for each class.\n    y_test : torch.Tensor\n        Class label indices (ground truth).\n\n    Returns\n    -------\n    float\n        Expected calibration error.\n    \"\"\"\n    (_, num_classes) = y_hat.size()\n    metric = MulticlassCalibrationError(num_classes=num_classes, n_bins=25, norm=\"l1\")\n    ece = metric(y_hat, y_test).item()\n    return ece\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.generate_episode","title":"<code>generate_episode(train_x, train_y, support_size, way, episode_size)</code>","text":"<p>Generate a single episode of data for a few-shot learning task.</p> <p>Parameters:</p> Name Type Description Default <code>train_x</code> <code>Tensor</code> <p>Input training data.</p> required <code>train_y</code> <code>Tensor</code> <p>Corresponding classification labels.</p> required <code>support_size</code> <code>int</code> <p>Number of support examples for each class.</p> required <code>way</code> <code>int</code> <p>Number of classes in the episode.</p> required <code>episode_size</code> <code>int</code> <p>Total number of examples in the episode.</p> required <p>Returns:</p> Type Description <code>Tuple[dict[Any, Tensor], Tensor, Tensor]</code> <p>Tuple of support examples, query examples, and query labels.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda train_x: len(train_x.shape) &gt;= 2)\n@icontract.require(lambda train_y: len(train_y.shape) == 1)\n@icontract.require(lambda support_size: support_size &gt; 1)\n@icontract.require(lambda way: way &gt; 0)\n@icontract.require(lambda episode_size: episode_size &gt; 0)\n@icontract.ensure(lambda result: len(result) == 3)\n@icontract.ensure(lambda result: result[1].shape[0] == result[2].shape[0])\n@icontract.ensure(lambda way, result: len(result[0]) == way)\n@icontract.ensure(\n    lambda support_size, result: all(\n        len(support) == support_size for support in result[0].values()\n    )\n)\n@beartype\ndef generate_episode(\n    train_x: torch.Tensor,\n    train_y: torch.Tensor,\n    support_size: int,\n    way: int,\n    episode_size: int,\n) -&gt; Tuple[dict[Any, torch.Tensor], torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Generate a single episode of data for a few-shot learning task.\n\n    Parameters\n    ----------\n    train_x : torch.Tensor\n        Input training data.\n    train_y : torch.Tensor\n        Corresponding classification labels.\n    support_size : int\n        Number of support examples for each class.\n    way : int\n        Number of classes in the episode.\n    episode_size : int\n        Total number of examples in the episode.\n\n    Returns\n    -------\n    Tuple[dict[Any, torch.Tensor], torch.Tensor, torch.Tensor]\n        Tuple of support examples, query examples, and query labels.\n    \"\"\"\n    labels, counts = torch.unique(train_y, return_counts=True)\n    if way &gt; len(labels):\n        raise ValueError(\n            f\"The way (#classes in each episode), {way}, must be &lt;= number of labels, {len(labels)}\"\n        )\n\n    selected_labels = sorted(\n        labels[torch.randperm(labels.shape[0])][:way].tolist()\n    )  # need to be in same order every time\n\n    for label, count in list(zip(labels, counts)):\n        if (label in selected_labels) and (count &lt; support_size):\n            raise ValueError(f\"Not enough support examples in class {label}\")\n    shuffled_idxs = _get_shuffle_idxs_by_class(train_y, selected_labels)\n\n    support = generate_support(\n        train_x, train_y, support_size, selected_labels, shuffled_idxs\n    )\n\n    examples_per_task = episode_size // way\n\n    episode_data_list = []\n    episode_label_list = []\n    episode_support = OrderedDict()\n    for episode_label, label in enumerate(selected_labels):\n        shuffled_x = train_x[shuffled_idxs[label]]\n        shuffled_y = torch.Tensor(\n            [episode_label] * len(shuffled_idxs[label])\n        )  # need sequential labels for episode\n\n        num_remaining_examples = shuffled_x.shape[0] - support_size\n        assert num_remaining_examples &gt; 0, (\n            \"Cannot have \"\n            + str(num_remaining_examples)\n            + \" left with support_size \"\n            + str(support_size)\n            + \" and shape \"\n            + str(shuffled_x.shape)\n            + \" from train_x shaped \"\n            + str(train_x.shape)\n        )\n        episode_end_idx = support_size + min(num_remaining_examples, examples_per_task)\n\n        episode_data_list.append(shuffled_x[support_size:episode_end_idx])\n        episode_label_list.append(shuffled_y[support_size:episode_end_idx])\n        episode_support[episode_label] = support[label]\n\n    episode_x = torch.concat(episode_data_list)\n    episode_y = torch.concat(episode_label_list)\n\n    return episode_support, episode_x, episode_y.squeeze().to(torch.long)\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.generate_model_metrics","title":"<code>generate_model_metrics(eq_preds, true_y)</code>","text":"<p>Generate various metrics for evaluating a model's performance.</p> <p>Parameters:</p> Name Type Description Default <code>eq_preds</code> <code>EquineOutput</code> <p>Model predictions.</p> required <code>true_y</code> <code>Tensor</code> <p>True class labels.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of model metrics.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(\n    lambda eq_preds, true_y: eq_preds.classes.size(dim=0) == true_y.size(dim=0)\n)\n@beartype\ndef generate_model_metrics(\n    eq_preds: EquineOutput, true_y: torch.Tensor\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate various metrics for evaluating a model's performance.\n\n    Parameters\n    ----------\n    eq_preds : EquineOutput\n        Model predictions.\n    true_y : torch.Tensor\n        True class labels.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary of model metrics.\n    \"\"\"\n    pred_y = torch.argmax(eq_preds.classes, dim=1)\n    metrics = {\n        \"accuracy\": accuracy_score(true_y, pred_y),\n        \"microF1Score\": f1_score(true_y, pred_y, average=\"micro\"),\n        \"confusionMatrix\": confusion_matrix(true_y, pred_y).tolist(),\n        \"brierScore\": brier_score(eq_preds.classes, true_y),\n        \"brierSkillScore\": brier_skill_score(eq_preds.classes, true_y),\n        \"expectedCalibrationError\": expected_calibration_error(\n            eq_preds.classes, true_y\n        ),\n    }\n    return metrics\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.generate_model_summary","title":"<code>generate_model_summary(model, eq_preds, test_y)</code>","text":"<p>Generate a summary of the model's performance.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Equine</code> <p>Model object.</p> required <code>eq_preds</code> <code>EquineOutput</code> <p>Model predictions.</p> required <code>test_y</code> <code>Tensor</code> <p>True class labels.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing model summary.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(\n    lambda eq_preds, test_y: test_y.shape[0] == eq_preds.classes.shape[0]\n)\n@beartype\ndef generate_model_summary(\n    model: Equine,\n    eq_preds: EquineOutput,\n    test_y: torch.Tensor,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate a summary of the model's performance.\n\n    Parameters\n    ----------\n    model : Equine\n        Model object.\n    eq_preds : EquineOutput\n        Model predictions.\n    test_y : torch.Tensor\n        True class labels.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing model summary.\n    \"\"\"\n    summary = generate_model_metrics(eq_preds, test_y)\n    summary[\"numTestExamples\"] = get_num_examples_per_label(test_y)\n    summary.update(model.train_summary)  # union of train_summary and generated metrics\n\n    return summary\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.generate_support","title":"<code>generate_support(train_x, train_y, support_size, selected_labels, shuffled_indexes=None)</code>","text":"<p>Randomly select <code>support_size</code> examples of <code>way</code> classes from the examples in <code>train_x</code> with corresponding labels in <code>train_y</code> and return them as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>train_x</code> <code>Tensor</code> <p>Input training data.</p> required <code>train_y</code> <code>Tensor</code> <p>Corresponding classification labels.</p> required <code>support_size</code> <code>int</code> <p>Number of support examples for each class.</p> required <code>selected_labels</code> <code>List</code> <p>Selected class labels to generate examples from.</p> required <code>shuffled_indexes</code> <code>Union[None, dict[Any, Tensor]]</code> <p>Simply use the precomputed indexes if they are available</p> <code>None</code> <p>Returns:</p> Type Description <code>OrderedDict[int, Tensor]</code> <p>Ordered dictionary of class labels with corresponding support examples.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda train_x, train_y: len(train_x) &lt;= len(train_y))\n@icontract.require(\n    lambda selected_labels, train_x: (0 &lt; len(selected_labels))\n    &amp; (len(selected_labels) &lt; len(train_x))\n)\n@icontract.require(\n    lambda support_size, train_x: (0 &lt; support_size) &amp; (support_size &lt; len(train_x))\n)\n@icontract.require(\n    lambda support_size, selected_labels, train_x: support_size * len(selected_labels)\n    &lt;= len(train_x)\n)\n@icontract.require(\n    lambda selected_labels, shuffled_indexes: (\n        (len(shuffled_indexes.keys()) == len(selected_labels))\n        if shuffled_indexes is not None\n        else True\n    )\n)\n@icontract.ensure(\n    lambda result, selected_labels: len(result.keys()) == len(selected_labels)\n)\n@beartype\ndef generate_support(\n    train_x: torch.Tensor,\n    train_y: torch.Tensor,\n    support_size: int,\n    selected_labels: List[Any],\n    shuffled_indexes: Union[None, dict[Any, torch.Tensor]] = None,\n) -&gt; OrderedDict[int, torch.Tensor]:\n    \"\"\"\n    Randomly select `support_size` examples of `way` classes from the examples in\n    `train_x` with corresponding labels in `train_y` and return them as a dictionary.\n\n    Parameters\n    ----------\n    train_x : torch.Tensor\n        Input training data.\n    train_y : torch.Tensor\n        Corresponding classification labels.\n    support_size : int\n        Number of support examples for each class.\n    selected_labels : List\n        Selected class labels to generate examples from.\n    shuffled_indexes: Union[None, dict[Any, torch.Tensor]], optional\n        Simply use the precomputed indexes if they are available\n\n    Returns\n    -------\n    OrderedDict[int, torch.Tensor]\n        Ordered dictionary of class labels with corresponding support examples.\n    \"\"\"\n    labels, counts = torch.unique(train_y, return_counts=True)\n    if shuffled_indexes is None:\n        for label, count in list(zip(labels, counts)):\n            if (label in selected_labels) and (count &lt; support_size):\n                raise ValueError(f\"Not enough support examples in class {label}\")\n        shuffled_idxs = _get_shuffle_idxs_by_class(train_y, selected_labels)\n    else:\n        shuffled_idxs = shuffled_indexes\n\n    support = OrderedDict[int, torch.Tensor]()\n    for label in selected_labels:\n        shuffled_x = train_x[shuffled_idxs[label]]\n\n        assert torch.unique(train_y[shuffled_idxs[label]]).tolist() == [\n            label\n        ], \"Not enough support for label \" + str(label)\n        selected_support = shuffled_x[:support_size]\n        support[int(label)] = selected_support\n\n    return support\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.generate_train_summary","title":"<code>generate_train_summary(model, train_y, date_trained)</code>","text":"<p>Generate a summary of the training data.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Equine</code> <p>Model object.</p> required <code>train_y</code> <code>Tensor</code> <p>Training labels.</p> required <code>date_trained</code> <code>str</code> <p>Date of training.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing training summary.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda train_y: train_y.shape[0] &gt; 0)\n@beartype\ndef generate_train_summary(\n    model: Equine, train_y: torch.Tensor, date_trained: str\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate a summary of the training data.\n\n    Parameters\n    ----------\n    model : Equine\n        Model object.\n    train_y : torch.Tensor\n        Training labels.\n    date_trained : str\n        Date of training.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary containing training summary.\n    \"\"\"\n    train_summary = {\n        \"numTrainExamples\": get_num_examples_per_label(train_y),\n        \"dateTrained\": date_trained,\n        \"modelType\": model.__class__.__name__,\n    }\n    return train_summary\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.get_num_examples_per_label","title":"<code>get_num_examples_per_label(Y)</code>","text":"<p>Get the number of examples per label in the given tensor.</p> <p>Parameters:</p> Name Type Description Default <code>Y</code> <code>Tensor</code> <p>Tensor of class labels.</p> required <p>Returns:</p> Type Description <code>List[dict[str, Any]]</code> <p>List of dictionaries containing label and number of examples.</p> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda Y: len(Y.shape) == 1)\n@icontract.ensure(\n    lambda result: all(\"label\" in d and \"numExamples\" in d for d in result)\n)\n@icontract.ensure(lambda result: all(d[\"numExamples\"] &gt;= 0 for d in result))\n@beartype\ndef get_num_examples_per_label(Y: torch.Tensor) -&gt; List[dict[str, Any]]:\n    \"\"\"\n    Get the number of examples per label in the given tensor.\n\n    Parameters\n    ----------\n    Y : torch.Tensor\n        Tensor of class labels.\n\n    Returns\n    -------\n    List[dict[str, Any]]\n        List of dictionaries containing label and number of examples.\n    \"\"\"\n    tensor_labels, tensor_counts = Y.unique(return_counts=True)\n\n    examples_per_label = []\n    for i, label in enumerate(tensor_labels):\n        examples_per_label.append(\n            {\"label\": label.item(), \"numExamples\": tensor_counts[i].item()}\n        )\n\n    return examples_per_label\n</code></pre>"},{"location":"reference/equine/utils/#equine.utils.mahalanobis_distance_nosq","title":"<code>mahalanobis_distance_nosq(x, cov)</code>","text":"<p>Compute Mahalanobis distance x^T C x (without square root), assume cov is symmetric positive definite</p> <pre><code>Parameters\n</code></pre> <pre><code>x : torch.Tensor\n    vectors to compute distances for\ncov : torch.Tensor\n    covariance matrix, assumes first dimension is number of classes\n</code></pre> Source code in <code>src/equine/utils.py</code> <pre><code>@icontract.require(lambda cov: cov.shape[-2] == cov.shape[-1])\ndef mahalanobis_distance_nosq(x: torch.Tensor, cov: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute Mahalanobis distance x^T C x (without square root), assume cov is symmetric positive definite\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            vectors to compute distances for\n        cov : torch.Tensor\n            covariance matrix, assumes first dimension is number of classes\n    \"\"\"\n    U, S, _ = torch.linalg.svd(cov)\n    S_inv_sqrt = torch.stack(\n        [torch.diag(torch.sqrt(1.0 / S[i])) for i in range(S.shape[0])], dim=0\n    )\n    prod = torch.matmul(S_inv_sqrt, torch.transpose(U, 1, 2))\n    dist = torch.sum(torch.square(torch.matmul(prod, x)), dim=1)\n    return dist\n</code></pre>"}]}