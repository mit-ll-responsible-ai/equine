
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Allan Wollaber, Steven Jorgensen, John Holodnak, Jensen Dempsey, and Harry Li">
      
      
      
        <link rel="prev" href="../equine_output/">
      
      
        <link rel="next" href="../utils/">
      
      
      <link rel="icon" href="../../../assets/favicon.svg">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.32">
    
    
      
        <title>equine_protonet - EQUi(Ne)<sup>2</sup> Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#equine.equine_protonet" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="EQUi(Ne)&lt;sup&gt;2&lt;/sup&gt; Documentation" class="md-header__button md-logo" aria-label="EQUi(Ne)<sup>2</sup> Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            EQUi(Ne)<sup>2</sup> Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              equine_protonet
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mit-ll-responsible-ai/equine" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../example_notebooks/toy_example_GP/" class="md-tabs__link">
          
  
  Examples

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  Code Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../CONTRIBUTING/" class="md-tabs__link">
          
  
  Development

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="EQUi(Ne)&lt;sup&gt;2&lt;/sup&gt; Documentation" class="md-nav__button md-logo" aria-label="EQUi(Ne)<sup>2</sup> Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    EQUi(Ne)<sup>2</sup> Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mit-ll-responsible-ai/equine" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Home
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../LICENSE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../example_notebooks/toy_example_GP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Toy Problem with GP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../example_notebooks/toy_example_EquineProtonet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Toy Problem with Protonet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../example_notebooks/MNIST_OOD_detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../example_notebooks/vnat_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Encrypted Network Traffic
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Code Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Code Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    equine
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            equine
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../_version/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    _version
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../equine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    equine
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../equine_gp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    equine_gp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../equine_output/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    equine_output
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    equine_protonet
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    equine_protonet
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#equine.equine_protonet" class="md-nav__link">
    <span class="md-ellipsis">
      equine_protonet
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet" class="md-nav__link">
    <span class="md-ellipsis">
      EquineProtonet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EquineProtonet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.calibrate_temperature" class="md-nav__link">
    <span class="md-ellipsis">
      calibrate_temperature
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.load" class="md-nav__link">
    <span class="md-ellipsis">
      load
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.save" class="md-nav__link">
    <span class="md-ellipsis">
      save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.train_model" class="md-nav__link">
    <span class="md-ellipsis">
      train_model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.update_support" class="md-nav__link">
    <span class="md-ellipsis">
      update_support
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet" class="md-nav__link">
    <span class="md-ellipsis">
      Protonet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Protonet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_classes" class="md-nav__link">
    <span class="md-ellipsis">
      compute_classes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_covariance_by_type" class="md-nav__link">
    <span class="md-ellipsis">
      compute_covariance_by_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_distance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      compute_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_global_moments" class="md-nav__link">
    <span class="md-ellipsis">
      compute_global_moments
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_prototypes" class="md-nav__link">
    <span class="md-ellipsis">
      compute_prototypes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_shared_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_shared_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.create_model_head" class="md-nav__link">
    <span class="md-ellipsis">
      create_model_head
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.regularize_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      regularize_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.update_support" class="md-nav__link">
    <span class="md-ellipsis">
      update_support
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Development
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Development
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CONTRIBUTING/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#equine.equine_protonet" class="md-nav__link">
    <span class="md-ellipsis">
      equine_protonet
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet" class="md-nav__link">
    <span class="md-ellipsis">
      EquineProtonet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EquineProtonet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.calibrate_temperature" class="md-nav__link">
    <span class="md-ellipsis">
      calibrate_temperature
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.load" class="md-nav__link">
    <span class="md-ellipsis">
      load
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.save" class="md-nav__link">
    <span class="md-ellipsis">
      save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.train_model" class="md-nav__link">
    <span class="md-ellipsis">
      train_model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.EquineProtonet.update_support" class="md-nav__link">
    <span class="md-ellipsis">
      update_support
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet" class="md-nav__link">
    <span class="md-ellipsis">
      Protonet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Protonet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_classes" class="md-nav__link">
    <span class="md-ellipsis">
      compute_classes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_covariance_by_type" class="md-nav__link">
    <span class="md-ellipsis">
      compute_covariance_by_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_distance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      compute_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_global_moments" class="md-nav__link">
    <span class="md-ellipsis">
      compute_global_moments
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_prototypes" class="md-nav__link">
    <span class="md-ellipsis">
      compute_prototypes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.compute_shared_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_shared_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.create_model_head" class="md-nav__link">
    <span class="md-ellipsis">
      create_model_head
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.regularize_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      regularize_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equine.equine_protonet.Protonet.update_support" class="md-nav__link">
    <span class="md-ellipsis">
      update_support
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>equine_protonet</h1>

<div class="doc doc-object doc-module">



<a id="equine.equine_protonet"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="equine.equine_protonet.EquineProtonet" class="doc doc-heading">
            <code>EquineProtonet</code>


<a href="#equine.equine_protonet.EquineProtonet" class="headerlink" title="Permanent link">Â¤</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="equine.equine.Equine" href="../equine/#equine.equine.Equine">Equine</a></code></p>


      <p>A class representing an EQUINE model that utilizes protonets and (optionally) relative Mahalanobis distances
to generate OOD and model confidence scores. This wraps any pytorch embedding neural network
and provides the <code>forward</code>, <code>predict</code>, <code>save</code>, and <code>load</code> methods required by Equine.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>embedding_model</code></td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neural Network feature embedding model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>emb_out_dim</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of output features from the embedding model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cov_type</code></td>
            <td>
                  <code><span title="equine.equine_protonet.CovType">CovType</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of covariance to use when training the protonet [UNIT, DIAG, FULL], by default CovType.UNIT.</p>
              </div>
            </td>
            <td>
                  <code><span title="equine.equine_protonet.CovType.UNIT">UNIT</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>relative_mahal</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Use relative mahalanobis distance for OOD calculations. If false, uses standard mahalanobis distance instead, by default True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>use_temperature</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use temperature scaling after training, by default False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>init_temperature</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>What to use as the initial temperature (1.0 has no effect), by default 1.0.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@beartype</span>
<span class="k">class</span> <span class="nc">EquineProtonet</span><span class="p">(</span><span class="n">Equine</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing an EQUINE model that utilizes protonets and (optionally) relative Mahalanobis distances</span>
<span class="sd">    to generate OOD and model confidence scores. This wraps any pytorch embedding neural network</span>
<span class="sd">    and provides the `forward`, `predict`, `save`, and `load` methods required by Equine.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    embedding_model : torch.nn.Module</span>
<span class="sd">        Neural Network feature embedding model.</span>
<span class="sd">    emb_out_dim : int</span>
<span class="sd">        The number of output features from the embedding model.</span>
<span class="sd">    cov_type : CovType, optional</span>
<span class="sd">        The type of covariance to use when training the protonet [UNIT, DIAG, FULL], by default CovType.UNIT.</span>
<span class="sd">    relative_mahal : bool, optional</span>
<span class="sd">        Use relative mahalanobis distance for OOD calculations. If false, uses standard mahalanobis distance instead, by default True.</span>
<span class="sd">    use_temperature : bool, optional</span>
<span class="sd">        Whether to use temperature scaling after training, by default False.</span>
<span class="sd">    init_temperature : float, optional</span>
<span class="sd">        What to use as the initial temperature (1.0 has no effect), by default 1.0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding_model</span><span class="p">,</span>
        <span class="n">emb_out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span> <span class="o">=</span> <span class="n">CovType</span><span class="o">.</span><span class="n">UNIT</span><span class="p">,</span>
        <span class="n">relative_mahal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_temperature</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">init_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">embedding_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">=</span> <span class="n">cov_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_reg_type</span> <span class="o">=</span> <span class="n">COV_REG_TYPE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relative_mahal</span> <span class="o">=</span> <span class="n">relative_mahal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span> <span class="o">=</span> <span class="n">emb_out_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">DEFAULT_EPSILON</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_summary</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span> <span class="o">=</span> <span class="n">use_temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_temperature</span> <span class="o">=</span> <span class="n">init_temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_temperature</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">Protonet</span><span class="p">(</span>
            <span class="n">embedding_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cov_reg_type</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates logits for classification based on the input tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : torch.Tensor</span>
<span class="sd">            The input tensor for generating predictions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The output class predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">preds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">preds</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="n">calib_frac</span><span class="p">:</span> <span class="n">calib_frac</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">calib_frac</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">TensorDataset</span><span class="p">,</span>
        <span class="n">num_episodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">calib_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">support_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
        <span class="n">way</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">episode_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span>
        <span class="n">opt_class</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="n">num_calibration_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">calibration_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train or fine-tune an EquineProtonet model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dataset : TensorDataset</span>
<span class="sd">            Input pytorch TensorDataset of training data for model.</span>
<span class="sd">        num_episodes : int</span>
<span class="sd">            The desired number of episodes to use for training.</span>
<span class="sd">        calib_frac : float, optional</span>
<span class="sd">            Fraction of given training data to reserve for model calibration, by default 0.2.</span>
<span class="sd">        support_size : int, optional</span>
<span class="sd">            Number of support examples to generate for each class, by default 25.</span>
<span class="sd">        way : int, optional</span>
<span class="sd">            Number of classes to train on per episode, by default 3.</span>
<span class="sd">        episode_size : int, optional</span>
<span class="sd">            Number of examples to use per episode, by default 100.</span>
<span class="sd">        loss_fn : Callable, optional</span>
<span class="sd">            A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.</span>
<span class="sd">        opt_class : Callable, optional</span>
<span class="sd">            A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.</span>
<span class="sd">        num_calibration_epochs : int, optional</span>
<span class="sd">            The desired number of epochs to use for temperature scaling, by default 2.</span>
<span class="sd">        calibration_lr : float, optional</span>
<span class="sd">            Learning rate for temperature scaling, by default 0.01.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple[dict[str, Any], torch.Tensor, torch.Tensor]</span>
<span class="sd">            A tuple containing the model summary, the held out calibration data, and the calibration labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_temperature</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:]</span>

        <span class="n">train_x</span><span class="p">,</span> <span class="n">calib_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">calib_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">calib_frac</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">Y</span>
        <span class="p">)</span>  <span class="c1"># TODO: Replace sklearn with torch call</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt_class</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">)):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">support</span><span class="p">,</span> <span class="n">episode_x</span><span class="p">,</span> <span class="n">episode_y</span> <span class="o">=</span> <span class="n">generate_episode</span><span class="p">(</span>
                <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">support_size</span><span class="p">,</span> <span class="n">way</span><span class="p">,</span> <span class="n">episode_size</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">episode_x</span><span class="p">)</span>
            <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">episode_y</span><span class="p">)</span>
            <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">full_support</span> <span class="o">=</span> <span class="n">generate_support</span><span class="p">(</span>
            <span class="n">train_x</span><span class="p">,</span>
            <span class="n">train_y</span><span class="p">,</span>
            <span class="n">support_size</span><span class="p">,</span>
            <span class="n">selected_labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_y</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span>
            <span class="n">full_support</span>
        <span class="p">)</span>  <span class="c1"># update support with final selected examples</span>

        <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
        <span class="n">pred_probs</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
        <span class="n">ood_dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ood_dist</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_outlier_scores</span><span class="p">(</span><span class="n">ood_dists</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calibrate_temperature</span><span class="p">(</span>
                <span class="n">calib_x</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">,</span> <span class="n">num_calibration_epochs</span><span class="p">,</span> <span class="n">calibration_lr</span>
            <span class="p">)</span>

        <span class="n">date_trained</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%m/</span><span class="si">%d</span><span class="s2">/%Y, %H:%M:%S&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_summary</span> <span class="o">=</span> <span class="n">generate_train_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">date_trained</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_summary</span><span class="p">,</span> <span class="n">calib_x</span><span class="p">,</span> <span class="n">calib_y</span>

    <span class="k">def</span> <span class="nf">calibrate_temperature</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">calib_x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">calib_y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">num_calibration_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">calibration_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        calib_x : torch.Tensor</span>
<span class="sd">            Training data to be used for temperature calibration.</span>
<span class="sd">        calib_y : torch.Tensor</span>
<span class="sd">            Labels corresponding to `calib_x`.</span>
<span class="sd">        num_calibration_epochs : int, optional</span>
<span class="sd">            Number of epochs to tune temperature, by default 1.</span>
<span class="sd">        calibration_lr : float, optional</span>
<span class="sd">            Learning rate for temperature optimization, by default 0.01.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">calibration_lr</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_calibration_epochs</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">pred_probs</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">calib_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_fit_outlier_scores</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">ood_dists</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private function to fit outlier scores with a kernel density estimate (KDE).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ood_dists : torch.Tensor</span>
<span class="sd">            Tensor of computed OOD distances.</span>
<span class="sd">        calib_y : torch.Tensor</span>
<span class="sd">            Tensor of class labels for `ood_dists` examples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span><span class="p">:</span>
            <span class="n">class_ood_dists</span> <span class="o">=</span> <span class="n">ood_dists</span><span class="p">[</span><span class="n">calib_y</span> <span class="o">==</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">class_kde</span> <span class="o">=</span> <span class="n">gaussian_kde</span><span class="p">(</span><span class="n">class_ood_dists</span><span class="p">)</span>  <span class="c1"># TODO convert to torch func</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_kde</span>

    <span class="k">def</span> <span class="nf">_compute_outlier_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ood_dists</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private function to compute OOD scores using the calculated kernel density estimate (KDE).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ood_dists : torch.Tensor</span>
<span class="sd">            Tensor of computed OOD distances.</span>
<span class="sd">        predictions : torch.Tensor</span>
<span class="sd">            Tensor of model protonet predictions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensor of OOD scores for the given examples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ood_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">ood_dists</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)):</span>
            <span class="c1"># Use KDE and RMD corresponding to the predicted class</span>
            <span class="n">predicted_class</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span>
            <span class="n">p_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span>
                <span class="n">ood_dists</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="p">)</span>
            <span class="n">ood_scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">p_value</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ood_scores</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">result</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_compute_ood_dist</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X_embeddings</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">predictions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">distances</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private function to compute OOD distances using a distance function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_embeddings : torch.Tensor</span>
<span class="sd">            Tensor of example embeddings.</span>
<span class="sd">        predictions : torch.Tensor</span>
<span class="sd">            Tensor of model protonet predictions for the given embeddings.</span>
<span class="sd">        distances : torch.Tensor</span>
<span class="sd">            Tensor of calculated protonet distances for the given embeddings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensor of OOD distances for the given embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Calculate (Relative) Mahalanobis Distance:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">relative_mahal</span><span class="p">:</span>
            <span class="n">null_distance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_distance</span><span class="p">(</span>
                <span class="n">X_embeddings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">global_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">global_covariance</span>
            <span class="p">)</span>
            <span class="n">null_distance</span> <span class="o">=</span> <span class="n">null_distance</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">ood_dist</span> <span class="o">=</span> <span class="n">distances</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span> <span class="o">-</span> <span class="n">null_distance</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ood_dist</span> <span class="o">=</span> <span class="n">distances</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>

        <span class="n">ood_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ood_dist</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">ood_dist</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EquineOutput</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict function for EquineProtonet, inherited and implemented from Equine.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : torch.Tensor</span>
<span class="sd">            Input tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        EquineOutput</span>
<span class="sd">            Output object containing prediction probabilities and OOD scores.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">]):</span>
            <span class="n">X_embed</span> <span class="o">=</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Handle single examples</span>
        <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">:</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">negative</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ood_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ood_dist</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>
        <span class="n">ood_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_outlier_scores</span><span class="p">(</span><span class="n">ood_dist</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">EquineOutput</span><span class="p">(</span><span class="n">classes</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">ood_scores</span><span class="o">=</span><span class="n">ood_scores</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">X_embed</span><span class="p">)</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="n">calib_frac</span><span class="p">:</span> <span class="p">(</span><span class="n">calib_frac</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">calib_frac</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">update_support</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">support_x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support_y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">calib_frac</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Function to update protonet support examples with given examples.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        support_x : torch.Tensor</span>
<span class="sd">            Tensor containing support examples for protonet.</span>
<span class="sd">        support_y : torch.Tensor</span>
<span class="sd">            Tensor containing labels for given support examples.</span>
<span class="sd">        calib_frac : float</span>
<span class="sd">            Fraction of given support data to use for OOD calibration.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">support_x</span><span class="p">,</span> <span class="n">calib_x</span><span class="p">,</span> <span class="n">support_y</span><span class="p">,</span> <span class="n">calib_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="n">support_x</span><span class="p">,</span> <span class="n">support_y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">calib_frac</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">support_y</span>
        <span class="p">)</span>
        <span class="n">labels</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">support_y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">support</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">counts</span><span class="o">.</span><span class="n">tolist</span><span class="p">())):</span>
            <span class="n">class_support</span> <span class="o">=</span> <span class="n">generate_support</span><span class="p">(</span>
                <span class="n">support_x</span><span class="p">,</span>
                <span class="n">support_y</span><span class="p">,</span>
                <span class="n">support_size</span><span class="o">=</span><span class="n">count</span><span class="p">,</span>
                <span class="n">selected_labels</span><span class="o">=</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">support</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">class_support</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>

        <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
        <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
        <span class="n">ood_dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ood_dist</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_outlier_scores</span><span class="p">(</span><span class="n">ood_dists</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">)</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_support</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prototypes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_prototypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prototypes</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save all model parameters to a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            Filename to write the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_settings</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;cov_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span><span class="p">,</span>
            <span class="s2">&quot;emb_out_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">,</span>
            <span class="s2">&quot;use_temperature&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">,</span>
            <span class="s2">&quot;init_temperature&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="s2">&quot;relative_mahal&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">relative_mahal</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">jit_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embedding_model</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">jit_model</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">buffer</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">save_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;settings&quot;</span><span class="p">:</span> <span class="n">model_settings</span><span class="p">,</span>
            <span class="s2">&quot;support&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support</span><span class="p">,</span>
            <span class="s2">&quot;outlier_kde&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span><span class="p">,</span>
            <span class="s2">&quot;model_head_save&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_head</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;embed_jit_save&quot;</span><span class="p">:</span> <span class="n">buffer</span><span class="p">,</span>
            <span class="s2">&quot;train_summary&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_summary</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_data</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>  <span class="c1"># TODO allow model checkpointing</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Equine</span><span class="p">:</span>  <span class="c1"># noqa: F821</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a previously saved EquineProtonet model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            The filename of the saved model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        EquineProtonet</span>
<span class="sd">            The reconstituted EquineProtonet object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_save</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">support</span> <span class="o">=</span> <span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;support&quot;</span><span class="p">]</span>
        <span class="n">jit_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;embed_jit_save&quot;</span><span class="p">])</span>  <span class="c1"># type: ignore</span>
        <span class="n">eq_model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">jit_model</span><span class="p">,</span> <span class="o">**</span><span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;settings&quot;</span><span class="p">])</span>

        <span class="n">eq_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_head</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;model_head_save&quot;</span><span class="p">])</span>
        <span class="n">eq_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">eq_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>
        <span class="n">eq_model</span><span class="o">.</span><span class="n">outlier_score_kde</span> <span class="o">=</span> <span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;outlier_kde&quot;</span><span class="p">]</span>
        <span class="n">eq_model</span><span class="o">.</span><span class="n">train_summary</span> <span class="o">=</span> <span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;train_summary&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">eq_model</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.calibrate_temperature" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">calibrate_temperature</span><span class="p">(</span><span class="n">calib_x</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">,</span> <span class="n">num_calibration_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">calibration_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.EquineProtonet.calibrate_temperature" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>calib_x</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Training data to be used for temperature calibration.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>calib_y</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Labels corresponding to <code>calib_x</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_calibration_epochs</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to tune temperature, by default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>calibration_lr</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Learning rate for temperature optimization, by default 0.01.</p>
              </div>
            </td>
            <td>
                  <code>0.01</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">calibrate_temperature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">calib_x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">calib_y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">num_calibration_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">calibration_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fine-tune the temperature after training. Note that this function is also run at the conclusion of train_model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    calib_x : torch.Tensor</span>
<span class="sd">        Training data to be used for temperature calibration.</span>
<span class="sd">    calib_y : torch.Tensor</span>
<span class="sd">        Labels corresponding to `calib_x`.</span>
<span class="sd">    num_calibration_epochs : int, optional</span>
<span class="sd">        Number of epochs to tune temperature, by default 1.</span>
<span class="sd">    calibration_lr : float, optional</span>
<span class="sd">        Learning rate for temperature optimization, by default 0.01.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">calibration_lr</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_calibration_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">pred_probs</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">calib_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.EquineProtonet.forward" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Generates logits for classification based on the input tensor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor for generating predictions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The output class predictions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates logits for classification based on the input tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : torch.Tensor</span>
<span class="sd">        The input tensor for generating predictions.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        The output class predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#equine.equine_protonet.EquineProtonet.load" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Load a previously saved EquineProtonet model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The filename of the saved model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="equine.equine_protonet.EquineProtonet" href="#equine.equine_protonet.EquineProtonet">EquineProtonet</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The reconstituted EquineProtonet object.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Equine</span><span class="p">:</span>  <span class="c1"># noqa: F821</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a previously saved EquineProtonet model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    path : str</span>
<span class="sd">        The filename of the saved model.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    EquineProtonet</span>
<span class="sd">        The reconstituted EquineProtonet object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_save</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">support</span> <span class="o">=</span> <span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;support&quot;</span><span class="p">]</span>
    <span class="n">jit_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;embed_jit_save&quot;</span><span class="p">])</span>  <span class="c1"># type: ignore</span>
    <span class="n">eq_model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">jit_model</span><span class="p">,</span> <span class="o">**</span><span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;settings&quot;</span><span class="p">])</span>

    <span class="n">eq_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_head</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;model_head_save&quot;</span><span class="p">])</span>
    <span class="n">eq_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">eq_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>
    <span class="n">eq_model</span><span class="o">.</span><span class="n">outlier_score_kde</span> <span class="o">=</span> <span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;outlier_kde&quot;</span><span class="p">]</span>
    <span class="n">eq_model</span><span class="o">.</span><span class="n">train_summary</span> <span class="o">=</span> <span class="n">model_save</span><span class="p">[</span><span class="s2">&quot;train_summary&quot;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">eq_model</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.predict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.EquineProtonet.predict" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Predict function for EquineProtonet, inherited and implemented from Equine.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="equine.equine.EquineOutput" href="../equine_output/#equine.equine_output.EquineOutput">EquineOutput</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output object containing prediction probabilities and OOD scores.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EquineOutput</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predict function for EquineProtonet, inherited and implemented from Equine.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : torch.Tensor</span>
<span class="sd">        Input tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    EquineOutput</span>
<span class="sd">        Output object containing prediction probabilities and OOD scores.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">]):</span>
        <span class="n">X_embed</span> <span class="o">=</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Handle single examples</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">:</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">negative</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ood_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ood_dist</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>
    <span class="n">ood_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_outlier_scores</span><span class="p">(</span><span class="n">ood_dist</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">EquineOutput</span><span class="p">(</span><span class="n">classes</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">ood_scores</span><span class="o">=</span><span class="n">ood_scores</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">X_embed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.EquineProtonet.save" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Save all model parameters to a file.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>path</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filename to write the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save all model parameters to a file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    path : str</span>
<span class="sd">        Filename to write the model.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;cov_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span><span class="p">,</span>
        <span class="s2">&quot;emb_out_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">,</span>
        <span class="s2">&quot;use_temperature&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">,</span>
        <span class="s2">&quot;init_temperature&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="s2">&quot;relative_mahal&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">relative_mahal</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">jit_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embedding_model</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
    <span class="n">buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">jit_model</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
    <span class="n">buffer</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">save_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;settings&quot;</span><span class="p">:</span> <span class="n">model_settings</span><span class="p">,</span>
        <span class="s2">&quot;support&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support</span><span class="p">,</span>
        <span class="s2">&quot;outlier_kde&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">outlier_score_kde</span><span class="p">,</span>
        <span class="s2">&quot;model_head_save&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_head</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s2">&quot;embed_jit_save&quot;</span><span class="p">:</span> <span class="n">buffer</span><span class="p">,</span>
        <span class="s2">&quot;train_summary&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_summary</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_data</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>  <span class="c1"># TODO allow model checkpointing</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.train_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_model</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">num_episodes</span><span class="p">,</span> <span class="n">calib_frac</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">support_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">way</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">episode_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">opt_class</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">num_calibration_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">calibration_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.EquineProtonet.train_model" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Train or fine-tune an EquineProtonet model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>dataset</code></td>
            <td>
                  <code><span title="torch.utils.data.TensorDataset">TensorDataset</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input pytorch TensorDataset of training data for model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_episodes</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The desired number of episodes to use for training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>calib_frac</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fraction of given training data to reserve for model calibration, by default 0.2.</p>
              </div>
            </td>
            <td>
                  <code>0.2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>support_size</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of support examples to generate for each class, by default 25.</p>
              </div>
            </td>
            <td>
                  <code>25</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>way</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of classes to train on per episode, by default 3.</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>episode_size</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of examples to use per episode, by default 100.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>loss_fn</code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.nn.functional.cross_entropy">cross_entropy</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>opt_class</code></td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.optim.Adam">Adam</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_calibration_epochs</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The desired number of epochs to use for temperature scaling, by default 2.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>calibration_lr</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Learning rate for temperature scaling, by default 0.01.</p>
              </div>
            </td>
            <td>
                  <code>0.01</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>tuple[dict[str, <span title="typing.Any">Any</span>], <span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple containing the model summary, the held out calibration data, and the calibration labels.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="n">calib_frac</span><span class="p">:</span> <span class="n">calib_frac</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">calib_frac</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="n">TensorDataset</span><span class="p">,</span>
    <span class="n">num_episodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">calib_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">support_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
    <span class="n">way</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">episode_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span>
    <span class="n">opt_class</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="n">num_calibration_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">calibration_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train or fine-tune an EquineProtonet model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dataset : TensorDataset</span>
<span class="sd">        Input pytorch TensorDataset of training data for model.</span>
<span class="sd">    num_episodes : int</span>
<span class="sd">        The desired number of episodes to use for training.</span>
<span class="sd">    calib_frac : float, optional</span>
<span class="sd">        Fraction of given training data to reserve for model calibration, by default 0.2.</span>
<span class="sd">    support_size : int, optional</span>
<span class="sd">        Number of support examples to generate for each class, by default 25.</span>
<span class="sd">    way : int, optional</span>
<span class="sd">        Number of classes to train on per episode, by default 3.</span>
<span class="sd">    episode_size : int, optional</span>
<span class="sd">        Number of examples to use per episode, by default 100.</span>
<span class="sd">    loss_fn : Callable, optional</span>
<span class="sd">        A pytorch loss function, eg., torch.nn.CrossEntropyLoss(), by default torch.nn.functional.cross_entropy.</span>
<span class="sd">    opt_class : Callable, optional</span>
<span class="sd">        A pytorch optimizer, e.g., torch.optim.Adam, by default torch.optim.Adam.</span>
<span class="sd">    num_calibration_epochs : int, optional</span>
<span class="sd">        The desired number of epochs to use for temperature scaling, by default 2.</span>
<span class="sd">    calibration_lr : float, optional</span>
<span class="sd">        Learning rate for temperature scaling, by default 0.01.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[dict[str, Any], torch.Tensor, torch.Tensor]</span>
<span class="sd">        A tuple containing the model summary, the held out calibration data, and the calibration labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_temperature</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:]</span>

    <span class="n">train_x</span><span class="p">,</span> <span class="n">calib_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">calib_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">calib_frac</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">Y</span>
    <span class="p">)</span>  <span class="c1"># TODO: Replace sklearn with torch call</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt_class</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">)):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">support</span><span class="p">,</span> <span class="n">episode_x</span><span class="p">,</span> <span class="n">episode_y</span> <span class="o">=</span> <span class="n">generate_episode</span><span class="p">(</span>
            <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">support_size</span><span class="p">,</span> <span class="n">way</span><span class="p">,</span> <span class="n">episode_size</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">episode_x</span><span class="p">)</span>
        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">dists</span><span class="p">),</span> <span class="n">episode_y</span><span class="p">)</span>
        <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">full_support</span> <span class="o">=</span> <span class="n">generate_support</span><span class="p">(</span>
        <span class="n">train_x</span><span class="p">,</span>
        <span class="n">train_y</span><span class="p">,</span>
        <span class="n">support_size</span><span class="p">,</span>
        <span class="n">selected_labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_y</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span>
        <span class="n">full_support</span>
    <span class="p">)</span>  <span class="c1"># update support with final selected examples</span>

    <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
    <span class="n">pred_probs</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
    <span class="n">ood_dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ood_dist</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_fit_outlier_scores</span><span class="p">(</span><span class="n">ood_dists</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_temperature</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">calibrate_temperature</span><span class="p">(</span>
            <span class="n">calib_x</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">,</span> <span class="n">num_calibration_epochs</span><span class="p">,</span> <span class="n">calibration_lr</span>
        <span class="p">)</span>

    <span class="n">date_trained</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%m/</span><span class="si">%d</span><span class="s2">/%Y, %H:%M:%S&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_summary</span> <span class="o">=</span> <span class="n">generate_train_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">date_trained</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_summary</span><span class="p">,</span> <span class="n">calib_x</span><span class="p">,</span> <span class="n">calib_y</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.EquineProtonet.update_support" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_support</span><span class="p">(</span><span class="n">support_x</span><span class="p">,</span> <span class="n">support_y</span><span class="p">,</span> <span class="n">calib_frac</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.EquineProtonet.update_support" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Function to update protonet support examples with given examples.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>support_x</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor containing support examples for protonet.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>support_y</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor containing labels for given support examples.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>calib_frac</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fraction of given support data to use for OOD calibration.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="n">calib_frac</span><span class="p">:</span> <span class="p">(</span><span class="n">calib_frac</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">calib_frac</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">update_support</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">support_x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">support_y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">calib_frac</span><span class="p">:</span> <span class="nb">float</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function to update protonet support examples with given examples.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    support_x : torch.Tensor</span>
<span class="sd">        Tensor containing support examples for protonet.</span>
<span class="sd">    support_y : torch.Tensor</span>
<span class="sd">        Tensor containing labels for given support examples.</span>
<span class="sd">    calib_frac : float</span>
<span class="sd">        Fraction of given support data to use for OOD calibration.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">support_x</span><span class="p">,</span> <span class="n">calib_x</span><span class="p">,</span> <span class="n">support_y</span><span class="p">,</span> <span class="n">calib_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">support_x</span><span class="p">,</span> <span class="n">support_y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">calib_frac</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">support_y</span>
    <span class="p">)</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">support_y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">support</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">counts</span><span class="o">.</span><span class="n">tolist</span><span class="p">())):</span>
        <span class="n">class_support</span> <span class="o">=</span> <span class="n">generate_support</span><span class="p">(</span>
            <span class="n">support_x</span><span class="p">,</span>
            <span class="n">support_y</span><span class="p">,</span>
            <span class="n">support_size</span><span class="o">=</span><span class="n">count</span><span class="p">,</span>
            <span class="n">selected_labels</span><span class="o">=</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">support</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">class_support</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>

    <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">calib_x</span><span class="p">)</span>
    <span class="n">ood_dists</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ood_dist</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">dists</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_fit_outlier_scores</span><span class="p">(</span><span class="n">ood_dists</span><span class="p">,</span> <span class="n">calib_y</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="equine.equine_protonet.Protonet" class="doc doc-heading">
            <code>Protonet</code>


<a href="#equine.equine_protonet.Protonet" class="headerlink" title="Permanent link">Â¤</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


      <p>Private class that implements a prototypical neural network for use in EQUINE.</p>

              <details class="quote">
                <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@beartype</span>
<span class="k">class</span> <span class="nc">Protonet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Private class that implements a prototypical neural network for use in EQUINE.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">emb_out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">,</span>
        <span class="n">cov_reg_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Protonet class constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        embedding_model : torch.nn.Module</span>
<span class="sd">            The PyTorch embedding model to generate logits with.</span>
<span class="sd">        emb_out_dim : int</span>
<span class="sd">            Dimension size of given embedding model&#39;s output.</span>
<span class="sd">        cov_type : CovType</span>
<span class="sd">            Type of covariance to use when computing distances [unit, diag, full].</span>
<span class="sd">        cov_reg_type : str</span>
<span class="sd">            Type of regularization to use when generating the covariance matrix [epsilon, shared].</span>
<span class="sd">        epsilon : float</span>
<span class="sd">            Epsilon value to use for covariance regularization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span> <span class="o">=</span> <span class="n">embedding_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">=</span> <span class="n">cov_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_reg_type</span> <span class="o">=</span> <span class="n">cov_reg_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span> <span class="o">=</span> <span class="n">emb_out_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">support</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># self.support_embeddings = None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_head</span><span class="p">(</span><span class="n">emb_out_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_model_head</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method for adding a PyTorch layer on top of the given embedding model. This layer</span>
<span class="sd">        is intended to offer extra degrees of freedom for distance learning in the embedding space.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        emb_out_dim : int</span>
<span class="sd">            Dimension size of the embedding model output.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.nn.Linear</span>
<span class="sd">            The created PyTorch model layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">emb_out_dim</span><span class="p">,</span> <span class="n">emb_out_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method for calculating model embeddings using both the given embedding model and the added model head.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : torch.Tensor</span>
<span class="sd">            Input tensor to compute embeddings on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Fully computed embedding tensors for the given X tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">head_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_head</span><span class="p">(</span><span class="n">model_embeddings</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">head_embeddings</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_prototypes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method for computing class prototypes based on given support examples.</span>
<span class="sd">        ``Prototypes&#39;&#39; in this context are the means of the support embeddings for each class.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensors of prototypes for each of the given classes in the support.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute prototype for each class</span>
        <span class="n">proto_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">:</span>  <span class="c1"># look at doing functorch</span>
            <span class="n">class_prototype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="n">proto_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">class_prototype</span><span class="p">)</span>

        <span class="n">prototypes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">proto_list</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prototypes</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method for generating the (regularized) support example covariance matrix(es) used for calculating distances.</span>
<span class="sd">        Note that this method is only called once per episode, and the resulting tensor is used for all queries.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cov_type : CovType</span>
<span class="sd">            Type of covariance to use [unit, diag, full].</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensor containing the generated regularized covariance matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">class_cov_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">class_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance_by_type</span><span class="p">(</span>
                <span class="n">cov_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_covariance</span>

        <span class="n">reg_covariance_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularize_covariance</span><span class="p">(</span>
            <span class="n">class_cov_dict</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_reg_type</span>
        <span class="p">)</span>
        <span class="n">reg_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">reg_covariance_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="k">return</span> <span class="n">reg_covariance</span>  <span class="c1"># TODO try putting everything on GPU with .to() and see if faster</span>

    <span class="k">def</span> <span class="nf">compute_covariance_by_type</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">,</span> <span class="n">embedding</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to select appropriate covariance matrix type based on cov_type</span>
<span class="sd">        :param cov_type: Type of covariance to use [unit, diag, full]</span>
<span class="sd">        :param embedding: embedding tensor to use when generating the covariance matrix</span>
<span class="sd">        :return torch.Tensor: Tensor containing the requested covariance matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span><span class="p">:</span>
            <span class="n">class_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
            <span class="n">class_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">UNIT</span><span class="p">:</span>
            <span class="n">class_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span>

        <span class="k">return</span> <span class="n">class_covariance</span>

    <span class="k">def</span> <span class="nf">regularize_covariance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">class_cov_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">,</span>
        <span class="n">cov_reg_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to add regularization to each class covariance matrix based on the selected regularization type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        class_cov_dict : OrderedDict[int, torch.Tensor]</span>
<span class="sd">            A dictionary containing each class and the corresponding covariance matrix.</span>
<span class="sd">        cov_type : CovType</span>
<span class="sd">            Type of covariance to use [unit, diag, full].</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[float, torch.Tensor]</span>
<span class="sd">            Dictionary containing the regularized class covariance matrices.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span><span class="p">:</span>
            <span class="n">regularization</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
            <span class="n">regularization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">UNIT</span><span class="p">:</span>
            <span class="n">regularization</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown Covariance Type&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cov_reg_type</span> <span class="o">==</span> <span class="s2">&quot;shared&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cov_type</span> <span class="o">!=</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span> <span class="ow">and</span> <span class="n">cov_type</span> <span class="o">!=</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">:</span>
                    <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+</span> <span class="n">regularization</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Covariance type UNIT is incompatible with shared regularization, </span><span class="se">\</span>
<span class="s2">                    reverting to epsilon regularization&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">class_cov_dict</span>

            <span class="n">shared_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_shared_covariance</span><span class="p">(</span><span class="n">class_cov_dict</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">:</span>
                <span class="n">num_class_support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">lamb</span> <span class="o">=</span> <span class="n">num_class_support</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_class_support</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

                <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">lamb</span> <span class="o">*</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
                    <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lamb</span><span class="p">)</span> <span class="o">*</span> <span class="n">shared_covariance</span>
                    <span class="o">+</span> <span class="n">regularization</span>
                <span class="p">)</span>

        <span class="k">elif</span> <span class="n">cov_reg_type</span> <span class="o">==</span> <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">class_cov_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+</span> <span class="n">regularization</span>

        <span class="k">return</span> <span class="n">class_cov_dict</span>

    <span class="k">def</span> <span class="nf">compute_shared_covariance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">class_cov_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to calculate a shared covariance matrix.</span>

<span class="sd">        The shared covariance matrix is calculated as the weighted average of the class covariance matrices,</span>
<span class="sd">        where the weights are the number of support examples for each class. This is useful when the number of</span>
<span class="sd">        support examples for each class is small.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        class_cov_dict : OrderedDict[int, torch.Tensor]</span>
<span class="sd">            A dictionary containing each class and the corresponding covariance matrix.</span>
<span class="sd">        cov_type : CovType</span>
<span class="sd">            Type of covariance to use [unit, diag, full].</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensor containing the shared covariance matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total_support</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">class_cov_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

        <span class="k">if</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span><span class="p">:</span>
            <span class="n">shared_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
            <span class="n">shared_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Shared covariance can only be used with FULL or DIAGONAL (not UNIT) covariance types&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">class_cov_dict</span><span class="p">:</span>
            <span class="n">num_class_support</span> <span class="o">=</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">shared_covariance</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">shared_covariance</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_class_support</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
            <span class="p">)</span>  <span class="c1"># undo N-1 div from cov</span>

        <span class="n">shared_covariance</span> <span class="o">=</span> <span class="n">shared_covariance</span> <span class="o">/</span> <span class="p">(</span>
            <span class="n">total_support</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># redo N-1 div for shared cov</span>

        <span class="k">return</span> <span class="n">shared_covariance</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X_embed</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="nd">@icontract</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">result</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">result</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">compute_distance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X_embed</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">cov</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to compute the distances to class prototypes for the given embeddings.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_embed : torch.Tensor</span>
<span class="sd">            The embeddings of the query examples.</span>
<span class="sd">        mu : torch.Tensor</span>
<span class="sd">            The class prototypes (means of the support embeddings).</span>
<span class="sd">        cov : torch.Tensor</span>
<span class="sd">            The support covariance matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The calculated distances from each of the class prototypes for the given embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># examples x 1 x dimension</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">_queries</span><span class="p">)</span>  <span class="c1"># examples x classes x dimension</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># (diagonal covariance)</span>
            <span class="c1"># examples x classes x dimension</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">diff</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">cov</span><span class="p">))</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># examples x classes</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>  <span class="c1"># examples x classes</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># len(cov.shape) == 3: (full covariance)</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">diff</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># classes x dimension x examples</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">mahalanobis_distance_nosq</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>  <span class="c1"># examples x classes</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dist</span>

    <span class="k">def</span> <span class="nf">compute_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distances</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to compute predicted classes from distances via a softmax function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        distances : torch.Tensor</span>
<span class="sd">            The distances of embeddings to class prototypes.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensor of class predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">distances</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">softmax</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Protonet forward function, generates class probability predictions and distances from prototypes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : torch.Tensor</span>
<span class="sd">            Input tensor of queries for generating predictions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">            Tuple containing class probability predictions, and class distances from prototypes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No support examples found. Protonet Model requires model support to </span><span class="se">\</span>
<span class="s2">                    be set with the &#39;update_support()&#39; method before calling forward.&quot;</span>
            <span class="p">)</span>

        <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">]):</span>
            <span class="n">X_embed</span> <span class="o">=</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># handle single examples</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_distance</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prototypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">)</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_classes</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">classes</span><span class="p">,</span> <span class="n">distances</span>

    <span class="k">def</span> <span class="nf">update_support</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">support</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to update the support examples, and all the calculations that rely on them.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        support : OrderedDict</span>
<span class="sd">            Ordered dict containing class labels and their associated support examples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">support</span> <span class="o">=</span> <span class="n">support</span>  <span class="c1"># TODO torch.nn.ParameterDict(support)</span>

        <span class="n">support_embs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">support</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">support</span><span class="p">:</span>
            <span class="n">support_embs</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">support</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">support_embs</span>  <span class="c1"># TODO torch.nn.ParameterDict(support_embs)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prototypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_prototypes</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_global_moments</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="n">PRED_COV_TYPE</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span><span class="p">)</span>

    <span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_global_moments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to calculate the global moments of the support embeddings for use in OOD score generation&quot;&quot;&quot;</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance_by_type</span><span class="p">(</span><span class="n">OOD_COV_TYPE</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">global_reg_input</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">global_reg_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularize_covariance</span><span class="p">(</span>
            <span class="n">global_reg_input</span><span class="p">,</span> <span class="n">OOD_COV_TYPE</span><span class="p">,</span> <span class="s2">&quot;epsilon&quot;</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">embedding_model</span><span class="p">,</span> <span class="n">emb_out_dim</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_reg_type</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.__init__" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Protonet class constructor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>embedding_model</code></td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The PyTorch embedding model to generate logits with.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>emb_out_dim</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension size of given embedding model's output.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cov_type</code></td>
            <td>
                  <code><span title="equine.equine_protonet.CovType">CovType</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of covariance to use when computing distances [unit, diag, full].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cov_reg_type</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of regularization to use when generating the covariance matrix [epsilon, shared].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>epsilon</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Epsilon value to use for covariance regularization.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">embedding_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">emb_out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">,</span>
    <span class="n">cov_reg_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Protonet class constructor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    embedding_model : torch.nn.Module</span>
<span class="sd">        The PyTorch embedding model to generate logits with.</span>
<span class="sd">    emb_out_dim : int</span>
<span class="sd">        Dimension size of given embedding model&#39;s output.</span>
<span class="sd">    cov_type : CovType</span>
<span class="sd">        Type of covariance to use when computing distances [unit, diag, full].</span>
<span class="sd">    cov_reg_type : str</span>
<span class="sd">        Type of regularization to use when generating the covariance matrix [epsilon, shared].</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Epsilon value to use for covariance regularization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span> <span class="o">=</span> <span class="n">embedding_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">=</span> <span class="n">cov_type</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cov_reg_type</span> <span class="o">=</span> <span class="n">cov_reg_type</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span> <span class="o">=</span> <span class="n">emb_out_dim</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">support</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># self.support_embeddings = None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_head</span><span class="p">(</span><span class="n">emb_out_dim</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_classes" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_classes</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.compute_classes" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to compute predicted classes from distances via a softmax function.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>distances</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The distances of embeddings to class prototypes.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of class predictions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distances</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to compute predicted classes from distances via a softmax function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    distances : torch.Tensor</span>
<span class="sd">        The distances of embeddings to class prototypes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Tensor of class predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">distances</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">softmax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_covariance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_covariance</span><span class="p">(</span><span class="n">cov_type</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.compute_covariance" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method for generating the (regularized) support example covariance matrix(es) used for calculating distances.
Note that this method is only called once per episode, and the resulting tensor is used for all queries.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>cov_type</code></td>
            <td>
                  <code><span title="equine.equine_protonet.CovType">CovType</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of covariance to use [unit, diag, full].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor containing the generated regularized covariance matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method for generating the (regularized) support example covariance matrix(es) used for calculating distances.</span>
<span class="sd">    Note that this method is only called once per episode, and the resulting tensor is used for all queries.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cov_type : CovType</span>
<span class="sd">        Type of covariance to use [unit, diag, full].</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Tensor containing the generated regularized covariance matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">class_cov_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">class_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance_by_type</span><span class="p">(</span>
            <span class="n">cov_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_covariance</span>

    <span class="n">reg_covariance_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularize_covariance</span><span class="p">(</span>
        <span class="n">class_cov_dict</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_reg_type</span>
    <span class="p">)</span>
    <span class="n">reg_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">reg_covariance_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

    <span class="k">return</span> <span class="n">reg_covariance</span>  <span class="c1"># TODO try putting everything on GPU with .to() and see if faster</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_covariance_by_type" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_covariance_by_type</span><span class="p">(</span><span class="n">cov_type</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.compute_covariance_by_type" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to select appropriate covariance matrix type based on cov_type
:param cov_type: Type of covariance to use [unit, diag, full]
:param embedding: embedding tensor to use when generating the covariance matrix
:return torch.Tensor: Tensor containing the requested covariance matrix</p>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_covariance_by_type</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">,</span> <span class="n">embedding</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to select appropriate covariance matrix type based on cov_type</span>
<span class="sd">    :param cov_type: Type of covariance to use [unit, diag, full]</span>
<span class="sd">    :param embedding: embedding tensor to use when generating the covariance matrix</span>
<span class="sd">    :return torch.Tensor: Tensor containing the requested covariance matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span><span class="p">:</span>
        <span class="n">class_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
        <span class="n">class_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">UNIT</span><span class="p">:</span>
        <span class="n">class_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">return</span> <span class="n">class_covariance</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_distance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_distance</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.compute_distance" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to compute the distances to class prototypes for the given embeddings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X_embed</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The embeddings of the query examples.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>mu</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The class prototypes (means of the support embeddings).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cov</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The support covariance matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The calculated distances from each of the class prototypes for the given embeddings.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X_embed</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nd">@icontract</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">result</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">result</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">compute_distance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">X_embed</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">cov</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to compute the distances to class prototypes for the given embeddings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_embed : torch.Tensor</span>
<span class="sd">        The embeddings of the query examples.</span>
<span class="sd">    mu : torch.Tensor</span>
<span class="sd">        The class prototypes (means of the support embeddings).</span>
<span class="sd">    cov : torch.Tensor</span>
<span class="sd">        The support covariance matrix.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        The calculated distances from each of the class prototypes for the given embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># examples x 1 x dimension</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">_queries</span><span class="p">)</span>  <span class="c1"># examples x classes x dimension</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># (diagonal covariance)</span>
        <span class="c1"># examples x classes x dimension</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">diff</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">cov</span><span class="p">))</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># examples x classes</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>  <span class="c1"># examples x classes</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># len(cov.shape) == 3: (full covariance)</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">diff</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># classes x dimension x examples</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">mahalanobis_distance_nosq</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>  <span class="c1"># examples x classes</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.compute_embeddings" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method for calculating model embeddings using both the given embedding model and the added model head.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor to compute embeddings on.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fully computed embedding tensors for the given X tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method for calculating model embeddings using both the given embedding model and the added model head.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : torch.Tensor</span>
<span class="sd">        Input tensor to compute embeddings on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Fully computed embedding tensors for the given X tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">head_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_head</span><span class="p">(</span><span class="n">model_embeddings</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">head_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_global_moments" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_global_moments</span><span class="p">()</span></code>

<a href="#equine.equine_protonet.Protonet.compute_global_moments" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to calculate the global moments of the support embeddings for use in OOD score generation</p>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_global_moments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to calculate the global moments of the support embeddings for use in OOD score generation&quot;&quot;&quot;</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">global_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance_by_type</span><span class="p">(</span><span class="n">OOD_COV_TYPE</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="n">global_reg_input</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">global_reg_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_covariance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">global_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularize_covariance</span><span class="p">(</span>
        <span class="n">global_reg_input</span><span class="p">,</span> <span class="n">OOD_COV_TYPE</span><span class="p">,</span> <span class="s2">&quot;epsilon&quot;</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">global_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_prototypes" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_prototypes</span><span class="p">()</span></code>

<a href="#equine.equine_protonet.Protonet.compute_prototypes" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method for computing class prototypes based on given support examples.
``Prototypes'' in this context are the means of the support embeddings for each class.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensors of prototypes for each of the given classes in the support.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@icontract</span><span class="o">.</span><span class="n">require</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_prototypes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method for computing class prototypes based on given support examples.</span>
<span class="sd">    ``Prototypes&#39;&#39; in this context are the means of the support embeddings for each class.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Tensors of prototypes for each of the given classes in the support.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute prototype for each class</span>
    <span class="n">proto_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">:</span>  <span class="c1"># look at doing functorch</span>
        <span class="n">class_prototype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">proto_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">class_prototype</span><span class="p">)</span>

    <span class="n">prototypes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">proto_list</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">prototypes</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.compute_shared_covariance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_shared_covariance</span><span class="p">(</span><span class="n">class_cov_dict</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.compute_shared_covariance" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to calculate a shared covariance matrix.</p>
<p>The shared covariance matrix is calculated as the weighted average of the class covariance matrices,
where the weights are the number of support examples for each class. This is useful when the number of
support examples for each class is small.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>class_cov_dict</code></td>
            <td>
                  <code><span title="collections.OrderedDict">OrderedDict</span>[int, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing each class and the corresponding covariance matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cov_type</code></td>
            <td>
                  <code><span title="equine.equine_protonet.CovType">CovType</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of covariance to use [unit, diag, full].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor containing the shared covariance matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_shared_covariance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">class_cov_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to calculate a shared covariance matrix.</span>

<span class="sd">    The shared covariance matrix is calculated as the weighted average of the class covariance matrices,</span>
<span class="sd">    where the weights are the number of support examples for each class. This is useful when the number of</span>
<span class="sd">    support examples for each class is small.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    class_cov_dict : OrderedDict[int, torch.Tensor]</span>
<span class="sd">        A dictionary containing each class and the corresponding covariance matrix.</span>
<span class="sd">    cov_type : CovType</span>
<span class="sd">        Type of covariance to use [unit, diag, full].</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Tensor containing the shared covariance matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_support</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">class_cov_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

    <span class="k">if</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span><span class="p">:</span>
        <span class="n">shared_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
        <span class="n">shared_covariance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Shared covariance can only be used with FULL or DIAGONAL (not UNIT) covariance types&quot;</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">class_cov_dict</span><span class="p">:</span>
        <span class="n">num_class_support</span> <span class="o">=</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">shared_covariance</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">shared_covariance</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_class_support</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
        <span class="p">)</span>  <span class="c1"># undo N-1 div from cov</span>

    <span class="n">shared_covariance</span> <span class="o">=</span> <span class="n">shared_covariance</span> <span class="o">/</span> <span class="p">(</span>
        <span class="n">total_support</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="p">)</span>  <span class="c1"># redo N-1 div for shared cov</span>

    <span class="k">return</span> <span class="n">shared_covariance</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.create_model_head" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_model_head</span><span class="p">(</span><span class="n">emb_out_dim</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.create_model_head" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method for adding a PyTorch layer on top of the given embedding model. This layer
is intended to offer extra degrees of freedom for distance learning in the embedding space.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>emb_out_dim</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension size of the embedding model output.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.nn.Linear">Linear</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The created PyTorch model layer.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_model_head</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method for adding a PyTorch layer on top of the given embedding model. This layer</span>
<span class="sd">    is intended to offer extra degrees of freedom for distance learning in the embedding space.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    emb_out_dim : int</span>
<span class="sd">        Dimension size of the embedding model output.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.nn.Linear</span>
<span class="sd">        The created PyTorch model layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">emb_out_dim</span><span class="p">,</span> <span class="n">emb_out_dim</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.forward" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Protonet forward function, generates class probability predictions and distances from prototypes.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of queries for generating predictions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>tuple[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple containing class probability predictions, and class distances from prototypes.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Protonet forward function, generates class probability predictions and distances from prototypes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : torch.Tensor</span>
<span class="sd">        Input tensor of queries for generating predictions.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">        Tuple containing class probability predictions, and class distances from prototypes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;No support examples found. Protonet Model requires model support to </span><span class="se">\</span>
<span class="s2">                be set with the &#39;update_support()&#39; method before calling forward.&quot;</span>
        <span class="p">)</span>

    <span class="n">X_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">]):</span>
        <span class="n">X_embed</span> <span class="o">=</span> <span class="n">X_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># handle single examples</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_distance</span><span class="p">(</span><span class="n">X_embed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prototypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_classes</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">classes</span><span class="p">,</span> <span class="n">distances</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.regularize_covariance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">regularize_covariance</span><span class="p">(</span><span class="n">class_cov_dict</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">,</span> <span class="n">cov_reg_type</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.regularize_covariance" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to add regularization to each class covariance matrix based on the selected regularization type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>class_cov_dict</code></td>
            <td>
                  <code><span title="collections.OrderedDict">OrderedDict</span>[int, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing each class and the corresponding covariance matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cov_type</code></td>
            <td>
                  <code><span title="equine.equine_protonet.CovType">CovType</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of covariance to use [unit, diag, full].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>dict[float, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary containing the regularized class covariance matrices.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">regularize_covariance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">class_cov_dict</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">cov_type</span><span class="p">:</span> <span class="n">CovType</span><span class="p">,</span>
    <span class="n">cov_reg_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to add regularization to each class covariance matrix based on the selected regularization type.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    class_cov_dict : OrderedDict[int, torch.Tensor]</span>
<span class="sd">        A dictionary containing each class and the corresponding covariance matrix.</span>
<span class="sd">    cov_type : CovType</span>
<span class="sd">        Type of covariance to use [unit, diag, full].</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict[float, torch.Tensor]</span>
<span class="sd">        Dictionary containing the regularized class covariance matrices.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span><span class="p">:</span>
        <span class="n">regularization</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
        <span class="n">regularization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cov_type</span> <span class="o">==</span> <span class="n">CovType</span><span class="o">.</span><span class="n">UNIT</span><span class="p">:</span>
        <span class="n">regularization</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_out_dim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown Covariance Type&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cov_reg_type</span> <span class="o">==</span> <span class="s2">&quot;shared&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cov_type</span> <span class="o">!=</span> <span class="n">CovType</span><span class="o">.</span><span class="n">FULL</span> <span class="ow">and</span> <span class="n">cov_type</span> <span class="o">!=</span> <span class="n">CovType</span><span class="o">.</span><span class="n">DIAGONAL</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">:</span>
                <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+</span> <span class="n">regularization</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Covariance type UNIT is incompatible with shared regularization, </span><span class="se">\</span>
<span class="s2">                reverting to epsilon regularization&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">class_cov_dict</span>

        <span class="n">shared_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_shared_covariance</span><span class="p">(</span><span class="n">class_cov_dict</span><span class="p">,</span> <span class="n">cov_type</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">:</span>
            <span class="n">num_class_support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">lamb</span> <span class="o">=</span> <span class="n">num_class_support</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_class_support</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">lamb</span> <span class="o">*</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
                <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lamb</span><span class="p">)</span> <span class="o">*</span> <span class="n">shared_covariance</span>
                <span class="o">+</span> <span class="n">regularization</span>
            <span class="p">)</span>

    <span class="k">elif</span> <span class="n">cov_reg_type</span> <span class="o">==</span> <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">class_cov_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_cov_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+</span> <span class="n">regularization</span>

    <span class="k">return</span> <span class="n">class_cov_dict</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="equine.equine_protonet.Protonet.update_support" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_support</span><span class="p">(</span><span class="n">support</span><span class="p">)</span></code>

<a href="#equine.equine_protonet.Protonet.update_support" class="headerlink" title="Permanent link">Â¤</a></h3>


    <div class="doc doc-contents ">

      <p>Method to update the support examples, and all the calculations that rely on them.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>support</code></td>
            <td>
                  <code><span title="collections.OrderedDict">OrderedDict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Ordered dict containing class labels and their associated support examples.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/equine/equine_protonet.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update_support</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">support</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to update the support examples, and all the calculations that rely on them.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    support : OrderedDict</span>
<span class="sd">        Ordered dict containing class labels and their associated support examples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">support</span> <span class="o">=</span> <span class="n">support</span>  <span class="c1"># TODO torch.nn.ParameterDict(support)</span>

    <span class="n">support_embs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">support</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">support</span><span class="p">:</span>
        <span class="n">support_embs</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">support</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">support_embeddings</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">support_embs</span>  <span class="c1"># TODO torch.nn.ParameterDict(support_embs)</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">prototypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_prototypes</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_global_moments</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="n">PRED_COV_TYPE</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariance</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright (c) 2024 Massachusetts Institute of Technology, MIT Licensed
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.471ce7a9.min.js"></script>
      
    
  </body>
</html>